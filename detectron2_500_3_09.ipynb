{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "detectron2_500_25.08.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPwExGAMQ0GN4wZEpqQEwYJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vidyabandgar97/A2A/blob/main/detectron2_500_3_09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCphTc0U7WZF",
        "outputId": "f65545fc-1997-4a65-cd07-52de8a8d3673"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x42TB5k-9eTH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ecbb8aa-01e9-4323-8e84-5c0f8f6bff3d"
      },
      "source": [
        "#getting training data\n",
        "%cd /content/drive/MyDrive/detectron2_500/\n",
        "!gdown --id 1Hh7XFuyPV2qH5Pg6sqce6WmdOZoSh-th\n",
        "!gdown --id 1FeJJYBgcfuZsunkk-WQFkHO8ry-Ywhrn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/detectron2_500\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Hh7XFuyPV2qH5Pg6sqce6WmdOZoSh-th\n",
            "To: /content/drive/MyDrive/detectron2_500/main.json\n",
            "100% 1.54M/1.54M [00:00<00:00, 48.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1FeJJYBgcfuZsunkk-WQFkHO8ry-Ywhrn\n",
            "To: /content/drive/MyDrive/detectron2_500/Dataset.zip\n",
            "114MB [00:01, 72.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWi7bs4M99gl",
        "outputId": "987a6605-8881-4d9c-8d8b-97d5997451de"
      },
      "source": [
        "!unzip /content/drive/MyDrive/detectron2_500/Dataset.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/detectron2_500/Dataset.zip\n",
            "   creating: Dataset/\n",
            "  inflating: Dataset/000000010363.jpg  \n",
            "  inflating: Dataset/000000014380.jpg  \n",
            "  inflating: Dataset/000000018837.jpg  \n",
            "  inflating: Dataset/000000022755.jpg  \n",
            "  inflating: Dataset/000000026926.jpg  \n",
            "  inflating: Dataset/000000030828.jpg  \n",
            "  inflating: Dataset/000000031118.jpg  \n",
            "  inflating: Dataset/000000032941.jpg  \n",
            "  inflating: Dataset/000000033109.jpg  \n",
            "  inflating: Dataset/000000033221.jpg  \n",
            "  inflating: Dataset/000000045596.jpg  \n",
            "  inflating: Dataset/000000057597.jpg  \n",
            "  inflating: Dataset/000000057672.jpg  \n",
            "  inflating: Dataset/000000067616.jpg  \n",
            "  inflating: Dataset/000000068093.jpg  \n",
            "  inflating: Dataset/000000074058.jpg  \n",
            "  inflating: Dataset/000000084170.jpg  \n",
            "  inflating: Dataset/000000084492.jpg  \n",
            "  inflating: Dataset/000000086220.jpg  \n",
            "  inflating: Dataset/000000086483.jpg  \n",
            "  inflating: Dataset/000000088462.jpg  \n",
            "  inflating: Dataset/000000094751.jpg  \n",
            "  inflating: Dataset/000000098392.jpg  \n",
            "  inflating: Dataset/000000100624.jpg  \n",
            "  inflating: Dataset/000000102411.jpg  \n",
            "  inflating: Dataset/000000102805.jpg  \n",
            "  inflating: Dataset/000000111036.jpg  \n",
            "  inflating: Dataset/000000111086.jpg  \n",
            "  inflating: Dataset/000000114770.jpg  \n",
            "  inflating: Dataset/000000121242.jpg  \n",
            "  inflating: Dataset/000000127092.jpg  \n",
            "  inflating: Dataset/000000127263.jpg  \n",
            "  inflating: Dataset/000000135410.jpg  \n",
            "  inflating: Dataset/000000135604.jpg  \n",
            "  inflating: Dataset/000000137727.jpg  \n",
            "  inflating: Dataset/000000141597.jpg  \n",
            "  inflating: Dataset/000000147725.jpg  \n",
            "  inflating: Dataset/000000147740.jpg  \n",
            "  inflating: Dataset/000000151962.jpg  \n",
            "  inflating: Dataset/000000156071.jpg  \n",
            "  inflating: Dataset/000000157756.jpg  \n",
            "  inflating: Dataset/000000157928.jpg  \n",
            "  inflating: Dataset/000000160012.jpg  \n",
            "  inflating: Dataset/000000166391.jpg  \n",
            "  inflating: Dataset/000000168330.jpg  \n",
            "  inflating: Dataset/000000169996.jpg  \n",
            "  inflating: Dataset/000000170545.jpg  \n",
            "  inflating: Dataset/000000172330.jpg  \n",
            "  inflating: Dataset/000000174482.jpg  \n",
            "  inflating: Dataset/000000176606.jpg  \n",
            "  inflating: Dataset/000000184324.jpg  \n",
            "  inflating: Dataset/000000184611.jpg  \n",
            "  inflating: Dataset/000000191013.jpg  \n",
            "  inflating: Dataset/000000192670.jpg  \n",
            "  inflating: Dataset/000000192716.jpg  \n",
            "  inflating: Dataset/000000194716.jpg  \n",
            "  inflating: Dataset/000000196759.jpg  \n",
            "  inflating: Dataset/000000198805.jpg  \n",
            "  inflating: Dataset/000000198928.jpg  \n",
            "  inflating: Dataset/000000200961.jpg  \n",
            "  inflating: Dataset/000000204871.jpg  \n",
            "  inflating: Dataset/000000209222.jpg  \n",
            "  inflating: Dataset/000000213255.jpg  \n",
            "  inflating: Dataset/000000221754.jpg  \n",
            "  inflating: Dataset/000000225532.jpg  \n",
            "  inflating: Dataset/000000227511.jpg  \n",
            "  inflating: Dataset/000000231508.jpg  \n",
            "  inflating: Dataset/000000243867.jpg  \n",
            "  inflating: Dataset/000000260266.jpg  \n",
            "  inflating: Dataset/000000260470.jpg  \n",
            "  inflating: Dataset/000000276707.jpg  \n",
            "  inflating: Dataset/000000276720.jpg  \n",
            "  inflating: Dataset/000000277005.jpg  \n",
            "  inflating: Dataset/000000278705.jpg  \n",
            "  inflating: Dataset/000000278749.jpg  \n",
            "  inflating: Dataset/000000278848.jpg  \n",
            "  inflating: Dataset/000000283037.jpg  \n",
            "  inflating: Dataset/000000283038.jpg  \n",
            "  inflating: Dataset/000000284725.jpg  \n",
            "  inflating: Dataset/000000287291.jpg  \n",
            "  inflating: Dataset/000000292997.jpg  \n",
            "  inflating: Dataset/000000293071.jpg  \n",
            "  inflating: Dataset/000000295420.jpg  \n",
            "  inflating: Dataset/000000301135.jpg  \n",
            "  inflating: Dataset/000000301376.jpg  \n",
            "  inflating: Dataset/000000301421.jpg  \n",
            "  inflating: Dataset/000000303305.jpg  \n",
            "  inflating: Dataset/000000303566.jpg  \n",
            "  inflating: Dataset/000000305695.jpg  \n",
            "  inflating: Dataset/000000309391.jpg  \n",
            "  inflating: Dataset/000000313588.jpg  \n",
            "  inflating: Dataset/000000315450.jpg  \n",
            "  inflating: Dataset/000000319607.jpg  \n",
            "  inflating: Dataset/000000323828.jpg  \n",
            "  inflating: Dataset/000000327890.jpg  \n",
            "  inflating: Dataset/000000334006.jpg  \n",
            "  inflating: Dataset/000000334309.jpg  \n",
            "  inflating: Dataset/000000334371.jpg  \n",
            "  inflating: Dataset/000000336232.jpg  \n",
            "  inflating: Dataset/000000342128.jpg  \n",
            "  inflating: Dataset/000000346232.jpg  \n",
            "  inflating: Dataset/000000354753.jpg  \n",
            "  inflating: Dataset/000000354829.jpg  \n",
            "  inflating: Dataset/000000356424.jpg  \n",
            "  inflating: Dataset/000000356612.jpg  \n",
            "  inflating: Dataset/000000383289.jpg  \n",
            "  inflating: Dataset/000000389566.jpg  \n",
            "  inflating: Dataset/000000391290.jpg  \n",
            "  inflating: Dataset/000000393226.jpg  \n",
            "  inflating: Dataset/000000395801.jpg  \n",
            "  inflating: Dataset/000000397351.jpg  \n",
            "  inflating: Dataset/000000408120.jpg  \n",
            "  inflating: Dataset/000000411938.jpg  \n",
            "  inflating: Dataset/000000414133.jpg  \n",
            "  inflating: Dataset/000000424162.jpg  \n",
            "  inflating: Dataset/000000426203.jpg  \n",
            "  inflating: Dataset/000000426268.jpg  \n",
            "  inflating: Dataset/000000426372.jpg  \n",
            "  inflating: Dataset/000000428454.jpg  \n",
            "  inflating: Dataset/000000436738.jpg  \n",
            "  inflating: Dataset/000000442456.jpg  \n",
            "  inflating: Dataset/000000442746.jpg  \n",
            "  inflating: Dataset/000000446651.jpg  \n",
            "  inflating: Dataset/000000454661.jpg  \n",
            "  inflating: Dataset/000000463037.jpg  \n",
            "  inflating: Dataset/000000475484.jpg  \n",
            "  inflating: Dataset/000000477227.jpg  \n",
            "  inflating: Dataset/000000492077.jpg  \n",
            "  inflating: Dataset/000000499768.jpg  \n",
            "  inflating: Dataset/000000499775.jpg  \n",
            "  inflating: Dataset/000000505942.jpg  \n",
            "  inflating: Dataset/000000507975.jpg  \n",
            "  inflating: Dataset/000000512564.jpg  \n",
            "  inflating: Dataset/000000514376.jpg  \n",
            "  inflating: Dataset/000000514586.jpg  \n",
            "  inflating: Dataset/000000526392.jpg  \n",
            "  inflating: Dataset/000000526728.jpg  \n",
            "  inflating: Dataset/000000530470.jpg  \n",
            "  inflating: Dataset/000000532481.jpg  \n",
            "  inflating: Dataset/000000534639.jpg  \n",
            "  inflating: Dataset/000000543043.jpg  \n",
            "  inflating: Dataset/000000545100.jpg  \n",
            "  inflating: Dataset/000000546823.jpg  \n",
            "  inflating: Dataset/000000553339.jpg  \n",
            "  inflating: Dataset/000000553511.jpg  \n",
            "  inflating: Dataset/000000555050.jpg  \n",
            "  inflating: Dataset/000000561679.jpg  \n",
            "  inflating: Dataset/000000563653.jpg  \n",
            "  inflating: Dataset/000000565391.jpg  \n",
            "  inflating: Dataset/000000565563.jpg  \n",
            "  inflating: Dataset/000000567640.jpg  \n",
            "  inflating: Dataset/000000577932.jpg  \n",
            "  inflating: Dataset/000000577976.jpg  \n",
            "  inflating: Dataset/000000579902.jpg  \n",
            "  inflating: Dataset/000000000139.jpg  \n",
            "  inflating: Dataset/000000004134.jpg  \n",
            "  inflating: Dataset/000000004495.jpg  \n",
            "  inflating: Dataset/000000008211.jpg  \n",
            "  inflating: Dataset/000000014439.jpg  \n",
            "  inflating: Dataset/000000016451.jpg  \n",
            "  inflating: Dataset/000000020553.jpg  \n",
            "  inflating: Dataset/000000022892.jpg  \n",
            "  inflating: Dataset/000000024610.jpg  \n",
            "  inflating: Dataset/000000025096.jpg  \n",
            "  inflating: Dataset/000000031248.jpg  \n",
            "  inflating: Dataset/000000032901.jpg  \n",
            "  inflating: Dataset/000000034873.jpg  \n",
            "  inflating: Dataset/000000039405.jpg  \n",
            "  inflating: Dataset/000000047112.jpg  \n",
            "  inflating: Dataset/000000051738.jpg  \n",
            "  inflating: Dataset/000000059598.jpg  \n",
            "  inflating: Dataset/000000061584.jpg  \n",
            "  inflating: Dataset/000000066038.jpg  \n",
            "  inflating: Dataset/000000074209.jpg  \n",
            "  inflating: Dataset/000000078170.jpg  \n",
            "  inflating: Dataset/000000079969.jpg  \n",
            "  inflating: Dataset/000000080340.jpg  \n",
            "  inflating: Dataset/000000082180.jpg  \n",
            "  inflating: Dataset/000000084362.jpg  \n",
            "  inflating: Dataset/000000084477.jpg  \n",
            "  inflating: Dataset/000000098853.jpg  \n",
            "  inflating: Dataset/000000100510.jpg  \n",
            "  inflating: Dataset/000000115245.jpg  \n",
            "  inflating: Dataset/000000123213.jpg  \n",
            "  inflating: Dataset/000000125129.jpg  \n",
            "  inflating: Dataset/000000127270.jpg  \n",
            "  inflating: Dataset/000000127394.jpg  \n",
            "  inflating: Dataset/000000129492.jpg  \n",
            "  inflating: Dataset/000000133244.jpg  \n",
            "  inflating: Dataset/000000139684.jpg  \n",
            "  inflating: Dataset/000000151820.jpg  \n",
            "  inflating: Dataset/000000159791.jpg  \n",
            "  inflating: Dataset/000000162092.jpg  \n",
            "  inflating: Dataset/000000163951.jpg  \n",
            "  inflating: Dataset/000000166166.jpg  \n",
            "  inflating: Dataset/000000166426.jpg  \n",
            "  inflating: Dataset/000000170474.jpg  \n",
            "  inflating: Dataset/000000172595.jpg  \n",
            "  inflating: Dataset/000000174231.jpg  \n",
            "  inflating: Dataset/000000180296.jpg  \n",
            "  inflating: Dataset/000000180487.jpg  \n",
            "  inflating: Dataset/000000188465.jpg  \n",
            "  inflating: Dataset/000000190648.jpg  \n",
            "  inflating: Dataset/000000190753.jpg  \n",
            "  inflating: Dataset/000000194724.jpg  \n",
            "  inflating: Dataset/000000194832.jpg  \n",
            "  inflating: Dataset/000000194875.jpg  \n",
            "  inflating: Dataset/000000196754.jpg  \n",
            "  inflating: Dataset/000000213224.jpg  \n",
            "  inflating: Dataset/000000213422.jpg  \n",
            "  inflating: Dataset/000000213445.jpg  \n",
            "  inflating: Dataset/000000215072.jpg  \n",
            "  inflating: Dataset/000000217285.jpg  \n",
            "  inflating: Dataset/000000221708.jpg  \n",
            "  inflating: Dataset/000000229659.jpg  \n",
            "  inflating: Dataset/000000229849.jpg  \n",
            "  inflating: Dataset/000000231580.jpg  \n",
            "  inflating: Dataset/000000231831.jpg  \n",
            "  inflating: Dataset/000000231879.jpg  \n",
            "  inflating: Dataset/000000235836.jpg  \n",
            "  inflating: Dataset/000000237984.jpg  \n",
            "  inflating: Dataset/000000239857.jpg  \n",
            "  inflating: Dataset/000000240023.jpg  \n",
            "  inflating: Dataset/000000241668.jpg  \n",
            "  inflating: Dataset/000000246308.jpg  \n",
            "  inflating: Dataset/000000248314.jpg  \n",
            "  inflating: Dataset/000000264441.jpg  \n",
            "  inflating: Dataset/000000268378.jpg  \n",
            "  inflating: Dataset/000000274687.jpg  \n",
            "  inflating: Dataset/000000277020.jpg  \n",
            "  inflating: Dataset/000000277051.jpg  \n",
            "  inflating: Dataset/000000297084.jpg  \n",
            "  inflating: Dataset/000000303653.jpg  \n",
            "  inflating: Dataset/000000311303.jpg  \n",
            "  inflating: Dataset/000000313454.jpg  \n",
            "  inflating: Dataset/000000319935.jpg  \n",
            "  inflating: Dataset/000000325838.jpg  \n",
            "  inflating: Dataset/000000326082.jpg  \n",
            "  inflating: Dataset/000000328238.jpg  \n",
            "  inflating: Dataset/000000336053.jpg  \n",
            "  inflating: Dataset/000000336356.jpg  \n",
            "  inflating: Dataset/000000338219.jpg  \n",
            "  inflating: Dataset/000000340175.jpg  \n",
            "  inflating: Dataset/000000344621.jpg  \n",
            "  inflating: Dataset/000000366884.jpg  \n",
            "  inflating: Dataset/000000367082.jpg  \n",
            "  inflating: Dataset/000000367095.jpg  \n",
            "  inflating: Dataset/000000368684.jpg  \n",
            "  inflating: Dataset/000000368900.jpg  \n",
            "  inflating: Dataset/000000374982.jpg  \n",
            "  inflating: Dataset/000000379332.jpg  \n",
            "  inflating: Dataset/000000383386.jpg  \n",
            "  inflating: Dataset/000000395343.jpg  \n",
            "  inflating: Dataset/000000395701.jpg  \n",
            "  inflating: Dataset/000000397354.jpg  \n",
            "  inflating: Dataset/000000405970.jpg  \n",
            "  inflating: Dataset/000000407614.jpg  \n",
            "  inflating: Dataset/000000411754.jpg  \n",
            "  inflating: Dataset/000000416104.jpg  \n",
            "  inflating: Dataset/000000419974.jpg  \n",
            "  inflating: Dataset/000000420069.jpg  \n",
            "  inflating: Dataset/000000428280.jpg  \n",
            "  inflating: Dataset/000000434459.jpg  \n",
            "  inflating: Dataset/000000434479.jpg  \n",
            "  inflating: Dataset/000000436617.jpg  \n",
            "  inflating: Dataset/000000438774.jpg  \n",
            "  inflating: Dataset/000000440475.jpg  \n",
            "  inflating: Dataset/000000446522.jpg  \n",
            "  inflating: Dataset/000000457078.jpg  \n",
            "  inflating: Dataset/000000461009.jpg  \n",
            "  inflating: Dataset/000000462904.jpg  \n",
            "  inflating: Dataset/000000467176.jpg  \n",
            "  inflating: Dataset/000000467315.jpg  \n",
            "  inflating: Dataset/000000473219.jpg  \n",
            "  inflating: Dataset/000000473237.jpg  \n",
            "  inflating: Dataset/000000481390.jpg  \n",
            "  inflating: Dataset/000000483667.jpg  \n",
            "  inflating: Dataset/000000485844.jpg  \n",
            "  inflating: Dataset/000000489764.jpg  \n",
            "  inflating: Dataset/000000491867.jpg  \n",
            "  inflating: Dataset/000000493905.jpg  \n",
            "  inflating: Dataset/000000500211.jpg  \n",
            "  inflating: Dataset/000000504074.jpg  \n",
            "  inflating: Dataset/000000520531.jpg  \n",
            "  inflating: Dataset/000000520659.jpg  \n",
            "  inflating: Dataset/000000530466.jpg  \n",
            "  inflating: Dataset/000000530975.jpg  \n",
            "  inflating: Dataset/000000532761.jpg  \n",
            "  inflating: Dataset/000000532901.jpg  \n",
            "  inflating: Dataset/000000536947.jpg  \n",
            "  inflating: Dataset/000000540928.jpg  \n",
            "  inflating: Dataset/000000540962.jpg  \n",
            "  inflating: Dataset/000000541123.jpg  \n",
            "  inflating: Dataset/000000543047.jpg  \n",
            "  inflating: Dataset/000000546964.jpg  \n",
            "  inflating: Dataset/000000559543.jpg  \n",
            "  inflating: Dataset/000000563470.jpg  \n",
            "  inflating: Dataset/000000571718.jpg  \n",
            "  inflating: Dataset/000000571857.jpg  \n",
            "  inflating: Dataset/000000575970.jpg  \n",
            "  inflating: Dataset/000000579970.jpg  \n",
            "  inflating: Dataset/000000014888.jpg  \n",
            "  inflating: Dataset/000000016010.jpg  \n",
            "  inflating: Dataset/000000023937.jpg  \n",
            "  inflating: Dataset/000000041635.jpg  \n",
            "  inflating: Dataset/000000047010.jpg  \n",
            "  inflating: Dataset/000000052565.jpg  \n",
            "  inflating: Dataset/000000060823.jpg  \n",
            "  inflating: Dataset/000000061171.jpg  \n",
            "  inflating: Dataset/000000087470.jpg  \n",
            "  inflating: Dataset/000000090062.jpg  \n",
            "  inflating: Dataset/000000105264.jpg  \n",
            "  inflating: Dataset/000000114907.jpg  \n",
            "  inflating: Dataset/000000118594.jpg  \n",
            "  inflating: Dataset/000000119038.jpg  \n",
            "  inflating: Dataset/000000124636.jpg  \n",
            "  inflating: Dataset/000000125072.jpg  \n",
            "  inflating: Dataset/000000125806.jpg  \n",
            "  inflating: Dataset/000000129416.jpg  \n",
            "  inflating: Dataset/000000133778.jpg  \n",
            "  inflating: Dataset/000000137576.jpg  \n",
            "  inflating: Dataset/000000140583.jpg  \n",
            "  inflating: Dataset/000000152740.jpg  \n",
            "  inflating: Dataset/000000166287.jpg  \n",
            "  inflating: Dataset/000000180383.jpg  \n",
            "  inflating: Dataset/000000193162.jpg  \n",
            "  inflating: Dataset/000000200667.jpg  \n",
            "  inflating: Dataset/000000206135.jpg  \n",
            "  inflating: Dataset/000000219440.jpg  \n",
            "  inflating: Dataset/000000221155.jpg  \n",
            "  inflating: Dataset/000000222863.jpg  \n",
            "  inflating: Dataset/000000223188.jpg  \n",
            "  inflating: Dataset/000000224093.jpg  \n",
            "  inflating: Dataset/000000229221.jpg  \n",
            "  inflating: Dataset/000000229858.jpg  \n",
            "  inflating: Dataset/000000233567.jpg  \n",
            "  inflating: Dataset/000000235857.jpg  \n",
            "  inflating: Dataset/000000240754.jpg  \n",
            "  inflating: Dataset/000000244411.jpg  \n",
            "  inflating: Dataset/000000247838.jpg  \n",
            "  inflating: Dataset/000000258911.jpg  \n",
            "  inflating: Dataset/000000267434.jpg  \n",
            "  inflating: Dataset/000000272212.jpg  \n",
            "  inflating: Dataset/000000276024.jpg  \n",
            "  inflating: Dataset/000000289393.jpg  \n",
            "  inflating: Dataset/000000298697.jpg  \n",
            "  inflating: Dataset/000000302165.jpg  \n",
            "  inflating: Dataset/000000306582.jpg  \n",
            "  inflating: Dataset/000000311392.jpg  \n",
            "  inflating: Dataset/000000314034.jpg  \n",
            "  inflating: Dataset/000000329447.jpg  \n",
            "  inflating: Dataset/000000332318.jpg  \n",
            "  inflating: Dataset/000000334555.jpg  \n",
            "  inflating: Dataset/000000347664.jpg  \n",
            "  inflating: Dataset/000000357081.jpg  \n",
            "  inflating: Dataset/000000361268.jpg  \n",
            "  inflating: Dataset/000000377486.jpg  \n",
            "  inflating: Dataset/000000387148.jpg  \n",
            "  inflating: Dataset/000000389451.jpg  \n",
            "  inflating: Dataset/000000396205.jpg  \n",
            "  inflating: Dataset/000000399764.jpg  \n",
            "  inflating: Dataset/000000402992.jpg  \n",
            "  inflating: Dataset/000000412887.jpg  \n",
            "  inflating: Dataset/000000415990.jpg  \n",
            "  inflating: Dataset/000000416758.jpg  \n",
            "  inflating: Dataset/000000416837.jpg  \n",
            "  inflating: Dataset/000000417085.jpg  \n",
            "  inflating: Dataset/000000418281.jpg  \n",
            "  inflating: Dataset/000000430073.jpg  \n",
            "  inflating: Dataset/000000435206.jpg  \n",
            "  inflating: Dataset/000000455219.jpg  \n",
            "  inflating: Dataset/000000459396.jpg  \n",
            "  inflating: Dataset/000000467776.jpg  \n",
            "  inflating: Dataset/000000492992.jpg  \n",
            "  inflating: Dataset/000000500663.jpg  \n",
            "  inflating: Dataset/000000512648.jpg  \n",
            "  inflating: Dataset/000000518213.jpg  \n",
            "  inflating: Dataset/000000526706.jpg  \n",
            "  inflating: Dataset/000000535094.jpg  \n",
            "  inflating: Dataset/000000545958.jpg  \n",
            "  inflating: Dataset/000000559099.jpg  \n",
            "  inflating: Dataset/000000572408.jpg  \n",
            "  inflating: Dataset/000000573626.jpg  \n",
            "  inflating: Dataset/000000580418.jpg  \n",
            "  inflating: Dataset/000000581100.jpg  \n",
            "  inflating: Dataset/000000008532.jpg  \n",
            "  inflating: Dataset/000000016598.jpg  \n",
            "  inflating: Dataset/000000032817.jpg  \n",
            "  inflating: Dataset/000000032861.jpg  \n",
            "  inflating: Dataset/000000032887.jpg  \n",
            "  inflating: Dataset/000000033005.jpg  \n",
            "  inflating: Dataset/000000033104.jpg  \n",
            "  inflating: Dataset/000000049259.jpg  \n",
            "  inflating: Dataset/000000057760.jpg  \n",
            "  inflating: Dataset/000000065736.jpg  \n",
            "  inflating: Dataset/000000065798.jpg  \n",
            "  inflating: Dataset/000000073946.jpg  \n",
            "  inflating: Dataset/000000074092.jpg  \n",
            "  inflating: Dataset/000000081988.jpg  \n",
            "  inflating: Dataset/000000082085.jpg  \n",
            "  inflating: Dataset/000000090284.jpg  \n",
            "  inflating: Dataset/000000098716.jpg  \n",
            "  inflating: Dataset/000000106757.jpg  \n",
            "  inflating: Dataset/000000106912.jpg  \n",
            "  inflating: Dataset/000000114884.jpg  \n",
            "  inflating: Dataset/000000122962.jpg  \n",
            "  inflating: Dataset/000000131138.jpg  \n",
            "  inflating: Dataset/000000131444.jpg  \n",
            "  inflating: Dataset/000000147729.jpg  \n",
            "  inflating: Dataset/000000180560.jpg  \n",
            "  inflating: Dataset/000000188439.jpg  \n",
            "  inflating: Dataset/000000188592.jpg  \n",
            "  inflating: Dataset/000000205105.jpg  \n",
            "  inflating: Dataset/000000213033.jpg  \n",
            "  inflating: Dataset/000000213035.jpg  \n",
            "  inflating: Dataset/000000213086.jpg  \n",
            "  inflating: Dataset/000000213171.jpg  \n",
            "  inflating: Dataset/000000221291.jpg  \n",
            "  inflating: Dataset/000000229553.jpg  \n",
            "  inflating: Dataset/000000229601.jpg  \n",
            "  inflating: Dataset/000000254016.jpg  \n",
            "  inflating: Dataset/000000254368.jpg  \n",
            "  inflating: Dataset/000000262487.jpg  \n",
            "  inflating: Dataset/000000270474.jpg  \n",
            "  inflating: Dataset/000000270677.jpg  \n",
            "  inflating: Dataset/000000295138.jpg  \n",
            "  inflating: Dataset/000000295316.jpg  \n",
            "  inflating: Dataset/000000303499.jpg  \n",
            "  inflating: Dataset/000000311394.jpg  \n",
            "  inflating: Dataset/000000319534.jpg  \n",
            "  inflating: Dataset/000000319721.jpg  \n",
            "  inflating: Dataset/000000327701.jpg  \n",
            "  inflating: Dataset/000000336209.jpg  \n",
            "  inflating: Dataset/000000336265.jpg  \n",
            "  inflating: Dataset/000000344268.jpg  \n",
            "  inflating: Dataset/000000352491.jpg  \n",
            "  inflating: Dataset/000000352582.jpg  \n",
            "  inflating: Dataset/000000352684.jpg  \n",
            "  inflating: Dataset/000000360661.jpg  \n",
            "  inflating: Dataset/000000368752.jpg  \n",
            "  inflating: Dataset/000000368961.jpg  \n",
            "  inflating: Dataset/000000369037.jpg  \n",
            "  inflating: Dataset/000000376900.jpg  \n",
            "  inflating: Dataset/000000377113.jpg  \n",
            "  inflating: Dataset/000000377239.jpg  \n",
            "  inflating: Dataset/000000385029.jpg  \n",
            "  inflating: Dataset/000000385190.jpg  \n",
            "  inflating: Dataset/000000393469.jpg  \n",
            "  inflating: Dataset/000000393569.jpg  \n",
            "  inflating: Dataset/000000401446.jpg  \n",
            "  inflating: Dataset/000000417911.jpg  \n",
            "  inflating: Dataset/000000418062.jpg  \n",
            "  inflating: Dataset/000000426241.jpg  \n",
            "  inflating: Dataset/000000426376.jpg  \n",
            "  inflating: Dataset/000000434204.jpg  \n",
            "  inflating: Dataset/000000434230.jpg  \n",
            "  inflating: Dataset/000000434247.jpg  \n",
            "  inflating: Dataset/000000434548.jpg  \n",
            "  inflating: Dataset/000000442463.jpg  \n",
            "  inflating: Dataset/000000442480.jpg  \n",
            "  inflating: Dataset/000000450686.jpg  \n",
            "  inflating: Dataset/000000458755.jpg  \n",
            "  inflating: Dataset/000000458992.jpg  \n",
            "  inflating: Dataset/000000459153.jpg  \n",
            "  inflating: Dataset/000000466986.jpg  \n",
            "  inflating: Dataset/000000475191.jpg  \n",
            "  inflating: Dataset/000000475387.jpg  \n",
            "  inflating: Dataset/000000508101.jpg  \n",
            "  inflating: Dataset/000000508312.jpg  \n",
            "  inflating: Dataset/000000516143.jpg  \n",
            "  inflating: Dataset/000000516173.jpg  \n",
            "  inflating: Dataset/000000516318.jpg  \n",
            "  inflating: Dataset/000000524456.jpg  \n",
            "  inflating: Dataset/000000532493.jpg  \n",
            "  inflating: Dataset/000000532530.jpg  \n",
            "  inflating: Dataset/000000532690.jpg  \n",
            "  inflating: Dataset/000000532855.jpg  \n",
            "  inflating: Dataset/000000540932.jpg  \n",
            "  inflating: Dataset/000000541055.jpg  \n",
            "  inflating: Dataset/000000549055.jpg  \n",
            "  inflating: Dataset/000000549220.jpg  \n",
            "  inflating: Dataset/000000008762.jpg  \n",
            "  inflating: Dataset/000000021839.jpg  \n",
            "  inflating: Dataset/000000026204.jpg  \n",
            "  inflating: Dataset/000000028993.jpg  \n",
            "  inflating: Dataset/000000039484.jpg  \n",
            "  inflating: Dataset/000000054967.jpg  \n",
            "  inflating: Dataset/000000057149.jpg  \n",
            "  inflating: Dataset/000000061268.jpg  \n",
            "  inflating: Dataset/000000069138.jpg  \n",
            "  inflating: Dataset/000000071877.jpg  \n",
            "  inflating: Dataset/000000076417.jpg  \n",
            "  inflating: Dataset/000000076547.jpg  \n",
            "  inflating: Dataset/000000088218.jpg  \n",
            "  inflating: Dataset/000000088432.jpg  \n",
            "  inflating: Dataset/000000099114.jpg  \n",
            "  inflating: Dataset/000000109441.jpg  \n",
            "  inflating: Dataset/000000110282.jpg  \n",
            "  inflating: Dataset/000000115946.jpg  \n",
            "  inflating: Dataset/000000119516.jpg  \n",
            "  inflating: Dataset/000000122166.jpg  \n",
            "  inflating: Dataset/000000125572.jpg  \n",
            "  inflating: Dataset/000000133819.jpg  \n",
            "  inflating: Dataset/000000142585.jpg  \n",
            "  inflating: Dataset/000000144706.jpg  \n",
            "  inflating: Dataset/000000148999.jpg  \n",
            "  inflating: Dataset/000000155443.jpg  \n",
            "  inflating: Dataset/000000155451.jpg  \n",
            "  inflating: Dataset/000000157365.jpg  \n",
            "  inflating: Dataset/000000162858.jpg  \n",
            "  inflating: Dataset/000000165039.jpg  \n",
            "  inflating: Dataset/000000166509.jpg  \n",
            "  inflating: Dataset/000000169169.jpg  \n",
            "  inflating: Dataset/000000171382.jpg  \n",
            "  inflating: Dataset/000000175438.jpg  \n",
            "  inflating: Dataset/000000178982.jpg  \n",
            "  inflating: Dataset/000000184400.jpg  \n",
            "  inflating: Dataset/000000193717.jpg  \n",
            "  inflating: Dataset/000000212573.jpg  \n",
            "  inflating: Dataset/000000213593.jpg  \n",
            "  inflating: Dataset/000000215723.jpg  \n",
            "  inflating: Dataset/000000216419.jpg  \n",
            "  inflating: Dataset/000000226417.jpg  \n",
            "  inflating: Dataset/000000228942.jpg  \n",
            "  inflating: Dataset/000000230450.jpg  \n",
            "  inflating: Dataset/000000242411.jpg  \n",
            "  inflating: Dataset/000000244379.jpg  \n",
            "  inflating: Dataset/000000245102.jpg  \n",
            "  inflating: Dataset/000000252219.jpg  \n",
            "  inflating: Dataset/000000253835.jpg  \n",
            "  inflating: Dataset/000000254814.jpg  \n",
            "  inflating: Dataset/000000269682.jpg  \n",
            "  inflating: Dataset/000000269942.jpg  \n",
            "  inflating: Dataset/000000274272.jpg  \n",
            "  inflating: Dataset/000000275727.jpg  \n",
            "  inflating: Dataset/000000280710.jpg  \n",
            "  inflating: Dataset/000000281179.jpg  \n",
            "  inflating: Dataset/000000284445.jpg  \n",
            "  inflating: Dataset/000000284762.jpg  \n",
            "  inflating: Dataset/000000295809.jpg  \n",
            "  inflating: Dataset/000000306893.jpg  \n",
            "  inflating: Dataset/000000307074.jpg  \n",
            "  inflating: Dataset/000000307598.jpg  \n",
            "  inflating: Dataset/000000311883.jpg  \n",
            "  inflating: Dataset/000000315187.jpg  \n",
            "  inflating: Dataset/000000319369.jpg  \n",
            "  inflating: Dataset/000000320232.jpg  \n",
            "  inflating: Dataset/000000323751.jpg  \n",
            "  inflating: Dataset/000000338560.jpg  \n",
            "  inflating: Dataset/000000338624.jpg  \n",
            "  inflating: Dataset/000000350023.jpg  \n",
            "  inflating: Dataset/000000351559.jpg  \n",
            "  inflating: Dataset/000000356169.jpg  \n",
            "  inflating: Dataset/000000361103.jpg  \n",
            "  inflating: Dataset/000000365745.jpg  \n",
            "  inflating: Dataset/000000373353.jpg  \n",
            "  inflating: Dataset/000000377946.jpg  \n",
            "  inflating: Dataset/000000380706.jpg  \n",
            "  inflating: Dataset/000000410712.jpg  \n",
            "  inflating: Dataset/000000412894.jpg  \n",
            "  inflating: Dataset/000000418696.jpg  \n",
            "  inflating: Dataset/000000423229.jpg  \n",
            "  inflating: Dataset/000000423798.jpg  \n",
            "  inflating: Dataset/000000430871.jpg  \n",
            "  inflating: Dataset/000000430875.jpg  \n",
            "  inflating: Dataset/000000431876.jpg  \n",
            "  inflating: Dataset/000000433774.jpg  \n",
            "  inflating: Dataset/000000438017.jpg  \n",
            "  inflating: Dataset/000000440617.jpg  \n",
            "  inflating: Dataset/000000441553.jpg  \n",
            "  inflating: Dataset/000000449198.jpg  \n",
            "  inflating: Dataset/000000453841.jpg  \n",
            "  inflating: Dataset/000000458325.jpg  \n",
            "  inflating: Dataset/000000460147.jpg  \n",
            "  inflating: Dataset/000000467511.jpg  \n",
            "  inflating: Dataset/000000479030.jpg  \n",
            "  inflating: Dataset/000000480944.jpg  \n",
            "  inflating: Dataset/000000482585.jpg  \n",
            "  inflating: Dataset/000000491213.jpg  \n",
            "  inflating: Dataset/000000496722.jpg  \n",
            "  inflating: Dataset/000000496854.jpg  \n",
            "  inflating: Dataset/000000500826.jpg  \n",
            "  inflating: Dataset/000000501023.jpg  \n",
            "  inflating: Dataset/000000503841.jpg  \n",
            "  inflating: Dataset/000000516708.jpg  \n",
            "  inflating: Dataset/000000520009.jpg  \n",
            "  inflating: Dataset/000000531134.jpg  \n",
            "  inflating: Dataset/000000538458.jpg  \n",
            "  inflating: Dataset/000000542856.jpg  \n",
            "  inflating: Dataset/000000544605.jpg  \n",
            "  inflating: Dataset/000000565012.jpg  \n",
            "  inflating: Dataset/000000565778.jpg  \n",
            "  inflating: Dataset/000000569030.jpg  \n",
            "  inflating: Dataset/000000571943.jpg  \n",
            "  inflating: Dataset/000000572555.jpg  \n",
            "  inflating: Dataset/000000575243.jpg  \n",
            "  inflating: Dataset/000000575372.jpg  \n",
            "  inflating: Dataset/000000001761.jpg  \n",
            "  inflating: Dataset/000000005477.jpg  \n",
            "  inflating: Dataset/000000013348.jpg  \n",
            "  inflating: Dataset/000000022396.jpg  \n",
            "  inflating: Dataset/000000033114.jpg  \n",
            "  inflating: Dataset/000000044652.jpg  \n",
            "  inflating: Dataset/000000052017.jpg  \n",
            "  inflating: Dataset/000000052412.jpg  \n",
            "  inflating: Dataset/000000071711.jpg  \n",
            "  inflating: Dataset/000000084752.jpg  \n",
            "  inflating: Dataset/000000090631.jpg  \n",
            "  inflating: Dataset/000000096549.jpg  \n",
            "  inflating: Dataset/000000098520.jpg  \n",
            "  inflating: Dataset/000000099054.jpg  \n",
            "  inflating: Dataset/000000101787.jpg  \n",
            "  inflating: Dataset/000000109900.jpg  \n",
            "  inflating: Dataset/000000110359.jpg  \n",
            "  inflating: Dataset/000000110721.jpg  \n",
            "  inflating: Dataset/000000131386.jpg  \n",
            "  inflating: Dataset/000000134886.jpg  \n",
            "  inflating: Dataset/000000135673.jpg  \n",
            "  inflating: Dataset/000000137950.jpg  \n",
            "  inflating: Dataset/000000139871.jpg  \n",
            "  inflating: Dataset/000000144114.jpg  \n",
            "  inflating: Dataset/000000161044.jpg  \n",
            "  inflating: Dataset/000000163746.jpg  \n",
            "  inflating: Dataset/000000167540.jpg  \n",
            "  inflating: Dataset/000000183500.jpg  \n",
            "  inflating: Dataset/000000187745.jpg  \n",
            "  inflating: Dataset/000000189828.jpg  \n",
            "  inflating: Dataset/000000190676.jpg  \n",
            "  inflating: Dataset/000000196185.jpg  \n",
            "  inflating: Dataset/000000199977.jpg  \n",
            "  inflating: Dataset/000000205401.jpg  \n",
            "  inflating: Dataset/000000208208.jpg  \n",
            "  inflating: Dataset/000000208901.jpg  \n",
            "  inflating: Dataset/000000214205.jpg  \n",
            "  inflating: Dataset/000000217060.jpg  \n",
            "  inflating: Dataset/000000229747.jpg  \n",
            "  inflating: Dataset/000000272049.jpg  \n",
            "  inflating: Dataset/000000272136.jpg  \n",
            "  inflating: Dataset/000000281693.jpg  \n",
            "  inflating: Dataset/000000293324.jpg  \n",
            "  inflating: Dataset/000000300659.jpg  \n",
            "  inflating: Dataset/000000323709.jpg  \n",
            "  inflating: Dataset/000000336309.jpg  \n",
            "  inflating: Dataset/000000338325.jpg  \n",
            "  inflating: Dataset/000000348881.jpg  \n",
            "  inflating: Dataset/000000379453.jpg  \n",
            "  inflating: Dataset/000000381639.jpg  \n",
            "  inflating: Dataset/000000383621.jpg  \n",
            "  inflating: Dataset/000000384350.jpg  \n",
            "  inflating: Dataset/000000388258.jpg  \n",
            "  inflating: Dataset/000000392481.jpg  \n",
            "  inflating: Dataset/000000396903.jpg  \n",
            "  inflating: Dataset/000000400922.jpg  \n",
            "  inflating: Dataset/000000404128.jpg  \n",
            "  inflating: Dataset/000000404479.jpg  \n",
            "  inflating: Dataset/000000408112.jpg  \n",
            "  inflating: Dataset/000000410221.jpg  \n",
            "  inflating: Dataset/000000424776.jpg  \n",
            "  inflating: Dataset/000000425221.jpg  \n",
            "  inflating: Dataset/000000449996.jpg  \n",
            "  inflating: Dataset/000000452122.jpg  \n",
            "  inflating: Dataset/000000456865.jpg  \n",
            "  inflating: Dataset/000000459467.jpg  \n",
            "  inflating: Dataset/000000469174.jpg  \n",
            "  inflating: Dataset/000000477441.jpg  \n",
            "  inflating: Dataset/000000478862.jpg  \n",
            "  inflating: Dataset/000000479912.jpg  \n",
            "  inflating: Dataset/000000485237.jpg  \n",
            "  inflating: Dataset/000000485802.jpg  \n",
            "  inflating: Dataset/000000488270.jpg  \n",
            "  inflating: Dataset/000000490413.jpg  \n",
            "  inflating: Dataset/000000493286.jpg  \n",
            "  inflating: Dataset/000000495054.jpg  \n",
            "  inflating: Dataset/000000497568.jpg  \n",
            "  inflating: Dataset/000000500049.jpg  \n",
            "  inflating: Dataset/000000502347.jpg  \n",
            "  inflating: Dataset/000000502599.jpg  \n",
            "  inflating: Dataset/000000504000.jpg  \n",
            "  inflating: Dataset/000000513580.jpg  \n",
            "  inflating: Dataset/000000517523.jpg  \n",
            "  inflating: Dataset/000000520324.jpg  \n",
            "  inflating: Dataset/000000524850.jpg  \n",
            "  inflating: Dataset/000000525322.jpg  \n",
            "  inflating: Dataset/000000543528.jpg  \n",
            "  inflating: Dataset/000000545407.jpg  \n",
            "  inflating: Dataset/000000553094.jpg  \n",
            "  inflating: Dataset/000000567432.jpg  \n",
            "  inflating: Dataset/000000575205.jpg  \n",
            "  inflating: Dataset/000000579158.jpg  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xt8h3pjV-MtO",
        "outputId": "1a616bf6-641d-4484-fefb-0b812d6f0d64"
      },
      "source": [
        "#getting test data\n",
        "%cd /content/drive/MyDrive/detectron2_500/\n",
        "\n",
        "!gdown --id 1WJxlhhb-fYf6YxXPkuWbxeuFF1kyn4QR\n",
        "\n",
        "!gdown --id 1pay0cn54PgEniz3Sctv01aKoSODmL_36"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/detectron2_500\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1WJxlhhb-fYf6YxXPkuWbxeuFF1kyn4QR\n",
            "To: /content/drive/My Drive/detectron2_500/main.json\n",
            "100% 386k/386k [00:00<00:00, 56.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1pay0cn54PgEniz3Sctv01aKoSODmL_36\n",
            "To: /content/drive/My Drive/detectron2_500/test_data.zip\n",
            "36.4MB [00:00, 59.2MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmDQvcb9-XC-",
        "outputId": "bd912a50-7a23-413b-a783-11e5e31da160"
      },
      "source": [
        "!unzip /content/drive/MyDrive/detectron2_500/test_data.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/detectron2_500/test_data.zip\n",
            "   creating: test_data/\n",
            "  inflating: test_data/COCO_val2014_000000451623.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000500826.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000255036.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000377832.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000279596.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000009274.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000082921.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000549943.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000287725.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000410712.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000230450.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000377946.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000525371.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000312341.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000263177.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000320482.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000132143.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000025550.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000173080.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000279621.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000386032.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000427091.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000304240.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000435312.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000488278.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000064332.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000320324.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000172851.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000541631.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000502599.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000246717.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000465735.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000295765.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000287559.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000058304.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000230232.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000011081.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000002881.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000473935.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000279343.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000490294.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000486233.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000537427.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000488270.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000052017.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000181386.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000033731.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000426840.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000254917.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000424776.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000418606.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000396051.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000525077.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000160529.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000490225.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000543528.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000027390.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000490275.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000244487.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000381709.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000117543.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000092963.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000156445.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000078580.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000254732.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000084752.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000355057.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000465664.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000144114.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000144122.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000189203.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000535322.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000232223.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000000632.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000066172.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000215815.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000180869.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000451214.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000082551.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000551650.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000137950.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000311954.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000156278.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000000623.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000486114.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000101088.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000332502.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000287366.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000180953.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000098927.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000099054.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000090732.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000031446.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000139917.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000533123.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000459502.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000303731.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000533129.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000574069.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000262940.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000082518.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000303685.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000107087.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000164453.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000229960.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000393814.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000213599.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000320078.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000491867.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000065883.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000451120.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000573784.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000016958.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000533069.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000148034.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000475723.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000033345.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000197219.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000508470.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000041550.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000492110.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000492107.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000221753.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000303713.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000368980.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000434511.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000131416.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000090429.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000385359.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000491856.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000147787.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000074058.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000123213.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000524601.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000516415.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000565582.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000541010.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000565575.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000229713.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000041279.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000287033.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000196928.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000287035.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000450885.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000483667.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000196924.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000516416.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000434787.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000115006.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000246105.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000188798.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000229688.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000526706.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000555337.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000115077.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000246061.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000434479.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000405811.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000555357.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000149832.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000278829.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000459050.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000231758.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000485758.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000235857.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000153973.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000397640.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000131390.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000336182.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000389451.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000076155.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000033066.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000524595.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000205108.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000137576.jpg  \n",
            "  inflating: test_data/000000287527.jpg  \n",
            "  inflating: test_data/000000000785.jpg  \n",
            "  inflating: test_data/000000361238.jpg  \n",
            "  inflating: test_data/000000492284.jpg  \n",
            "  inflating: test_data/000000271116.jpg  \n",
            "  inflating: test_data/000000099114.jpg  \n",
            "  inflating: test_data/000000369442.jpg  \n",
            "  inflating: test_data/000000377635.jpg  \n",
            "  inflating: test_data/000000492282.jpg  \n",
            "  inflating: test_data/000000353051.jpg  \n",
            "  inflating: test_data/000000295713.jpg  \n",
            "  inflating: test_data/000000336658.jpg  \n",
            "  inflating: test_data/000000090891.jpg  \n",
            "  inflating: test_data/000000500477.jpg  \n",
            "  inflating: test_data/000000164602.jpg  \n",
            "  inflating: test_data/000000197388.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000219440.jpg  \n",
            "  inflating: test_data/000000082688.jpg  \n",
            "  inflating: test_data/000000500478.jpg  \n",
            "  inflating: test_data/000000082696.jpg  \n",
            "  inflating: test_data/000000082715.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000246064.jpg  \n",
            "  inflating: test_data/000000303893.jpg  \n",
            "  inflating: test_data/COCO_val2014_000000217393.jpg  \n",
            "  inflating: test_data/000000353027.jpg  \n",
            "  inflating: test_data/000000040083.jpg  \n",
            "  inflating: test_data/000000457884.jpg  \n",
            "  inflating: test_data/000000226417.jpg  \n",
            "  inflating: test_data/000000377946.jpg  \n",
            "  inflating: test_data/000000564336.jpg  \n",
            "  inflating: test_data/000000087144.jpg  \n",
            "  inflating: test_data/000000410712.jpg  \n",
            "  inflating: test_data/000000289938.jpg  \n",
            "  inflating: test_data/000000179265.jpg  \n",
            "  inflating: test_data/000000119911.jpg  \n",
            "  inflating: test_data/000000303863.jpg  \n",
            "  inflating: test_data/000000369751.jpg  \n",
            "  inflating: test_data/000000496722.jpg  \n",
            "  inflating: test_data/000000511076.jpg  \n",
            "  inflating: test_data/000000369812.jpg  \n",
            "  inflating: test_data/000000232538.jpg  \n",
            "  inflating: test_data/000000468124.jpg  \n",
            "  inflating: test_data/000000228436.jpg  \n",
            "  inflating: test_data/000000281687.jpg  \n",
            "  inflating: test_data/000000416885.jpg  \n",
            "  inflating: test_data/000000382111.jpg  \n",
            "  inflating: test_data/000000513181.jpg  \n",
            "  inflating: test_data/000000441468.jpg  \n",
            "  inflating: test_data/000000365642.jpg  \n",
            "  inflating: test_data/000000146498.jpg  \n",
            "  inflating: test_data/000000027768.jpg  \n",
            "  inflating: test_data/000000142472.jpg  \n",
            "  inflating: test_data/000000042070.jpg  \n",
            "  inflating: test_data/000000038048.jpg  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWQ8qc5VIqKy",
        "outputId": "ee439a72-2f6f-401e-cf95-ad5202ef65ed"
      },
      "source": [
        "%cd /content/drive/MyDrive/detectron2_500/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/detectron2_500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXc0eBT6EM-_",
        "outputId": "7b57d4a4-e781-4340-a66c-3861684b9fe2"
      },
      "source": [
        "# install dependencies: (use cu101 because colab has CUDA 10.1)\n",
        "!pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html \n",
        "!pip install cython pyyaml==5.1\n",
        "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version\n",
        "# opencv is pre-installed on colab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/cu101/torch_stable.html\n",
            "Collecting torch==1.5\n",
            "  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.0%2Bcu101-cp37-cp37m-linux_x86_64.whl (703.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 703.8 MB 23 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.6\n",
            "  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.0%2Bcu101-cp37-cp37m-linux_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 29.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.5) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.5) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.6) (7.1.2)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.10.0+cu102\n",
            "    Uninstalling torchvision-0.10.0+cu102:\n",
            "      Successfully uninstalled torchvision-0.10.0+cu102\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.5.0+cu101 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.5.0+cu101 torchvision-0.6.0+cu101\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (0.29.24)\n",
            "Collecting pyyaml==5.1\n",
            "  Downloading PyYAML-5.1.tar.gz (274 kB)\n",
            "\u001b[K     |████████████████████████████████| 274 kB 5.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.1-cp37-cp37m-linux_x86_64.whl size=44092 sha256=92594dcc1c124813ab7eb003c7aa8486d7d6d973cc428ae7307563e72d67f766\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/f5/10/d00a2bd30928b972790053b5de0c703ca87324f3fead0f2fd9\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: pyyaml\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed pyyaml-5.1\n",
            "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-a6zuof21\n",
            "  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-a6zuof21\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (57.4.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (0.29.24)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.19.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools==2.0) (1.15.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp37-cp37m-linux_x86_64.whl size=263923 sha256=5621ac4d63f1ff5fe5d2e6c96ba71750cf5665a07a8905b0f6cca968a28bfd68\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jk2f71oq/wheels/e2/6b/1d/344ac773c7495ea0b85eb228bc66daec7400a143a92d36b7b1\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: pycocotools\n",
            "  Attempting uninstall: pycocotools\n",
            "    Found existing installation: pycocotools 2.0.2\n",
            "    Uninstalling pycocotools-2.0.2:\n",
            "      Successfully uninstalled pycocotools-2.0.2\n",
            "Successfully installed pycocotools-2.0\n",
            "1.5.0+cu101 True\n",
            "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Copyright (C) 2017 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXMyGSVdMNET",
        "outputId": "5dd225a8-c453-4eae-84d3-f5247767c0fd"
      },
      "source": [
        "!pip install torch==1.9.0 torchvision==0.4.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.9.0\n",
            "  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 2.8 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.4.1\n",
            "  Downloading torchvision-0.4.1-cp37-cp37m-manylinux1_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 19.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.4.1) (1.19.5)\n",
            "INFO: pip is looking at multiple versions of <Python from Requires-Python> to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Cannot install torch==1.9.0 and torchvision==0.4.1 because these package versions have conflicting dependencies.\u001b[0m\n",
            "\n",
            "The conflict is caused by:\n",
            "    The user requested torch==1.9.0\n",
            "    torchvision 0.4.1 depends on torch==1.3.0\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
            "\n",
            "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/user_guide/#fixing-conflicting-dependencies\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFSjj8WrFdBR",
        "outputId": "4109d470-3220-4127-a041-ef3b06a666ed"
      },
      "source": [
        "!pip install detectron2==0.1.3 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html\n",
            "Collecting detectron2==0.1.3\n",
            "  Downloading https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/detectron2-0.1.3%2Bcu101-cp37-cp37m-linux_x86_64.whl (6.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.2 MB 785 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (0.8.9)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (4.62.0)\n",
            "Collecting fvcore>=0.1.1\n",
            "  Downloading fvcore-0.1.5.post20210825.tar.gz (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 2.9 MB/s \n",
            "\u001b[?25hCollecting mock\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (1.1.0)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (0.16.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (1.3.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (2.6.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (3.2.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore>=0.1.1->detectron2==0.1.3) (1.19.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore>=0.1.1->detectron2==0.1.3) (5.1)\n",
            "Collecting iopath>=0.1.7\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.1.3) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.1.3) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.1.3) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.1.3) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->detectron2==0.1.3) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (3.3.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (2.23.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (1.39.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (0.4.5)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (0.37.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (1.34.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (0.12.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (1.8.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.1.3) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->detectron2==0.1.3) (4.6.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (2021.5.30)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.1.3) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->detectron2==0.1.3) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->detectron2==0.1.3) (3.7.4.3)\n",
            "Building wheels for collected packages: fvcore\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20210825-py3-none-any.whl size=60661 sha256=f02820364461027e4d64617105d05b4ff0748eec76d57942c1e9ceaa963b35e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/53/c4/f8/c4cb07f135845218b019b4a55d8a0470a0f21ee13f8dcd16be\n",
            "Successfully built fvcore\n",
            "Installing collected packages: portalocker, yacs, iopath, mock, fvcore, detectron2\n",
            "Successfully installed detectron2-0.1.3+cu101 fvcore-0.1.5.post20210825 iopath-0.1.9 mock-4.0.3 portalocker-2.3.2 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6w3eMNagForN",
        "outputId": "a39aa230-2905-4bb7-b3f1-db1516607194"
      },
      "source": [
        "# check pytorch installation: \n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "#assert torch.__version__.startswith(\"1.9\")   # please manually install torch 1.9 if Colab changes its default version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.5.0+cu101 True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZ-xLH3OGe92"
      },
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liqMNPZ7Gu-u"
      },
      "source": [
        "#if your dataset is in COCO format, this cell can be replaced by the following three lines:\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "register_coco_instances(\"my_dataset_train2\", {}, \"/content/drive/MyDrive/detectron2_500/train.json\", \"/content/drive/MyDrive/detectron2_500/Dataset\")\n",
        "register_coco_instances(\"my_dataset_val2\", {}, \"/content/drive/MyDrive/detectron2_500/test.json\", \"/content/drive/MyDrive/detectron2_500/test_data\")\n",
        "register_coco_instances(\"my_dataset_test2\", {}, \"/content/drive/MyDrive/detectron2_500/test.json\", \"/content/drive/MyDrive/detectron2_500/test_data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E00Y7CxmCrY1"
      },
      "source": [
        "#We are importing our own Trainer Module here to use the COCO validation evaluation during training. Otherwise no validation eval occurs.\n",
        "\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.evaluation import COCOEvaluator\n",
        "from detectron2.data import transforms as T\n",
        "\n",
        "from detectron2.data import (\n",
        "    MetadataCatalog,\n",
        "    build_detection_test_loader,\n",
        "    build_detection_train_loader,\n",
        ")\n",
        "\n",
        "from detectron2.data import DatasetMapper   # the default mapper"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF8DmJX9Crg5"
      },
      "source": [
        "class CocoTrainer(DefaultTrainer):\n",
        "\n",
        "  @classmethod\n",
        "  def build_train_loader(cls, cfg):\n",
        "    return build_detection_train_loader(\n",
        "        cfg, \n",
        "        mapper=DatasetMapper(\n",
        "            cfg, \n",
        "            is_train=True, \n",
        "            augmentations=[\n",
        "                           T.Resize((1024, 1024)), \n",
        "                           T.HFlipTransform(1024)\n",
        "                           ]\n",
        "        )\n",
        "    )\n",
        "\n",
        "  @classmethod\n",
        "  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "    if output_folder is None:\n",
        "        os.makedirs(\"coco_eval\", exist_ok=True)\n",
        "        output_folder = \"coco_eval\"\n",
        "\n",
        "    return COCOEvaluator(dataset_name, cfg, False, output_folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sP3GDy82EwRx",
        "outputId": "26ff8881-c481-4b02-e5dc-29fd97e19830"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Sep  2 05:54:58 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P8    35W / 149W |      3MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6y2f6x5HzEI",
        "outputId": "3b9fc037-b5a1-4e3e-ae7d-1845679352b9"
      },
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "import os\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.OUTPUT_DIR = \"/content/drive/MyDrive/detectron2_500/output_detect\"\n",
        "cfg.SOLVER.CHECKPOINT_PERIOD = 1000\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"Misc/mask_rcnn_R_50_FPN_3x_dconv_c3-c5.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"my_dataset_train2\",)\n",
        "cfg.DATASETS.TEST = (\"my_dataset_val2\",)\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"Misc/mask_rcnn_R_50_FPN_3x_dconv_c3-c5.yaml\")  # Let training initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
        "cfg.SOLVER.MAX_ITER = 58000    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
        "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 6  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
        "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg) \n",
        "trainer.resume_or_load(resume=True)\n",
        "trainer.train()\n",
        "#trainer.test()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[09/02 06:01:43 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): DeformBottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(128, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): DeformBottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(128, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): DeformBottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(128, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): DeformBottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(128, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): DeformBottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=256, out_channels=256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): DeformBottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=256, out_channels=256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): DeformBottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=256, out_channels=256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): DeformBottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=256, out_channels=256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): DeformBottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=256, out_channels=256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): DeformBottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=256, out_channels=256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): DeformBottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): DeformBottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): DeformBottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[09/02 06:01:43 d2.data.datasets.coco]: \u001b[0mLoaded 689 images in COCO format from /content/drive/MyDrive/detectron2_500/train.json\n",
            "\u001b[32m[09/02 06:01:43 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 689 images left.\n",
            "\u001b[32m[09/02 06:01:44 d2.data.build]: \u001b[0mDistribution of instances among all 6 categories:\n",
            "\u001b[36m|  category  | #instances   |  category  | #instances   |   category    | #instances   |\n",
            "|:----------:|:-------------|:----------:|:-------------|:-------------:|:-------------|\n",
            "| aeroplane  | 143          |    car     | 500          |     chair     | 500          |\n",
            "|    cow     | 372          |   person   | 500          | traffic_light | 499          |\n",
            "|            |              |            |              |               |              |\n",
            "|   total    | 2514         |            |              |               |              |\u001b[0m\n",
            "\u001b[32m[09/02 06:01:44 d2.data.common]: \u001b[0mSerializing 689 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[09/02 06:01:44 d2.data.common]: \u001b[0mSerialized dataset takes 1.35 MiB\n",
            "\u001b[32m[09/02 06:01:44 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[09/02 06:01:44 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[09/02 06:01:52 d2.engine.train_loop]: \u001b[0mStarting training from iteration 50000\n",
            "\u001b[32m[09/02 06:02:29 d2.utils.events]: \u001b[0m eta: 4:07:06  iter: 50019  total_loss: 0.222  loss_cls: 0.037  loss_box_reg: 0.095  loss_mask: 0.112  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8573  data_time: 0.0322  lr: 0.000250  max_mem: 2592M\n",
            "\u001b[32m[09/02 06:03:07 d2.utils.events]: \u001b[0m eta: 4:10:51  iter: 50039  total_loss: 0.261  loss_cls: 0.028  loss_box_reg: 0.088  loss_mask: 0.124  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8819  data_time: 0.0080  lr: 0.000250  max_mem: 2677M\n",
            "\u001b[32m[09/02 06:03:43 d2.utils.events]: \u001b[0m eta: 4:05:38  iter: 50059  total_loss: 0.233  loss_cls: 0.022  loss_box_reg: 0.093  loss_mask: 0.111  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8547  data_time: 0.0079  lr: 0.000250  max_mem: 2677M\n",
            "\u001b[32m[09/02 06:04:19 d2.utils.events]: \u001b[0m eta: 4:01:18  iter: 50079  total_loss: 0.223  loss_cls: 0.028  loss_box_reg: 0.082  loss_mask: 0.113  loss_rpn_cls: 0.000  loss_rpn_loc: 0.013  time: 1.8404  data_time: 0.0076  lr: 0.000250  max_mem: 2694M\n",
            "\u001b[32m[09/02 06:04:54 d2.utils.events]: \u001b[0m eta: 3:59:06  iter: 50099  total_loss: 0.238  loss_cls: 0.022  loss_box_reg: 0.084  loss_mask: 0.124  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8237  data_time: 0.0077  lr: 0.000250  max_mem: 2694M\n",
            "\u001b[32m[09/02 06:05:33 d2.utils.events]: \u001b[0m eta: 4:02:03  iter: 50119  total_loss: 0.255  loss_cls: 0.028  loss_box_reg: 0.082  loss_mask: 0.113  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8418  data_time: 0.0086  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:06:10 d2.utils.events]: \u001b[0m eta: 4:01:09  iter: 50139  total_loss: 0.246  loss_cls: 0.030  loss_box_reg: 0.096  loss_mask: 0.117  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  time: 1.8416  data_time: 0.0081  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:06:44 d2.utils.events]: \u001b[0m eta: 3:58:31  iter: 50159  total_loss: 0.252  loss_cls: 0.030  loss_box_reg: 0.100  loss_mask: 0.119  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 1.8257  data_time: 0.0086  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:07:22 d2.utils.events]: \u001b[0m eta: 3:59:12  iter: 50179  total_loss: 0.279  loss_cls: 0.036  loss_box_reg: 0.096  loss_mask: 0.132  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8338  data_time: 0.0073  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:07:57 d2.utils.events]: \u001b[0m eta: 3:57:18  iter: 50199  total_loss: 0.290  loss_cls: 0.024  loss_box_reg: 0.105  loss_mask: 0.129  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8256  data_time: 0.0088  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:08:34 d2.utils.events]: \u001b[0m eta: 3:56:42  iter: 50219  total_loss: 0.230  loss_cls: 0.023  loss_box_reg: 0.097  loss_mask: 0.111  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  time: 1.8257  data_time: 0.0086  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:09:11 d2.utils.events]: \u001b[0m eta: 3:56:04  iter: 50239  total_loss: 0.257  loss_cls: 0.030  loss_box_reg: 0.087  loss_mask: 0.121  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 1.8264  data_time: 0.0086  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:09:47 d2.utils.events]: \u001b[0m eta: 3:55:27  iter: 50259  total_loss: 0.240  loss_cls: 0.024  loss_box_reg: 0.103  loss_mask: 0.109  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8251  data_time: 0.0086  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:10:23 d2.utils.events]: \u001b[0m eta: 3:54:38  iter: 50279  total_loss: 0.264  loss_cls: 0.025  loss_box_reg: 0.097  loss_mask: 0.115  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8245  data_time: 0.0084  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:10:59 d2.utils.events]: \u001b[0m eta: 3:54:01  iter: 50299  total_loss: 0.237  loss_cls: 0.029  loss_box_reg: 0.086  loss_mask: 0.124  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8219  data_time: 0.0081  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:11:35 d2.utils.events]: \u001b[0m eta: 3:53:31  iter: 50319  total_loss: 0.274  loss_cls: 0.024  loss_box_reg: 0.116  loss_mask: 0.116  loss_rpn_cls: 0.000  loss_rpn_loc: 0.011  time: 1.8222  data_time: 0.0085  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:12:13 d2.utils.events]: \u001b[0m eta: 3:52:59  iter: 50339  total_loss: 0.184  loss_cls: 0.017  loss_box_reg: 0.064  loss_mask: 0.105  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8250  data_time: 0.0087  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:12:48 d2.utils.events]: \u001b[0m eta: 3:52:12  iter: 50359  total_loss: 0.297  loss_cls: 0.032  loss_box_reg: 0.098  loss_mask: 0.135  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8222  data_time: 0.0079  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:13:23 d2.utils.events]: \u001b[0m eta: 3:51:17  iter: 50379  total_loss: 0.291  loss_cls: 0.020  loss_box_reg: 0.114  loss_mask: 0.146  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 1.8175  data_time: 0.0095  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:13:58 d2.utils.events]: \u001b[0m eta: 3:50:23  iter: 50399  total_loss: 0.304  loss_cls: 0.037  loss_box_reg: 0.122  loss_mask: 0.138  loss_rpn_cls: 0.001  loss_rpn_loc: 0.016  time: 1.8141  data_time: 0.0090  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:14:35 d2.utils.events]: \u001b[0m eta: 3:49:43  iter: 50419  total_loss: 0.234  loss_cls: 0.027  loss_box_reg: 0.089  loss_mask: 0.115  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8153  data_time: 0.0098  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:15:12 d2.utils.events]: \u001b[0m eta: 3:49:28  iter: 50439  total_loss: 0.257  loss_cls: 0.027  loss_box_reg: 0.096  loss_mask: 0.117  loss_rpn_cls: 0.000  loss_rpn_loc: 0.010  time: 1.8167  data_time: 0.0102  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:15:48 d2.utils.events]: \u001b[0m eta: 3:49:04  iter: 50459  total_loss: 0.243  loss_cls: 0.021  loss_box_reg: 0.091  loss_mask: 0.120  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8171  data_time: 0.0092  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:16:25 d2.utils.events]: \u001b[0m eta: 3:48:28  iter: 50479  total_loss: 0.246  loss_cls: 0.023  loss_box_reg: 0.090  loss_mask: 0.112  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 1.8174  data_time: 0.0088  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:17:01 d2.utils.events]: \u001b[0m eta: 3:47:51  iter: 50499  total_loss: 0.215  loss_cls: 0.017  loss_box_reg: 0.084  loss_mask: 0.106  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8169  data_time: 0.0101  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:17:37 d2.utils.events]: \u001b[0m eta: 3:47:26  iter: 50519  total_loss: 0.209  loss_cls: 0.023  loss_box_reg: 0.078  loss_mask: 0.108  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8172  data_time: 0.0108  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:18:15 d2.utils.events]: \u001b[0m eta: 3:47:00  iter: 50539  total_loss: 0.298  loss_cls: 0.035  loss_box_reg: 0.107  loss_mask: 0.125  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 1.8191  data_time: 0.0083  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:18:52 d2.utils.events]: \u001b[0m eta: 3:46:26  iter: 50559  total_loss: 0.235  loss_cls: 0.025  loss_box_reg: 0.099  loss_mask: 0.110  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8206  data_time: 0.0091  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:19:30 d2.utils.events]: \u001b[0m eta: 3:46:10  iter: 50579  total_loss: 0.252  loss_cls: 0.026  loss_box_reg: 0.092  loss_mask: 0.118  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8226  data_time: 0.0094  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:20:05 d2.utils.events]: \u001b[0m eta: 3:45:15  iter: 50599  total_loss: 0.263  loss_cls: 0.029  loss_box_reg: 0.112  loss_mask: 0.127  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 1.8213  data_time: 0.0104  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:20:41 d2.utils.events]: \u001b[0m eta: 3:44:36  iter: 50619  total_loss: 0.207  loss_cls: 0.014  loss_box_reg: 0.075  loss_mask: 0.099  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8206  data_time: 0.0078  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:21:17 d2.utils.events]: \u001b[0m eta: 3:43:57  iter: 50639  total_loss: 0.255  loss_cls: 0.021  loss_box_reg: 0.089  loss_mask: 0.125  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8198  data_time: 0.0106  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:21:53 d2.utils.events]: \u001b[0m eta: 3:43:15  iter: 50659  total_loss: 0.206  loss_cls: 0.019  loss_box_reg: 0.080  loss_mask: 0.103  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8193  data_time: 0.0101  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:22:31 d2.utils.events]: \u001b[0m eta: 3:42:48  iter: 50679  total_loss: 0.258  loss_cls: 0.025  loss_box_reg: 0.088  loss_mask: 0.124  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8206  data_time: 0.0102  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:23:08 d2.utils.events]: \u001b[0m eta: 3:42:20  iter: 50699  total_loss: 0.243  loss_cls: 0.035  loss_box_reg: 0.100  loss_mask: 0.111  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 1.8222  data_time: 0.0100  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:23:46 d2.utils.events]: \u001b[0m eta: 3:42:01  iter: 50719  total_loss: 0.201  loss_cls: 0.022  loss_box_reg: 0.074  loss_mask: 0.110  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8235  data_time: 0.0085  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:24:21 d2.utils.events]: \u001b[0m eta: 3:41:00  iter: 50739  total_loss: 0.271  loss_cls: 0.023  loss_box_reg: 0.114  loss_mask: 0.132  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  time: 1.8220  data_time: 0.0104  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:24:59 d2.utils.events]: \u001b[0m eta: 3:40:30  iter: 50759  total_loss: 0.217  loss_cls: 0.031  loss_box_reg: 0.080  loss_mask: 0.115  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8236  data_time: 0.0094  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:25:35 d2.utils.events]: \u001b[0m eta: 3:40:09  iter: 50779  total_loss: 0.263  loss_cls: 0.021  loss_box_reg: 0.096  loss_mask: 0.129  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  time: 1.8241  data_time: 0.0092  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:26:11 d2.utils.events]: \u001b[0m eta: 3:39:17  iter: 50799  total_loss: 0.285  loss_cls: 0.027  loss_box_reg: 0.107  loss_mask: 0.136  loss_rpn_cls: 0.001  loss_rpn_loc: 0.013  time: 1.8227  data_time: 0.0107  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:26:48 d2.utils.events]: \u001b[0m eta: 3:38:51  iter: 50819  total_loss: 0.218  loss_cls: 0.021  loss_box_reg: 0.089  loss_mask: 0.097  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8236  data_time: 0.0113  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:27:23 d2.utils.events]: \u001b[0m eta: 3:37:58  iter: 50839  total_loss: 0.231  loss_cls: 0.020  loss_box_reg: 0.080  loss_mask: 0.110  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8214  data_time: 0.0122  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:27:59 d2.utils.events]: \u001b[0m eta: 3:37:18  iter: 50859  total_loss: 0.237  loss_cls: 0.028  loss_box_reg: 0.087  loss_mask: 0.113  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8216  data_time: 0.0086  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:28:36 d2.utils.events]: \u001b[0m eta: 3:36:44  iter: 50879  total_loss: 0.240  loss_cls: 0.024  loss_box_reg: 0.095  loss_mask: 0.123  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8223  data_time: 0.0090  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:29:13 d2.utils.events]: \u001b[0m eta: 3:36:15  iter: 50899  total_loss: 0.253  loss_cls: 0.025  loss_box_reg: 0.095  loss_mask: 0.135  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8227  data_time: 0.0085  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:29:49 d2.utils.events]: \u001b[0m eta: 3:35:48  iter: 50919  total_loss: 0.276  loss_cls: 0.035  loss_box_reg: 0.106  loss_mask: 0.116  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  time: 1.8220  data_time: 0.0100  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:30:26 d2.utils.events]: \u001b[0m eta: 3:35:11  iter: 50939  total_loss: 0.280  loss_cls: 0.030  loss_box_reg: 0.114  loss_mask: 0.127  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 1.8221  data_time: 0.0100  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:31:05 d2.utils.events]: \u001b[0m eta: 3:35:05  iter: 50959  total_loss: 0.201  loss_cls: 0.016  loss_box_reg: 0.074  loss_mask: 0.107  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8253  data_time: 0.0083  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:31:42 d2.utils.events]: \u001b[0m eta: 3:34:28  iter: 50979  total_loss: 0.254  loss_cls: 0.026  loss_box_reg: 0.100  loss_mask: 0.115  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 1.8253  data_time: 0.0102  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:32:20 d2.utils.events]: \u001b[0m eta: 3:33:31  iter: 50999  total_loss: 0.242  loss_cls: 0.035  loss_box_reg: 0.100  loss_mask: 0.124  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8246  data_time: 0.0091  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:32:55 d2.utils.events]: \u001b[0m eta: 3:32:37  iter: 51019  total_loss: 0.276  loss_cls: 0.030  loss_box_reg: 0.087  loss_mask: 0.107  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 1.8233  data_time: 0.0086  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:33:32 d2.utils.events]: \u001b[0m eta: 3:31:52  iter: 51039  total_loss: 0.226  loss_cls: 0.026  loss_box_reg: 0.081  loss_mask: 0.113  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8239  data_time: 0.0089  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:34:09 d2.utils.events]: \u001b[0m eta: 3:31:36  iter: 51059  total_loss: 0.234  loss_cls: 0.023  loss_box_reg: 0.085  loss_mask: 0.121  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8242  data_time: 0.0105  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:34:46 d2.utils.events]: \u001b[0m eta: 3:31:25  iter: 51079  total_loss: 0.203  loss_cls: 0.020  loss_box_reg: 0.080  loss_mask: 0.097  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8247  data_time: 0.0126  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:35:21 d2.utils.events]: \u001b[0m eta: 3:30:50  iter: 51099  total_loss: 0.283  loss_cls: 0.030  loss_box_reg: 0.116  loss_mask: 0.127  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  time: 1.8237  data_time: 0.0091  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:35:57 d2.utils.events]: \u001b[0m eta: 3:29:42  iter: 51119  total_loss: 0.265  loss_cls: 0.031  loss_box_reg: 0.104  loss_mask: 0.134  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8234  data_time: 0.0085  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:36:34 d2.utils.events]: \u001b[0m eta: 3:29:13  iter: 51139  total_loss: 0.238  loss_cls: 0.029  loss_box_reg: 0.099  loss_mask: 0.115  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8238  data_time: 0.0087  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:37:11 d2.utils.events]: \u001b[0m eta: 3:29:04  iter: 51159  total_loss: 0.245  loss_cls: 0.026  loss_box_reg: 0.088  loss_mask: 0.102  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8241  data_time: 0.0104  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:37:48 d2.utils.events]: \u001b[0m eta: 3:28:15  iter: 51179  total_loss: 0.314  loss_cls: 0.031  loss_box_reg: 0.121  loss_mask: 0.138  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  time: 1.8241  data_time: 0.0076  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:38:26 d2.utils.events]: \u001b[0m eta: 3:28:06  iter: 51199  total_loss: 0.209  loss_cls: 0.024  loss_box_reg: 0.073  loss_mask: 0.104  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8253  data_time: 0.0080  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:39:01 d2.utils.events]: \u001b[0m eta: 3:27:23  iter: 51219  total_loss: 0.314  loss_cls: 0.030  loss_box_reg: 0.117  loss_mask: 0.141  loss_rpn_cls: 0.000  loss_rpn_loc: 0.019  time: 1.8246  data_time: 0.0106  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:39:39 d2.utils.events]: \u001b[0m eta: 3:26:56  iter: 51239  total_loss: 0.259  loss_cls: 0.033  loss_box_reg: 0.102  loss_mask: 0.103  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 1.8258  data_time: 0.0097  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:40:14 d2.utils.events]: \u001b[0m eta: 3:26:12  iter: 51259  total_loss: 0.226  loss_cls: 0.024  loss_box_reg: 0.087  loss_mask: 0.115  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8245  data_time: 0.0080  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:40:52 d2.utils.events]: \u001b[0m eta: 3:25:53  iter: 51279  total_loss: 0.204  loss_cls: 0.018  loss_box_reg: 0.084  loss_mask: 0.101  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 1.8253  data_time: 0.0098  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:41:29 d2.utils.events]: \u001b[0m eta: 3:25:37  iter: 51299  total_loss: 0.239  loss_cls: 0.025  loss_box_reg: 0.096  loss_mask: 0.109  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8261  data_time: 0.0089  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:42:04 d2.utils.events]: \u001b[0m eta: 3:24:24  iter: 51319  total_loss: 0.239  loss_cls: 0.028  loss_box_reg: 0.088  loss_mask: 0.110  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  time: 1.8243  data_time: 0.0101  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:42:41 d2.utils.events]: \u001b[0m eta: 3:23:49  iter: 51339  total_loss: 0.242  loss_cls: 0.019  loss_box_reg: 0.085  loss_mask: 0.137  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8253  data_time: 0.0100  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:43:20 d2.utils.events]: \u001b[0m eta: 3:23:47  iter: 51359  total_loss: 0.212  loss_cls: 0.019  loss_box_reg: 0.067  loss_mask: 0.113  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8269  data_time: 0.0116  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:43:56 d2.utils.events]: \u001b[0m eta: 3:23:16  iter: 51379  total_loss: 0.271  loss_cls: 0.030  loss_box_reg: 0.104  loss_mask: 0.124  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  time: 1.8264  data_time: 0.0092  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:44:33 d2.utils.events]: \u001b[0m eta: 3:22:49  iter: 51399  total_loss: 0.263  loss_cls: 0.030  loss_box_reg: 0.101  loss_mask: 0.130  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 1.8265  data_time: 0.0091  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:45:11 d2.utils.events]: \u001b[0m eta: 3:22:22  iter: 51419  total_loss: 0.222  loss_cls: 0.019  loss_box_reg: 0.082  loss_mask: 0.120  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8275  data_time: 0.0094  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:45:48 d2.utils.events]: \u001b[0m eta: 3:21:45  iter: 51439  total_loss: 0.275  loss_cls: 0.030  loss_box_reg: 0.098  loss_mask: 0.127  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8279  data_time: 0.0096  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:46:23 d2.utils.events]: \u001b[0m eta: 3:20:52  iter: 51459  total_loss: 0.202  loss_cls: 0.020  loss_box_reg: 0.075  loss_mask: 0.091  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8268  data_time: 0.0077  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:46:58 d2.utils.events]: \u001b[0m eta: 3:20:00  iter: 51479  total_loss: 0.235  loss_cls: 0.030  loss_box_reg: 0.111  loss_mask: 0.112  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8262  data_time: 0.0080  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:47:36 d2.utils.events]: \u001b[0m eta: 3:19:38  iter: 51499  total_loss: 0.272  loss_cls: 0.031  loss_box_reg: 0.116  loss_mask: 0.121  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  time: 1.8272  data_time: 0.0082  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:48:13 d2.utils.events]: \u001b[0m eta: 3:19:03  iter: 51519  total_loss: 0.229  loss_cls: 0.031  loss_box_reg: 0.076  loss_mask: 0.124  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8274  data_time: 0.0084  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:48:50 d2.utils.events]: \u001b[0m eta: 3:18:16  iter: 51539  total_loss: 0.302  loss_cls: 0.030  loss_box_reg: 0.123  loss_mask: 0.127  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 1.8276  data_time: 0.0084  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:49:26 d2.utils.events]: \u001b[0m eta: 3:17:14  iter: 51559  total_loss: 0.279  loss_cls: 0.027  loss_box_reg: 0.102  loss_mask: 0.140  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8269  data_time: 0.0078  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:50:02 d2.utils.events]: \u001b[0m eta: 3:16:32  iter: 51579  total_loss: 0.210  loss_cls: 0.020  loss_box_reg: 0.080  loss_mask: 0.099  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8266  data_time: 0.0097  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:50:38 d2.utils.events]: \u001b[0m eta: 3:15:51  iter: 51599  total_loss: 0.273  loss_cls: 0.029  loss_box_reg: 0.096  loss_mask: 0.124  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8261  data_time: 0.0122  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:51:12 d2.utils.events]: \u001b[0m eta: 3:15:10  iter: 51619  total_loss: 0.227  loss_cls: 0.019  loss_box_reg: 0.085  loss_mask: 0.118  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8249  data_time: 0.0083  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:51:47 d2.utils.events]: \u001b[0m eta: 3:14:29  iter: 51639  total_loss: 0.208  loss_cls: 0.020  loss_box_reg: 0.070  loss_mask: 0.107  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 1.8238  data_time: 0.0075  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:52:23 d2.utils.events]: \u001b[0m eta: 3:13:48  iter: 51659  total_loss: 0.257  loss_cls: 0.026  loss_box_reg: 0.088  loss_mask: 0.118  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8235  data_time: 0.0094  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:52:59 d2.utils.events]: \u001b[0m eta: 3:13:01  iter: 51679  total_loss: 0.206  loss_cls: 0.024  loss_box_reg: 0.076  loss_mask: 0.101  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8232  data_time: 0.0098  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:53:35 d2.utils.events]: \u001b[0m eta: 3:12:11  iter: 51699  total_loss: 0.201  loss_cls: 0.021  loss_box_reg: 0.074  loss_mask: 0.100  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8228  data_time: 0.0088  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:54:12 d2.utils.events]: \u001b[0m eta: 3:11:31  iter: 51719  total_loss: 0.261  loss_cls: 0.032  loss_box_reg: 0.090  loss_mask: 0.118  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 1.8236  data_time: 0.0113  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:54:50 d2.utils.events]: \u001b[0m eta: 3:11:15  iter: 51739  total_loss: 0.245  loss_cls: 0.024  loss_box_reg: 0.094  loss_mask: 0.116  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 1.8243  data_time: 0.0092  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:55:27 d2.utils.events]: \u001b[0m eta: 3:10:41  iter: 51759  total_loss: 0.276  loss_cls: 0.029  loss_box_reg: 0.107  loss_mask: 0.128  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8247  data_time: 0.0107  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:56:03 d2.utils.events]: \u001b[0m eta: 3:10:02  iter: 51779  total_loss: 0.258  loss_cls: 0.022  loss_box_reg: 0.104  loss_mask: 0.132  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8244  data_time: 0.0101  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:56:41 d2.utils.events]: \u001b[0m eta: 3:09:41  iter: 51799  total_loss: 0.233  loss_cls: 0.023  loss_box_reg: 0.093  loss_mask: 0.117  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8253  data_time: 0.0124  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:57:18 d2.utils.events]: \u001b[0m eta: 3:09:02  iter: 51819  total_loss: 0.250  loss_cls: 0.024  loss_box_reg: 0.087  loss_mask: 0.122  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8251  data_time: 0.0089  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:57:53 d2.utils.events]: \u001b[0m eta: 3:08:28  iter: 51839  total_loss: 0.247  loss_cls: 0.032  loss_box_reg: 0.087  loss_mask: 0.124  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8246  data_time: 0.0105  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:58:30 d2.utils.events]: \u001b[0m eta: 3:07:58  iter: 51859  total_loss: 0.211  loss_cls: 0.019  loss_box_reg: 0.083  loss_mask: 0.110  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 1.8249  data_time: 0.0082  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:59:06 d2.utils.events]: \u001b[0m eta: 3:07:16  iter: 51879  total_loss: 0.226  loss_cls: 0.027  loss_box_reg: 0.094  loss_mask: 0.111  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8247  data_time: 0.0084  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 06:59:41 d2.utils.events]: \u001b[0m eta: 3:06:32  iter: 51899  total_loss: 0.195  loss_cls: 0.019  loss_box_reg: 0.069  loss_mask: 0.090  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 1.8238  data_time: 0.0080  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:00:19 d2.utils.events]: \u001b[0m eta: 3:05:58  iter: 51919  total_loss: 0.224  loss_cls: 0.026  loss_box_reg: 0.086  loss_mask: 0.101  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8242  data_time: 0.0106  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:00:54 d2.utils.events]: \u001b[0m eta: 3:05:05  iter: 51939  total_loss: 0.275  loss_cls: 0.034  loss_box_reg: 0.110  loss_mask: 0.115  loss_rpn_cls: 0.000  loss_rpn_loc: 0.010  time: 1.8236  data_time: 0.0089  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:01:29 d2.utils.events]: \u001b[0m eta: 3:04:13  iter: 51959  total_loss: 0.248  loss_cls: 0.020  loss_box_reg: 0.093  loss_mask: 0.127  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8230  data_time: 0.0095  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:02:05 d2.utils.events]: \u001b[0m eta: 3:03:34  iter: 51979  total_loss: 0.235  loss_cls: 0.026  loss_box_reg: 0.091  loss_mask: 0.126  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 1.8226  data_time: 0.0088  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:02:44 d2.utils.events]: \u001b[0m eta: 3:03:01  iter: 51999  total_loss: 0.248  loss_cls: 0.020  loss_box_reg: 0.093  loss_mask: 0.125  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8226  data_time: 0.0105  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:03:20 d2.utils.events]: \u001b[0m eta: 3:02:34  iter: 52019  total_loss: 0.291  loss_cls: 0.038  loss_box_reg: 0.118  loss_mask: 0.119  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8223  data_time: 0.0090  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:03:55 d2.utils.events]: \u001b[0m eta: 3:01:50  iter: 52039  total_loss: 0.239  loss_cls: 0.036  loss_box_reg: 0.084  loss_mask: 0.115  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8221  data_time: 0.0088  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:04:32 d2.utils.events]: \u001b[0m eta: 3:01:12  iter: 52059  total_loss: 0.279  loss_cls: 0.028  loss_box_reg: 0.102  loss_mask: 0.145  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 1.8223  data_time: 0.0093  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:05:08 d2.utils.events]: \u001b[0m eta: 3:00:29  iter: 52079  total_loss: 0.244  loss_cls: 0.030  loss_box_reg: 0.100  loss_mask: 0.126  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 1.8219  data_time: 0.0081  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:05:45 d2.utils.events]: \u001b[0m eta: 3:00:03  iter: 52099  total_loss: 0.204  loss_cls: 0.019  loss_box_reg: 0.080  loss_mask: 0.111  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8222  data_time: 0.0107  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:06:24 d2.utils.events]: \u001b[0m eta: 2:59:33  iter: 52119  total_loss: 0.226  loss_cls: 0.024  loss_box_reg: 0.087  loss_mask: 0.106  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8232  data_time: 0.0093  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:07:00 d2.utils.events]: \u001b[0m eta: 2:58:49  iter: 52139  total_loss: 0.253  loss_cls: 0.030  loss_box_reg: 0.093  loss_mask: 0.112  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  time: 1.8232  data_time: 0.0078  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:07:37 d2.utils.events]: \u001b[0m eta: 2:58:09  iter: 52159  total_loss: 0.191  loss_cls: 0.015  loss_box_reg: 0.063  loss_mask: 0.102  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 1.8234  data_time: 0.0102  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:08:13 d2.utils.events]: \u001b[0m eta: 2:57:28  iter: 52179  total_loss: 0.265  loss_cls: 0.036  loss_box_reg: 0.098  loss_mask: 0.126  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  time: 1.8232  data_time: 0.0101  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:08:49 d2.utils.events]: \u001b[0m eta: 2:56:32  iter: 52199  total_loss: 0.221  loss_cls: 0.028  loss_box_reg: 0.085  loss_mask: 0.109  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8227  data_time: 0.0102  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:09:25 d2.utils.events]: \u001b[0m eta: 2:56:09  iter: 52219  total_loss: 0.234  loss_cls: 0.024  loss_box_reg: 0.097  loss_mask: 0.111  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8228  data_time: 0.0089  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:10:01 d2.utils.events]: \u001b[0m eta: 2:55:22  iter: 52239  total_loss: 0.257  loss_cls: 0.029  loss_box_reg: 0.107  loss_mask: 0.113  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8226  data_time: 0.0106  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:10:37 d2.utils.events]: \u001b[0m eta: 2:54:48  iter: 52259  total_loss: 0.212  loss_cls: 0.018  loss_box_reg: 0.085  loss_mask: 0.103  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8225  data_time: 0.0092  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:11:14 d2.utils.events]: \u001b[0m eta: 2:53:56  iter: 52279  total_loss: 0.227  loss_cls: 0.023  loss_box_reg: 0.084  loss_mask: 0.115  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8223  data_time: 0.0094  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:11:51 d2.utils.events]: \u001b[0m eta: 2:53:22  iter: 52299  total_loss: 0.314  loss_cls: 0.032  loss_box_reg: 0.114  loss_mask: 0.127  loss_rpn_cls: 0.001  loss_rpn_loc: 0.013  time: 1.8227  data_time: 0.0090  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:12:28 d2.utils.events]: \u001b[0m eta: 2:53:10  iter: 52319  total_loss: 0.254  loss_cls: 0.038  loss_box_reg: 0.096  loss_mask: 0.109  loss_rpn_cls: 0.000  loss_rpn_loc: 0.012  time: 1.8230  data_time: 0.0091  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:13:04 d2.utils.events]: \u001b[0m eta: 2:52:29  iter: 52339  total_loss: 0.263  loss_cls: 0.022  loss_box_reg: 0.088  loss_mask: 0.123  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8229  data_time: 0.0087  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:13:41 d2.utils.events]: \u001b[0m eta: 2:51:45  iter: 52359  total_loss: 0.210  loss_cls: 0.017  loss_box_reg: 0.071  loss_mask: 0.122  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8231  data_time: 0.0105  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:14:17 d2.utils.events]: \u001b[0m eta: 2:51:09  iter: 52379  total_loss: 0.233  loss_cls: 0.027  loss_box_reg: 0.096  loss_mask: 0.106  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8227  data_time: 0.0098  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:14:54 d2.utils.events]: \u001b[0m eta: 2:50:33  iter: 52399  total_loss: 0.294  loss_cls: 0.027  loss_box_reg: 0.108  loss_mask: 0.122  loss_rpn_cls: 0.001  loss_rpn_loc: 0.013  time: 1.8230  data_time: 0.0094  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:15:31 d2.utils.events]: \u001b[0m eta: 2:49:54  iter: 52419  total_loss: 0.286  loss_cls: 0.023  loss_box_reg: 0.090  loss_mask: 0.139  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8231  data_time: 0.0102  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:16:06 d2.utils.events]: \u001b[0m eta: 2:49:06  iter: 52439  total_loss: 0.191  loss_cls: 0.021  loss_box_reg: 0.079  loss_mask: 0.112  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8227  data_time: 0.0099  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:16:42 d2.utils.events]: \u001b[0m eta: 2:48:42  iter: 52459  total_loss: 0.319  loss_cls: 0.032  loss_box_reg: 0.102  loss_mask: 0.148  loss_rpn_cls: 0.001  loss_rpn_loc: 0.015  time: 1.8226  data_time: 0.0087  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:17:19 d2.utils.events]: \u001b[0m eta: 2:48:13  iter: 52479  total_loss: 0.299  loss_cls: 0.024  loss_box_reg: 0.111  loss_mask: 0.123  loss_rpn_cls: 0.000  loss_rpn_loc: 0.013  time: 1.8225  data_time: 0.0103  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:17:54 d2.utils.events]: \u001b[0m eta: 2:47:13  iter: 52499  total_loss: 0.193  loss_cls: 0.022  loss_box_reg: 0.078  loss_mask: 0.100  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 1.8222  data_time: 0.0094  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:18:31 d2.utils.events]: \u001b[0m eta: 2:46:28  iter: 52519  total_loss: 0.274  loss_cls: 0.029  loss_box_reg: 0.109  loss_mask: 0.128  loss_rpn_cls: 0.000  loss_rpn_loc: 0.012  time: 1.8223  data_time: 0.0097  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:19:08 d2.utils.events]: \u001b[0m eta: 2:45:54  iter: 52539  total_loss: 0.203  loss_cls: 0.023  loss_box_reg: 0.070  loss_mask: 0.098  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8226  data_time: 0.0092  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:19:45 d2.utils.events]: \u001b[0m eta: 2:45:40  iter: 52559  total_loss: 0.241  loss_cls: 0.024  loss_box_reg: 0.098  loss_mask: 0.118  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8228  data_time: 0.0090  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:20:21 d2.utils.events]: \u001b[0m eta: 2:44:45  iter: 52579  total_loss: 0.176  loss_cls: 0.012  loss_box_reg: 0.067  loss_mask: 0.093  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 1.8226  data_time: 0.0083  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:20:58 d2.utils.events]: \u001b[0m eta: 2:44:27  iter: 52599  total_loss: 0.280  loss_cls: 0.028  loss_box_reg: 0.100  loss_mask: 0.132  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 1.8229  data_time: 0.0097  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:21:34 d2.utils.events]: \u001b[0m eta: 2:43:53  iter: 52619  total_loss: 0.252  loss_cls: 0.028  loss_box_reg: 0.097  loss_mask: 0.110  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8227  data_time: 0.0082  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:22:13 d2.utils.events]: \u001b[0m eta: 2:43:33  iter: 52639  total_loss: 0.280  loss_cls: 0.026  loss_box_reg: 0.086  loss_mask: 0.114  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8233  data_time: 0.0090  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:22:48 d2.utils.events]: \u001b[0m eta: 2:42:52  iter: 52659  total_loss: 0.236  loss_cls: 0.024  loss_box_reg: 0.088  loss_mask: 0.103  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8230  data_time: 0.0104  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:23:24 d2.utils.events]: \u001b[0m eta: 2:42:13  iter: 52679  total_loss: 0.297  loss_cls: 0.032  loss_box_reg: 0.098  loss_mask: 0.138  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 1.8226  data_time: 0.0088  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:24:00 d2.utils.events]: \u001b[0m eta: 2:41:39  iter: 52699  total_loss: 0.227  loss_cls: 0.020  loss_box_reg: 0.085  loss_mask: 0.115  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8225  data_time: 0.0106  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:24:36 d2.utils.events]: \u001b[0m eta: 2:40:59  iter: 52719  total_loss: 0.238  loss_cls: 0.026  loss_box_reg: 0.086  loss_mask: 0.136  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8226  data_time: 0.0095  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:25:12 d2.utils.events]: \u001b[0m eta: 2:40:14  iter: 52739  total_loss: 0.273  loss_cls: 0.030  loss_box_reg: 0.096  loss_mask: 0.132  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8223  data_time: 0.0105  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:25:48 d2.utils.events]: \u001b[0m eta: 2:39:13  iter: 52759  total_loss: 0.237  loss_cls: 0.026  loss_box_reg: 0.090  loss_mask: 0.108  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  time: 1.8220  data_time: 0.0105  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:26:25 d2.utils.events]: \u001b[0m eta: 2:38:37  iter: 52779  total_loss: 0.268  loss_cls: 0.026  loss_box_reg: 0.099  loss_mask: 0.127  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 1.8222  data_time: 0.0086  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:27:03 d2.utils.events]: \u001b[0m eta: 2:37:56  iter: 52799  total_loss: 0.258  loss_cls: 0.023  loss_box_reg: 0.092  loss_mask: 0.117  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8227  data_time: 0.0087  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:27:39 d2.utils.events]: \u001b[0m eta: 2:37:20  iter: 52819  total_loss: 0.266  loss_cls: 0.029  loss_box_reg: 0.105  loss_mask: 0.108  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8225  data_time: 0.0089  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:28:16 d2.utils.events]: \u001b[0m eta: 2:37:07  iter: 52839  total_loss: 0.266  loss_cls: 0.037  loss_box_reg: 0.096  loss_mask: 0.130  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 1.8227  data_time: 0.0083  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:28:51 d2.utils.events]: \u001b[0m eta: 2:36:11  iter: 52859  total_loss: 0.275  loss_cls: 0.029  loss_box_reg: 0.093  loss_mask: 0.126  loss_rpn_cls: 0.000  loss_rpn_loc: 0.011  time: 1.8222  data_time: 0.0090  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:29:27 d2.utils.events]: \u001b[0m eta: 2:35:34  iter: 52879  total_loss: 0.268  loss_cls: 0.019  loss_box_reg: 0.095  loss_mask: 0.124  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 1.8221  data_time: 0.0085  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:30:04 d2.utils.events]: \u001b[0m eta: 2:35:22  iter: 52899  total_loss: 0.251  loss_cls: 0.039  loss_box_reg: 0.084  loss_mask: 0.113  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 1.8223  data_time: 0.0101  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:30:41 d2.utils.events]: \u001b[0m eta: 2:34:46  iter: 52919  total_loss: 0.239  loss_cls: 0.025  loss_box_reg: 0.095  loss_mask: 0.110  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8225  data_time: 0.0084  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:31:15 d2.utils.events]: \u001b[0m eta: 2:34:06  iter: 52939  total_loss: 0.202  loss_cls: 0.019  loss_box_reg: 0.077  loss_mask: 0.100  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 1.8218  data_time: 0.0098  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:31:51 d2.utils.events]: \u001b[0m eta: 2:33:21  iter: 52959  total_loss: 0.235  loss_cls: 0.021  loss_box_reg: 0.087  loss_mask: 0.123  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8216  data_time: 0.0101  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:32:29 d2.utils.events]: \u001b[0m eta: 2:32:56  iter: 52979  total_loss: 0.217  loss_cls: 0.025  loss_box_reg: 0.076  loss_mask: 0.105  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8221  data_time: 0.0084  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:33:07 d2.utils.events]: \u001b[0m eta: 2:32:15  iter: 52999  total_loss: 0.202  loss_cls: 0.018  loss_box_reg: 0.075  loss_mask: 0.112  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8218  data_time: 0.0100  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:33:43 d2.utils.events]: \u001b[0m eta: 2:31:21  iter: 53019  total_loss: 0.266  loss_cls: 0.025  loss_box_reg: 0.101  loss_mask: 0.120  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 1.8217  data_time: 0.0115  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:34:18 d2.utils.events]: \u001b[0m eta: 2:30:41  iter: 53039  total_loss: 0.224  loss_cls: 0.024  loss_box_reg: 0.078  loss_mask: 0.103  loss_rpn_cls: 0.000  loss_rpn_loc: 0.010  time: 1.8213  data_time: 0.0086  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:34:56 d2.utils.events]: \u001b[0m eta: 2:30:27  iter: 53059  total_loss: 0.192  loss_cls: 0.020  loss_box_reg: 0.078  loss_mask: 0.083  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8216  data_time: 0.0087  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:35:32 d2.utils.events]: \u001b[0m eta: 2:29:49  iter: 53079  total_loss: 0.312  loss_cls: 0.031  loss_box_reg: 0.112  loss_mask: 0.138  loss_rpn_cls: 0.001  loss_rpn_loc: 0.013  time: 1.8216  data_time: 0.0097  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:36:09 d2.utils.events]: \u001b[0m eta: 2:28:56  iter: 53099  total_loss: 0.233  loss_cls: 0.024  loss_box_reg: 0.091  loss_mask: 0.121  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 1.8218  data_time: 0.0087  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:36:46 d2.utils.events]: \u001b[0m eta: 2:28:19  iter: 53119  total_loss: 0.196  loss_cls: 0.026  loss_box_reg: 0.071  loss_mask: 0.100  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8219  data_time: 0.0076  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:37:22 d2.utils.events]: \u001b[0m eta: 2:27:46  iter: 53139  total_loss: 0.243  loss_cls: 0.024  loss_box_reg: 0.088  loss_mask: 0.120  loss_rpn_cls: 0.000  loss_rpn_loc: 0.012  time: 1.8219  data_time: 0.0100  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:37:59 d2.utils.events]: \u001b[0m eta: 2:27:10  iter: 53159  total_loss: 0.205  loss_cls: 0.017  loss_box_reg: 0.075  loss_mask: 0.099  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8220  data_time: 0.0103  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:38:34 d2.utils.events]: \u001b[0m eta: 2:26:33  iter: 53179  total_loss: 0.258  loss_cls: 0.025  loss_box_reg: 0.107  loss_mask: 0.122  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8215  data_time: 0.0108  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:39:12 d2.utils.events]: \u001b[0m eta: 2:26:34  iter: 53199  total_loss: 0.269  loss_cls: 0.031  loss_box_reg: 0.098  loss_mask: 0.125  loss_rpn_cls: 0.000  loss_rpn_loc: 0.012  time: 1.8219  data_time: 0.0088  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:39:48 d2.utils.events]: \u001b[0m eta: 2:25:43  iter: 53219  total_loss: 0.312  loss_cls: 0.035  loss_box_reg: 0.112  loss_mask: 0.146  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  time: 1.8218  data_time: 0.0099  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:40:23 d2.utils.events]: \u001b[0m eta: 2:24:57  iter: 53239  total_loss: 0.256  loss_cls: 0.036  loss_box_reg: 0.110  loss_mask: 0.114  loss_rpn_cls: 0.000  loss_rpn_loc: 0.010  time: 1.8214  data_time: 0.0082  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:41:00 d2.utils.events]: \u001b[0m eta: 2:24:25  iter: 53259  total_loss: 0.245  loss_cls: 0.021  loss_box_reg: 0.100  loss_mask: 0.112  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8216  data_time: 0.0120  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:41:37 d2.utils.events]: \u001b[0m eta: 2:24:01  iter: 53279  total_loss: 0.217  loss_cls: 0.020  loss_box_reg: 0.072  loss_mask: 0.121  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8218  data_time: 0.0097  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:42:14 d2.utils.events]: \u001b[0m eta: 2:23:15  iter: 53299  total_loss: 0.239  loss_cls: 0.024  loss_box_reg: 0.094  loss_mask: 0.125  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8218  data_time: 0.0083  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:42:51 d2.utils.events]: \u001b[0m eta: 2:22:48  iter: 53319  total_loss: 0.233  loss_cls: 0.025  loss_box_reg: 0.083  loss_mask: 0.115  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8220  data_time: 0.0107  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:43:28 d2.utils.events]: \u001b[0m eta: 2:22:19  iter: 53339  total_loss: 0.262  loss_cls: 0.026  loss_box_reg: 0.092  loss_mask: 0.120  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8223  data_time: 0.0084  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:44:06 d2.utils.events]: \u001b[0m eta: 2:21:46  iter: 53359  total_loss: 0.301  loss_cls: 0.039  loss_box_reg: 0.106  loss_mask: 0.127  loss_rpn_cls: 0.000  loss_rpn_loc: 0.011  time: 1.8226  data_time: 0.0086  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:44:41 d2.utils.events]: \u001b[0m eta: 2:21:07  iter: 53379  total_loss: 0.198  loss_cls: 0.021  loss_box_reg: 0.081  loss_mask: 0.093  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8223  data_time: 0.0098  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:45:17 d2.utils.events]: \u001b[0m eta: 2:20:29  iter: 53399  total_loss: 0.183  loss_cls: 0.014  loss_box_reg: 0.076  loss_mask: 0.092  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8222  data_time: 0.0090  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:45:54 d2.utils.events]: \u001b[0m eta: 2:19:51  iter: 53419  total_loss: 0.197  loss_cls: 0.018  loss_box_reg: 0.074  loss_mask: 0.095  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8222  data_time: 0.0091  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:46:31 d2.utils.events]: \u001b[0m eta: 2:19:14  iter: 53439  total_loss: 0.184  loss_cls: 0.020  loss_box_reg: 0.065  loss_mask: 0.093  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8223  data_time: 0.0088  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:47:07 d2.utils.events]: \u001b[0m eta: 2:18:39  iter: 53459  total_loss: 0.302  loss_cls: 0.033  loss_box_reg: 0.126  loss_mask: 0.123  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8222  data_time: 0.0088  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:47:44 d2.utils.events]: \u001b[0m eta: 2:18:06  iter: 53479  total_loss: 0.291  loss_cls: 0.033  loss_box_reg: 0.106  loss_mask: 0.122  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 1.8224  data_time: 0.0103  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:48:21 d2.utils.events]: \u001b[0m eta: 2:17:36  iter: 53499  total_loss: 0.242  loss_cls: 0.030  loss_box_reg: 0.087  loss_mask: 0.113  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8225  data_time: 0.0084  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:48:55 d2.utils.events]: \u001b[0m eta: 2:16:50  iter: 53519  total_loss: 0.246  loss_cls: 0.021  loss_box_reg: 0.092  loss_mask: 0.126  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  time: 1.8220  data_time: 0.0105  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:49:32 d2.utils.events]: \u001b[0m eta: 2:16:11  iter: 53539  total_loss: 0.252  loss_cls: 0.023  loss_box_reg: 0.089  loss_mask: 0.134  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 1.8220  data_time: 0.0116  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:50:10 d2.utils.events]: \u001b[0m eta: 2:15:44  iter: 53559  total_loss: 0.246  loss_cls: 0.031  loss_box_reg: 0.087  loss_mask: 0.111  loss_rpn_cls: 0.000  loss_rpn_loc: 0.012  time: 1.8223  data_time: 0.0083  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:50:47 d2.utils.events]: \u001b[0m eta: 2:15:26  iter: 53579  total_loss: 0.255  loss_cls: 0.023  loss_box_reg: 0.084  loss_mask: 0.143  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8227  data_time: 0.0091  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:51:23 d2.utils.events]: \u001b[0m eta: 2:14:44  iter: 53599  total_loss: 0.212  loss_cls: 0.026  loss_box_reg: 0.082  loss_mask: 0.098  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8225  data_time: 0.0099  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:52:00 d2.utils.events]: \u001b[0m eta: 2:14:10  iter: 53619  total_loss: 0.330  loss_cls: 0.031  loss_box_reg: 0.113  loss_mask: 0.131  loss_rpn_cls: 0.000  loss_rpn_loc: 0.012  time: 1.8226  data_time: 0.0091  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:52:36 d2.utils.events]: \u001b[0m eta: 2:13:15  iter: 53639  total_loss: 0.236  loss_cls: 0.030  loss_box_reg: 0.085  loss_mask: 0.113  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8225  data_time: 0.0088  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:53:12 d2.utils.events]: \u001b[0m eta: 2:12:42  iter: 53659  total_loss: 0.266  loss_cls: 0.024  loss_box_reg: 0.085  loss_mask: 0.117  loss_rpn_cls: 0.000  loss_rpn_loc: 0.017  time: 1.8224  data_time: 0.0090  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:53:48 d2.utils.events]: \u001b[0m eta: 2:12:11  iter: 53679  total_loss: 0.253  loss_cls: 0.032  loss_box_reg: 0.099  loss_mask: 0.115  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8222  data_time: 0.0086  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:54:26 d2.utils.events]: \u001b[0m eta: 2:11:44  iter: 53699  total_loss: 0.231  loss_cls: 0.033  loss_box_reg: 0.093  loss_mask: 0.100  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8227  data_time: 0.0105  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:55:04 d2.utils.events]: \u001b[0m eta: 2:11:11  iter: 53719  total_loss: 0.219  loss_cls: 0.023  loss_box_reg: 0.087  loss_mask: 0.108  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8230  data_time: 0.0093  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:55:41 d2.utils.events]: \u001b[0m eta: 2:10:43  iter: 53739  total_loss: 0.231  loss_cls: 0.026  loss_box_reg: 0.095  loss_mask: 0.106  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8231  data_time: 0.0102  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:56:17 d2.utils.events]: \u001b[0m eta: 2:10:08  iter: 53759  total_loss: 0.227  loss_cls: 0.016  loss_box_reg: 0.073  loss_mask: 0.102  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8229  data_time: 0.0094  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:56:52 d2.utils.events]: \u001b[0m eta: 2:09:23  iter: 53779  total_loss: 0.191  loss_cls: 0.017  loss_box_reg: 0.079  loss_mask: 0.096  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8227  data_time: 0.0096  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:57:28 d2.utils.events]: \u001b[0m eta: 2:08:42  iter: 53799  total_loss: 0.247  loss_cls: 0.028  loss_box_reg: 0.093  loss_mask: 0.109  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  time: 1.8226  data_time: 0.0088  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:58:03 d2.utils.events]: \u001b[0m eta: 2:07:57  iter: 53819  total_loss: 0.236  loss_cls: 0.023  loss_box_reg: 0.093  loss_mask: 0.110  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8222  data_time: 0.0089  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:58:41 d2.utils.events]: \u001b[0m eta: 2:07:26  iter: 53839  total_loss: 0.285  loss_cls: 0.036  loss_box_reg: 0.106  loss_mask: 0.118  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  time: 1.8226  data_time: 0.0091  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:59:18 d2.utils.events]: \u001b[0m eta: 2:06:55  iter: 53859  total_loss: 0.205  loss_cls: 0.025  loss_box_reg: 0.072  loss_mask: 0.099  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8228  data_time: 0.0094  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 07:59:55 d2.utils.events]: \u001b[0m eta: 2:06:24  iter: 53879  total_loss: 0.213  loss_cls: 0.019  loss_box_reg: 0.079  loss_mask: 0.102  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8229  data_time: 0.0086  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:00:29 d2.utils.events]: \u001b[0m eta: 2:05:33  iter: 53899  total_loss: 0.284  loss_cls: 0.027  loss_box_reg: 0.102  loss_mask: 0.141  loss_rpn_cls: 0.000  loss_rpn_loc: 0.011  time: 1.8222  data_time: 0.0124  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:01:05 d2.utils.events]: \u001b[0m eta: 2:04:53  iter: 53919  total_loss: 0.244  loss_cls: 0.030  loss_box_reg: 0.091  loss_mask: 0.119  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 1.8220  data_time: 0.0081  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:01:40 d2.utils.events]: \u001b[0m eta: 2:04:22  iter: 53939  total_loss: 0.198  loss_cls: 0.018  loss_box_reg: 0.078  loss_mask: 0.105  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 1.8217  data_time: 0.0083  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:02:16 d2.utils.events]: \u001b[0m eta: 2:03:53  iter: 53959  total_loss: 0.222  loss_cls: 0.028  loss_box_reg: 0.085  loss_mask: 0.112  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8217  data_time: 0.0100  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:02:52 d2.utils.events]: \u001b[0m eta: 2:03:09  iter: 53979  total_loss: 0.192  loss_cls: 0.023  loss_box_reg: 0.073  loss_mask: 0.103  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8215  data_time: 0.0093  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:03:31 d2.utils.events]: \u001b[0m eta: 2:02:32  iter: 53999  total_loss: 0.243  loss_cls: 0.021  loss_box_reg: 0.099  loss_mask: 0.124  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  time: 1.8215  data_time: 0.0081  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:04:06 d2.utils.events]: \u001b[0m eta: 2:01:52  iter: 54019  total_loss: 0.218  loss_cls: 0.023  loss_box_reg: 0.091  loss_mask: 0.115  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8213  data_time: 0.0101  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:04:44 d2.utils.events]: \u001b[0m eta: 2:01:22  iter: 54039  total_loss: 0.252  loss_cls: 0.024  loss_box_reg: 0.102  loss_mask: 0.115  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8215  data_time: 0.0089  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:05:21 d2.utils.events]: \u001b[0m eta: 2:00:43  iter: 54059  total_loss: 0.233  loss_cls: 0.022  loss_box_reg: 0.080  loss_mask: 0.118  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8217  data_time: 0.0084  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:05:58 d2.utils.events]: \u001b[0m eta: 2:00:08  iter: 54079  total_loss: 0.188  loss_cls: 0.020  loss_box_reg: 0.076  loss_mask: 0.093  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 1.8219  data_time: 0.0095  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:06:35 d2.utils.events]: \u001b[0m eta: 1:59:32  iter: 54099  total_loss: 0.250  loss_cls: 0.020  loss_box_reg: 0.103  loss_mask: 0.134  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 1.8220  data_time: 0.0082  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:07:11 d2.utils.events]: \u001b[0m eta: 1:58:38  iter: 54119  total_loss: 0.244  loss_cls: 0.020  loss_box_reg: 0.102  loss_mask: 0.112  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 1.8218  data_time: 0.0085  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:07:47 d2.utils.events]: \u001b[0m eta: 1:58:00  iter: 54139  total_loss: 0.286  loss_cls: 0.031  loss_box_reg: 0.095  loss_mask: 0.124  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 1.8217  data_time: 0.0084  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:08:23 d2.utils.events]: \u001b[0m eta: 1:57:24  iter: 54159  total_loss: 0.195  loss_cls: 0.018  loss_box_reg: 0.090  loss_mask: 0.095  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 1.8217  data_time: 0.0087  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:09:00 d2.utils.events]: \u001b[0m eta: 1:56:54  iter: 54179  total_loss: 0.307  loss_cls: 0.034  loss_box_reg: 0.118  loss_mask: 0.134  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  time: 1.8219  data_time: 0.0081  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:09:37 d2.utils.events]: \u001b[0m eta: 1:56:01  iter: 54199  total_loss: 0.285  loss_cls: 0.027  loss_box_reg: 0.104  loss_mask: 0.130  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  time: 1.8218  data_time: 0.0119  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:10:14 d2.utils.events]: \u001b[0m eta: 1:55:31  iter: 54219  total_loss: 0.218  loss_cls: 0.023  loss_box_reg: 0.075  loss_mask: 0.104  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8220  data_time: 0.0088  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:10:51 d2.utils.events]: \u001b[0m eta: 1:55:02  iter: 54239  total_loss: 0.299  loss_cls: 0.028  loss_box_reg: 0.109  loss_mask: 0.138  loss_rpn_cls: 0.000  loss_rpn_loc: 0.011  time: 1.8221  data_time: 0.0089  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:11:26 d2.utils.events]: \u001b[0m eta: 1:54:21  iter: 54259  total_loss: 0.219  loss_cls: 0.020  loss_box_reg: 0.077  loss_mask: 0.109  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8219  data_time: 0.0099  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:12:03 d2.utils.events]: \u001b[0m eta: 1:53:41  iter: 54279  total_loss: 0.305  loss_cls: 0.032  loss_box_reg: 0.114  loss_mask: 0.132  loss_rpn_cls: 0.001  loss_rpn_loc: 0.013  time: 1.8220  data_time: 0.0110  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:12:40 d2.utils.events]: \u001b[0m eta: 1:53:10  iter: 54299  total_loss: 0.222  loss_cls: 0.017  loss_box_reg: 0.086  loss_mask: 0.112  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8220  data_time: 0.0087  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:13:17 d2.utils.events]: \u001b[0m eta: 1:52:28  iter: 54319  total_loss: 0.239  loss_cls: 0.029  loss_box_reg: 0.098  loss_mask: 0.114  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8221  data_time: 0.0081  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:13:53 d2.utils.events]: \u001b[0m eta: 1:51:43  iter: 54339  total_loss: 0.237  loss_cls: 0.024  loss_box_reg: 0.090  loss_mask: 0.102  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8221  data_time: 0.0081  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:14:30 d2.utils.events]: \u001b[0m eta: 1:51:03  iter: 54359  total_loss: 0.218  loss_cls: 0.022  loss_box_reg: 0.074  loss_mask: 0.117  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8222  data_time: 0.0103  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:15:07 d2.utils.events]: \u001b[0m eta: 1:50:29  iter: 54379  total_loss: 0.273  loss_cls: 0.029  loss_box_reg: 0.085  loss_mask: 0.121  loss_rpn_cls: 0.001  loss_rpn_loc: 0.013  time: 1.8223  data_time: 0.0090  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:15:44 d2.utils.events]: \u001b[0m eta: 1:49:52  iter: 54399  total_loss: 0.242  loss_cls: 0.025  loss_box_reg: 0.093  loss_mask: 0.112  loss_rpn_cls: 0.000  loss_rpn_loc: 0.010  time: 1.8225  data_time: 0.0098  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:16:20 d2.utils.events]: \u001b[0m eta: 1:49:16  iter: 54419  total_loss: 0.228  loss_cls: 0.023  loss_box_reg: 0.075  loss_mask: 0.114  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8225  data_time: 0.0106  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:16:55 d2.utils.events]: \u001b[0m eta: 1:48:37  iter: 54439  total_loss: 0.230  loss_cls: 0.021  loss_box_reg: 0.076  loss_mask: 0.115  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8219  data_time: 0.0090  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:17:28 d2.utils.events]: \u001b[0m eta: 1:47:54  iter: 54459  total_loss: 0.256  loss_cls: 0.035  loss_box_reg: 0.095  loss_mask: 0.121  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8213  data_time: 0.0091  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:18:06 d2.utils.events]: \u001b[0m eta: 1:47:17  iter: 54479  total_loss: 0.228  loss_cls: 0.025  loss_box_reg: 0.089  loss_mask: 0.104  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8216  data_time: 0.0081  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:18:43 d2.utils.events]: \u001b[0m eta: 1:46:37  iter: 54499  total_loss: 0.242  loss_cls: 0.020  loss_box_reg: 0.078  loss_mask: 0.115  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8217  data_time: 0.0073  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:19:19 d2.utils.events]: \u001b[0m eta: 1:46:05  iter: 54519  total_loss: 0.184  loss_cls: 0.018  loss_box_reg: 0.071  loss_mask: 0.097  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 1.8217  data_time: 0.0112  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:19:57 d2.utils.events]: \u001b[0m eta: 1:45:31  iter: 54539  total_loss: 0.267  loss_cls: 0.028  loss_box_reg: 0.102  loss_mask: 0.110  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  time: 1.8220  data_time: 0.0104  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:20:35 d2.utils.events]: \u001b[0m eta: 1:44:53  iter: 54559  total_loss: 0.232  loss_cls: 0.017  loss_box_reg: 0.086  loss_mask: 0.109  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8224  data_time: 0.0095  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:21:12 d2.utils.events]: \u001b[0m eta: 1:44:14  iter: 54579  total_loss: 0.238  loss_cls: 0.025  loss_box_reg: 0.088  loss_mask: 0.118  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8225  data_time: 0.0092  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:21:50 d2.utils.events]: \u001b[0m eta: 1:43:45  iter: 54599  total_loss: 0.331  loss_cls: 0.022  loss_box_reg: 0.117  loss_mask: 0.140  loss_rpn_cls: 0.001  loss_rpn_loc: 0.013  time: 1.8228  data_time: 0.0107  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:22:27 d2.utils.events]: \u001b[0m eta: 1:43:07  iter: 54619  total_loss: 0.172  loss_cls: 0.013  loss_box_reg: 0.065  loss_mask: 0.093  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 1.8228  data_time: 0.0115  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:23:05 d2.utils.events]: \u001b[0m eta: 1:42:34  iter: 54639  total_loss: 0.262  loss_cls: 0.022  loss_box_reg: 0.095  loss_mask: 0.122  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  time: 1.8231  data_time: 0.0084  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:23:41 d2.utils.events]: \u001b[0m eta: 1:41:58  iter: 54659  total_loss: 0.270  loss_cls: 0.023  loss_box_reg: 0.104  loss_mask: 0.122  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8231  data_time: 0.0106  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:24:16 d2.utils.events]: \u001b[0m eta: 1:41:20  iter: 54679  total_loss: 0.217  loss_cls: 0.019  loss_box_reg: 0.073  loss_mask: 0.108  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8228  data_time: 0.0104  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:24:52 d2.utils.events]: \u001b[0m eta: 1:40:38  iter: 54699  total_loss: 0.206  loss_cls: 0.025  loss_box_reg: 0.082  loss_mask: 0.122  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  time: 1.8227  data_time: 0.0103  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:25:30 d2.utils.events]: \u001b[0m eta: 1:40:04  iter: 54719  total_loss: 0.228  loss_cls: 0.017  loss_box_reg: 0.087  loss_mask: 0.117  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8229  data_time: 0.0100  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:26:06 d2.utils.events]: \u001b[0m eta: 1:39:20  iter: 54739  total_loss: 0.339  loss_cls: 0.042  loss_box_reg: 0.113  loss_mask: 0.132  loss_rpn_cls: 0.000  loss_rpn_loc: 0.014  time: 1.8228  data_time: 0.0094  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:26:42 d2.utils.events]: \u001b[0m eta: 1:38:45  iter: 54759  total_loss: 0.272  loss_cls: 0.029  loss_box_reg: 0.102  loss_mask: 0.117  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 1.8227  data_time: 0.0089  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:27:17 d2.utils.events]: \u001b[0m eta: 1:38:09  iter: 54779  total_loss: 0.300  loss_cls: 0.028  loss_box_reg: 0.107  loss_mask: 0.146  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  time: 1.8225  data_time: 0.0087  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:27:55 d2.utils.events]: \u001b[0m eta: 1:37:39  iter: 54799  total_loss: 0.251  loss_cls: 0.023  loss_box_reg: 0.099  loss_mask: 0.115  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8228  data_time: 0.0097  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:28:32 d2.utils.events]: \u001b[0m eta: 1:37:04  iter: 54819  total_loss: 0.256  loss_cls: 0.033  loss_box_reg: 0.085  loss_mask: 0.119  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8229  data_time: 0.0089  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:29:10 d2.utils.events]: \u001b[0m eta: 1:36:27  iter: 54839  total_loss: 0.212  loss_cls: 0.020  loss_box_reg: 0.078  loss_mask: 0.105  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8232  data_time: 0.0081  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:29:47 d2.utils.events]: \u001b[0m eta: 1:35:50  iter: 54859  total_loss: 0.259  loss_cls: 0.031  loss_box_reg: 0.089  loss_mask: 0.119  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8234  data_time: 0.0104  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:30:23 d2.utils.events]: \u001b[0m eta: 1:35:09  iter: 54879  total_loss: 0.207  loss_cls: 0.021  loss_box_reg: 0.084  loss_mask: 0.095  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8233  data_time: 0.0106  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:31:00 d2.utils.events]: \u001b[0m eta: 1:34:38  iter: 54899  total_loss: 0.258  loss_cls: 0.022  loss_box_reg: 0.095  loss_mask: 0.130  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  time: 1.8234  data_time: 0.0110  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:31:35 d2.utils.events]: \u001b[0m eta: 1:33:56  iter: 54919  total_loss: 0.246  loss_cls: 0.026  loss_box_reg: 0.085  loss_mask: 0.115  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8230  data_time: 0.0086  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:32:11 d2.utils.events]: \u001b[0m eta: 1:33:24  iter: 54939  total_loss: 0.242  loss_cls: 0.024  loss_box_reg: 0.076  loss_mask: 0.129  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8229  data_time: 0.0089  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:32:47 d2.utils.events]: \u001b[0m eta: 1:32:44  iter: 54959  total_loss: 0.237  loss_cls: 0.025  loss_box_reg: 0.088  loss_mask: 0.107  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8229  data_time: 0.0087  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:33:24 d2.utils.events]: \u001b[0m eta: 1:32:07  iter: 54979  total_loss: 0.307  loss_cls: 0.039  loss_box_reg: 0.118  loss_mask: 0.134  loss_rpn_cls: 0.000  loss_rpn_loc: 0.010  time: 1.8230  data_time: 0.0091  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:34:03 d2.utils.events]: \u001b[0m eta: 1:31:34  iter: 54999  total_loss: 0.205  loss_cls: 0.021  loss_box_reg: 0.077  loss_mask: 0.097  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8230  data_time: 0.0084  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:34:39 d2.utils.events]: \u001b[0m eta: 1:30:58  iter: 55019  total_loss: 0.231  loss_cls: 0.023  loss_box_reg: 0.084  loss_mask: 0.109  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8230  data_time: 0.0099  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:35:16 d2.utils.events]: \u001b[0m eta: 1:30:23  iter: 55039  total_loss: 0.212  loss_cls: 0.019  loss_box_reg: 0.086  loss_mask: 0.113  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8231  data_time: 0.0093  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:35:53 d2.utils.events]: \u001b[0m eta: 1:29:44  iter: 55059  total_loss: 0.272  loss_cls: 0.034  loss_box_reg: 0.101  loss_mask: 0.124  loss_rpn_cls: 0.001  loss_rpn_loc: 0.018  time: 1.8231  data_time: 0.0103  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:36:30 d2.utils.events]: \u001b[0m eta: 1:29:08  iter: 55079  total_loss: 0.257  loss_cls: 0.026  loss_box_reg: 0.105  loss_mask: 0.118  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8233  data_time: 0.0093  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:37:06 d2.utils.events]: \u001b[0m eta: 1:28:30  iter: 55099  total_loss: 0.255  loss_cls: 0.024  loss_box_reg: 0.101  loss_mask: 0.117  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 1.8231  data_time: 0.0083  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:37:42 d2.utils.events]: \u001b[0m eta: 1:27:54  iter: 55119  total_loss: 0.244  loss_cls: 0.023  loss_box_reg: 0.104  loss_mask: 0.125  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  time: 1.8231  data_time: 0.0099  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:38:20 d2.utils.events]: \u001b[0m eta: 1:27:22  iter: 55139  total_loss: 0.238  loss_cls: 0.020  loss_box_reg: 0.090  loss_mask: 0.114  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8234  data_time: 0.0092  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:38:56 d2.utils.events]: \u001b[0m eta: 1:26:42  iter: 55159  total_loss: 0.288  loss_cls: 0.022  loss_box_reg: 0.112  loss_mask: 0.140  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  time: 1.8233  data_time: 0.0097  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:39:32 d2.utils.events]: \u001b[0m eta: 1:26:04  iter: 55179  total_loss: 0.225  loss_cls: 0.028  loss_box_reg: 0.088  loss_mask: 0.103  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8231  data_time: 0.0080  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:40:08 d2.utils.events]: \u001b[0m eta: 1:25:28  iter: 55199  total_loss: 0.248  loss_cls: 0.030  loss_box_reg: 0.084  loss_mask: 0.124  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 1.8231  data_time: 0.0095  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:40:45 d2.utils.events]: \u001b[0m eta: 1:24:52  iter: 55219  total_loss: 0.263  loss_cls: 0.022  loss_box_reg: 0.100  loss_mask: 0.124  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8232  data_time: 0.0086  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:41:23 d2.utils.events]: \u001b[0m eta: 1:24:23  iter: 55239  total_loss: 0.236  loss_cls: 0.029  loss_box_reg: 0.089  loss_mask: 0.108  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8236  data_time: 0.0087  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:41:59 d2.utils.events]: \u001b[0m eta: 1:23:50  iter: 55259  total_loss: 0.221  loss_cls: 0.023  loss_box_reg: 0.090  loss_mask: 0.098  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8235  data_time: 0.0111  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:42:36 d2.utils.events]: \u001b[0m eta: 1:23:15  iter: 55279  total_loss: 0.228  loss_cls: 0.028  loss_box_reg: 0.090  loss_mask: 0.100  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8235  data_time: 0.0103  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:43:14 d2.utils.events]: \u001b[0m eta: 1:22:40  iter: 55299  total_loss: 0.281  loss_cls: 0.023  loss_box_reg: 0.101  loss_mask: 0.120  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 1.8238  data_time: 0.0086  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:43:50 d2.utils.events]: \u001b[0m eta: 1:22:04  iter: 55319  total_loss: 0.243  loss_cls: 0.027  loss_box_reg: 0.083  loss_mask: 0.108  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8237  data_time: 0.0095  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:44:25 d2.utils.events]: \u001b[0m eta: 1:21:25  iter: 55339  total_loss: 0.244  loss_cls: 0.021  loss_box_reg: 0.098  loss_mask: 0.114  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 1.8234  data_time: 0.0102  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:45:02 d2.utils.events]: \u001b[0m eta: 1:20:48  iter: 55359  total_loss: 0.226  loss_cls: 0.030  loss_box_reg: 0.080  loss_mask: 0.106  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8234  data_time: 0.0121  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:45:38 d2.utils.events]: \u001b[0m eta: 1:20:11  iter: 55379  total_loss: 0.247  loss_cls: 0.023  loss_box_reg: 0.089  loss_mask: 0.126  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8233  data_time: 0.0118  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:46:15 d2.utils.events]: \u001b[0m eta: 1:19:34  iter: 55399  total_loss: 0.214  loss_cls: 0.021  loss_box_reg: 0.073  loss_mask: 0.101  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8234  data_time: 0.0133  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:46:49 d2.utils.events]: \u001b[0m eta: 1:18:53  iter: 55419  total_loss: 0.281  loss_cls: 0.027  loss_box_reg: 0.103  loss_mask: 0.123  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8231  data_time: 0.0091  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:47:27 d2.utils.events]: \u001b[0m eta: 1:18:26  iter: 55439  total_loss: 0.222  loss_cls: 0.019  loss_box_reg: 0.072  loss_mask: 0.098  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8233  data_time: 0.0091  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:48:03 d2.utils.events]: \u001b[0m eta: 1:17:53  iter: 55459  total_loss: 0.306  loss_cls: 0.031  loss_box_reg: 0.122  loss_mask: 0.120  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 1.8231  data_time: 0.0082  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:48:38 d2.utils.events]: \u001b[0m eta: 1:17:09  iter: 55479  total_loss: 0.281  loss_cls: 0.038  loss_box_reg: 0.106  loss_mask: 0.129  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  time: 1.8230  data_time: 0.0075  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:49:15 d2.utils.events]: \u001b[0m eta: 1:16:37  iter: 55499  total_loss: 0.222  loss_cls: 0.028  loss_box_reg: 0.087  loss_mask: 0.107  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 1.8230  data_time: 0.0106  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:49:52 d2.utils.events]: \u001b[0m eta: 1:16:00  iter: 55519  total_loss: 0.223  loss_cls: 0.025  loss_box_reg: 0.086  loss_mask: 0.092  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8232  data_time: 0.0136  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:50:29 d2.utils.events]: \u001b[0m eta: 1:15:22  iter: 55539  total_loss: 0.268  loss_cls: 0.033  loss_box_reg: 0.096  loss_mask: 0.121  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8232  data_time: 0.0093  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:51:06 d2.utils.events]: \u001b[0m eta: 1:14:42  iter: 55559  total_loss: 0.193  loss_cls: 0.022  loss_box_reg: 0.063  loss_mask: 0.106  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 1.8233  data_time: 0.0085  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:51:41 d2.utils.events]: \u001b[0m eta: 1:14:05  iter: 55579  total_loss: 0.307  loss_cls: 0.037  loss_box_reg: 0.105  loss_mask: 0.124  loss_rpn_cls: 0.000  loss_rpn_loc: 0.013  time: 1.8231  data_time: 0.0120  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:52:18 d2.utils.events]: \u001b[0m eta: 1:13:23  iter: 55599  total_loss: 0.229  loss_cls: 0.035  loss_box_reg: 0.088  loss_mask: 0.108  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8232  data_time: 0.0086  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:52:55 d2.utils.events]: \u001b[0m eta: 1:12:50  iter: 55619  total_loss: 0.232  loss_cls: 0.021  loss_box_reg: 0.083  loss_mask: 0.105  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8233  data_time: 0.0085  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:53:33 d2.utils.events]: \u001b[0m eta: 1:12:11  iter: 55639  total_loss: 0.232  loss_cls: 0.016  loss_box_reg: 0.082  loss_mask: 0.129  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8234  data_time: 0.0111  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:54:09 d2.utils.events]: \u001b[0m eta: 1:11:35  iter: 55659  total_loss: 0.256  loss_cls: 0.035  loss_box_reg: 0.097  loss_mask: 0.116  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8234  data_time: 0.0101  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:54:45 d2.utils.events]: \u001b[0m eta: 1:11:00  iter: 55679  total_loss: 0.230  loss_cls: 0.021  loss_box_reg: 0.081  loss_mask: 0.109  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 1.8233  data_time: 0.0107  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:55:21 d2.utils.events]: \u001b[0m eta: 1:10:27  iter: 55699  total_loss: 0.281  loss_cls: 0.027  loss_box_reg: 0.097  loss_mask: 0.134  loss_rpn_cls: 0.000  loss_rpn_loc: 0.011  time: 1.8233  data_time: 0.0096  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:55:57 d2.utils.events]: \u001b[0m eta: 1:09:47  iter: 55719  total_loss: 0.260  loss_cls: 0.026  loss_box_reg: 0.091  loss_mask: 0.119  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  time: 1.8232  data_time: 0.0103  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:56:33 d2.utils.events]: \u001b[0m eta: 1:09:10  iter: 55739  total_loss: 0.227  loss_cls: 0.024  loss_box_reg: 0.097  loss_mask: 0.096  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8231  data_time: 0.0103  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:57:09 d2.utils.events]: \u001b[0m eta: 1:08:31  iter: 55759  total_loss: 0.264  loss_cls: 0.023  loss_box_reg: 0.104  loss_mask: 0.133  loss_rpn_cls: 0.000  loss_rpn_loc: 0.010  time: 1.8230  data_time: 0.0100  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:57:45 d2.utils.events]: \u001b[0m eta: 1:07:54  iter: 55779  total_loss: 0.224  loss_cls: 0.020  loss_box_reg: 0.092  loss_mask: 0.101  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8229  data_time: 0.0091  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:58:22 d2.utils.events]: \u001b[0m eta: 1:07:11  iter: 55799  total_loss: 0.286  loss_cls: 0.032  loss_box_reg: 0.107  loss_mask: 0.128  loss_rpn_cls: 0.000  loss_rpn_loc: 0.010  time: 1.8230  data_time: 0.0128  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:58:58 d2.utils.events]: \u001b[0m eta: 1:06:30  iter: 55819  total_loss: 0.234  loss_cls: 0.021  loss_box_reg: 0.077  loss_mask: 0.115  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8229  data_time: 0.0096  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 08:59:33 d2.utils.events]: \u001b[0m eta: 1:05:50  iter: 55839  total_loss: 0.237  loss_cls: 0.023  loss_box_reg: 0.078  loss_mask: 0.120  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8227  data_time: 0.0088  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:00:10 d2.utils.events]: \u001b[0m eta: 1:05:11  iter: 55859  total_loss: 0.240  loss_cls: 0.022  loss_box_reg: 0.092  loss_mask: 0.099  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8227  data_time: 0.0088  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:00:45 d2.utils.events]: \u001b[0m eta: 1:04:34  iter: 55879  total_loss: 0.248  loss_cls: 0.018  loss_box_reg: 0.085  loss_mask: 0.119  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 1.8226  data_time: 0.0095  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:01:23 d2.utils.events]: \u001b[0m eta: 1:03:58  iter: 55899  total_loss: 0.255  loss_cls: 0.030  loss_box_reg: 0.096  loss_mask: 0.127  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8227  data_time: 0.0106  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:01:58 d2.utils.events]: \u001b[0m eta: 1:03:24  iter: 55919  total_loss: 0.301  loss_cls: 0.031  loss_box_reg: 0.112  loss_mask: 0.133  loss_rpn_cls: 0.000  loss_rpn_loc: 0.012  time: 1.8226  data_time: 0.0083  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:02:36 d2.utils.events]: \u001b[0m eta: 1:02:48  iter: 55939  total_loss: 0.212  loss_cls: 0.020  loss_box_reg: 0.083  loss_mask: 0.107  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8228  data_time: 0.0109  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:03:12 d2.utils.events]: \u001b[0m eta: 1:02:12  iter: 55959  total_loss: 0.258  loss_cls: 0.028  loss_box_reg: 0.088  loss_mask: 0.120  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  time: 1.8228  data_time: 0.0095  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:03:48 d2.utils.events]: \u001b[0m eta: 1:01:35  iter: 55979  total_loss: 0.274  loss_cls: 0.025  loss_box_reg: 0.103  loss_mask: 0.119  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8226  data_time: 0.0091  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:04:26 d2.utils.events]: \u001b[0m eta: 1:00:56  iter: 55999  total_loss: 0.251  loss_cls: 0.031  loss_box_reg: 0.093  loss_mask: 0.127  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8225  data_time: 0.0106  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:05:02 d2.utils.events]: \u001b[0m eta: 1:00:18  iter: 56019  total_loss: 0.251  loss_cls: 0.024  loss_box_reg: 0.107  loss_mask: 0.124  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 1.8224  data_time: 0.0086  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:05:38 d2.utils.events]: \u001b[0m eta: 0:59:41  iter: 56039  total_loss: 0.298  loss_cls: 0.040  loss_box_reg: 0.102  loss_mask: 0.118  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 1.8223  data_time: 0.0085  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:06:16 d2.utils.events]: \u001b[0m eta: 0:59:08  iter: 56059  total_loss: 0.230  loss_cls: 0.020  loss_box_reg: 0.083  loss_mask: 0.119  loss_rpn_cls: 0.000  loss_rpn_loc: 0.011  time: 1.8225  data_time: 0.0099  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:06:52 d2.utils.events]: \u001b[0m eta: 0:58:28  iter: 56079  total_loss: 0.219  loss_cls: 0.025  loss_box_reg: 0.077  loss_mask: 0.101  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8225  data_time: 0.0093  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:07:28 d2.utils.events]: \u001b[0m eta: 0:57:55  iter: 56099  total_loss: 0.218  loss_cls: 0.017  loss_box_reg: 0.078  loss_mask: 0.120  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8225  data_time: 0.0107  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:08:06 d2.utils.events]: \u001b[0m eta: 0:57:22  iter: 56119  total_loss: 0.227  loss_cls: 0.033  loss_box_reg: 0.089  loss_mask: 0.110  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  time: 1.8227  data_time: 0.0110  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:08:43 d2.utils.events]: \u001b[0m eta: 0:56:44  iter: 56139  total_loss: 0.244  loss_cls: 0.026  loss_box_reg: 0.079  loss_mask: 0.114  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8227  data_time: 0.0092  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:09:19 d2.utils.events]: \u001b[0m eta: 0:56:10  iter: 56159  total_loss: 0.209  loss_cls: 0.019  loss_box_reg: 0.088  loss_mask: 0.104  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8227  data_time: 0.0103  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:09:54 d2.utils.events]: \u001b[0m eta: 0:55:32  iter: 56179  total_loss: 0.200  loss_cls: 0.023  loss_box_reg: 0.083  loss_mask: 0.091  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8224  data_time: 0.0114  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:10:31 d2.utils.events]: \u001b[0m eta: 0:54:54  iter: 56199  total_loss: 0.200  loss_cls: 0.023  loss_box_reg: 0.080  loss_mask: 0.095  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8225  data_time: 0.0092  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:11:08 d2.utils.events]: \u001b[0m eta: 0:54:18  iter: 56219  total_loss: 0.227  loss_cls: 0.023  loss_box_reg: 0.092  loss_mask: 0.099  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8227  data_time: 0.0074  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:11:45 d2.utils.events]: \u001b[0m eta: 0:53:39  iter: 56239  total_loss: 0.190  loss_cls: 0.014  loss_box_reg: 0.074  loss_mask: 0.103  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 1.8227  data_time: 0.0086  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:12:20 d2.utils.events]: \u001b[0m eta: 0:53:00  iter: 56259  total_loss: 0.208  loss_cls: 0.028  loss_box_reg: 0.086  loss_mask: 0.096  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  time: 1.8224  data_time: 0.0084  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:12:56 d2.utils.events]: \u001b[0m eta: 0:52:22  iter: 56279  total_loss: 0.234  loss_cls: 0.029  loss_box_reg: 0.082  loss_mask: 0.122  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8223  data_time: 0.0104  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:13:30 d2.utils.events]: \u001b[0m eta: 0:51:42  iter: 56299  total_loss: 0.209  loss_cls: 0.019  loss_box_reg: 0.086  loss_mask: 0.107  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 1.8219  data_time: 0.0087  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:14:06 d2.utils.events]: \u001b[0m eta: 0:51:06  iter: 56319  total_loss: 0.214  loss_cls: 0.026  loss_box_reg: 0.087  loss_mask: 0.087  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8220  data_time: 0.0086  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:14:43 d2.utils.events]: \u001b[0m eta: 0:50:31  iter: 56339  total_loss: 0.221  loss_cls: 0.025  loss_box_reg: 0.084  loss_mask: 0.091  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8220  data_time: 0.0087  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:15:21 d2.utils.events]: \u001b[0m eta: 0:49:54  iter: 56359  total_loss: 0.270  loss_cls: 0.039  loss_box_reg: 0.099  loss_mask: 0.108  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  time: 1.8222  data_time: 0.0094  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:15:57 d2.utils.events]: \u001b[0m eta: 0:49:20  iter: 56379  total_loss: 0.319  loss_cls: 0.032  loss_box_reg: 0.122  loss_mask: 0.137  loss_rpn_cls: 0.000  loss_rpn_loc: 0.013  time: 1.8222  data_time: 0.0087  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:16:35 d2.utils.events]: \u001b[0m eta: 0:48:43  iter: 56399  total_loss: 0.321  loss_cls: 0.028  loss_box_reg: 0.115  loss_mask: 0.156  loss_rpn_cls: 0.001  loss_rpn_loc: 0.014  time: 1.8224  data_time: 0.0080  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:17:11 d2.utils.events]: \u001b[0m eta: 0:48:07  iter: 56419  total_loss: 0.205  loss_cls: 0.029  loss_box_reg: 0.075  loss_mask: 0.099  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8223  data_time: 0.0106  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:17:48 d2.utils.events]: \u001b[0m eta: 0:47:29  iter: 56439  total_loss: 0.226  loss_cls: 0.028  loss_box_reg: 0.082  loss_mask: 0.108  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8224  data_time: 0.0078  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:18:25 d2.utils.events]: \u001b[0m eta: 0:46:54  iter: 56459  total_loss: 0.244  loss_cls: 0.027  loss_box_reg: 0.086  loss_mask: 0.126  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  time: 1.8224  data_time: 0.0088  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:19:00 d2.utils.events]: \u001b[0m eta: 0:46:19  iter: 56479  total_loss: 0.277  loss_cls: 0.035  loss_box_reg: 0.099  loss_mask: 0.131  loss_rpn_cls: 0.000  loss_rpn_loc: 0.013  time: 1.8223  data_time: 0.0095  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:19:36 d2.utils.events]: \u001b[0m eta: 0:45:40  iter: 56499  total_loss: 0.252  loss_cls: 0.026  loss_box_reg: 0.096  loss_mask: 0.130  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  time: 1.8222  data_time: 0.0100  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:20:14 d2.utils.events]: \u001b[0m eta: 0:45:03  iter: 56519  total_loss: 0.267  loss_cls: 0.032  loss_box_reg: 0.103  loss_mask: 0.133  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  time: 1.8224  data_time: 0.0103  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:20:50 d2.utils.events]: \u001b[0m eta: 0:44:26  iter: 56539  total_loss: 0.219  loss_cls: 0.019  loss_box_reg: 0.086  loss_mask: 0.125  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8223  data_time: 0.0096  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:21:28 d2.utils.events]: \u001b[0m eta: 0:43:50  iter: 56559  total_loss: 0.243  loss_cls: 0.025  loss_box_reg: 0.097  loss_mask: 0.115  loss_rpn_cls: 0.000  loss_rpn_loc: 0.010  time: 1.8226  data_time: 0.0084  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:22:05 d2.utils.events]: \u001b[0m eta: 0:43:16  iter: 56579  total_loss: 0.276  loss_cls: 0.021  loss_box_reg: 0.090  loss_mask: 0.126  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8226  data_time: 0.0088  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:22:41 d2.utils.events]: \u001b[0m eta: 0:42:41  iter: 56599  total_loss: 0.202  loss_cls: 0.024  loss_box_reg: 0.084  loss_mask: 0.116  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8226  data_time: 0.0087  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:23:18 d2.utils.events]: \u001b[0m eta: 0:42:07  iter: 56619  total_loss: 0.227  loss_cls: 0.022  loss_box_reg: 0.088  loss_mask: 0.105  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8228  data_time: 0.0081  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:23:54 d2.utils.events]: \u001b[0m eta: 0:41:28  iter: 56639  total_loss: 0.295  loss_cls: 0.032  loss_box_reg: 0.110  loss_mask: 0.132  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 1.8226  data_time: 0.0113  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:24:29 d2.utils.events]: \u001b[0m eta: 0:40:50  iter: 56659  total_loss: 0.231  loss_cls: 0.027  loss_box_reg: 0.085  loss_mask: 0.109  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8224  data_time: 0.0108  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:25:06 d2.utils.events]: \u001b[0m eta: 0:40:15  iter: 56679  total_loss: 0.246  loss_cls: 0.020  loss_box_reg: 0.090  loss_mask: 0.118  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8224  data_time: 0.0097  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:25:42 d2.utils.events]: \u001b[0m eta: 0:39:38  iter: 56699  total_loss: 0.213  loss_cls: 0.017  loss_box_reg: 0.076  loss_mask: 0.103  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8225  data_time: 0.0081  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:26:18 d2.utils.events]: \u001b[0m eta: 0:39:02  iter: 56719  total_loss: 0.223  loss_cls: 0.021  loss_box_reg: 0.081  loss_mask: 0.102  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8224  data_time: 0.0094  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:26:57 d2.utils.events]: \u001b[0m eta: 0:38:29  iter: 56739  total_loss: 0.232  loss_cls: 0.027  loss_box_reg: 0.080  loss_mask: 0.103  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8228  data_time: 0.0079  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:27:34 d2.utils.events]: \u001b[0m eta: 0:37:55  iter: 56759  total_loss: 0.250  loss_cls: 0.019  loss_box_reg: 0.092  loss_mask: 0.134  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8228  data_time: 0.0092  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:28:11 d2.utils.events]: \u001b[0m eta: 0:37:19  iter: 56779  total_loss: 0.238  loss_cls: 0.026  loss_box_reg: 0.086  loss_mask: 0.120  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8229  data_time: 0.0098  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:28:47 d2.utils.events]: \u001b[0m eta: 0:36:42  iter: 56799  total_loss: 0.212  loss_cls: 0.020  loss_box_reg: 0.079  loss_mask: 0.120  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  time: 1.8228  data_time: 0.0106  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:29:24 d2.utils.events]: \u001b[0m eta: 0:36:07  iter: 56819  total_loss: 0.248  loss_cls: 0.023  loss_box_reg: 0.093  loss_mask: 0.119  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8228  data_time: 0.0087  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:29:59 d2.utils.events]: \u001b[0m eta: 0:35:31  iter: 56839  total_loss: 0.335  loss_cls: 0.029  loss_box_reg: 0.125  loss_mask: 0.132  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 1.8227  data_time: 0.0093  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:30:36 d2.utils.events]: \u001b[0m eta: 0:34:53  iter: 56859  total_loss: 0.224  loss_cls: 0.020  loss_box_reg: 0.088  loss_mask: 0.113  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8227  data_time: 0.0095  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:31:11 d2.utils.events]: \u001b[0m eta: 0:34:17  iter: 56879  total_loss: 0.255  loss_cls: 0.021  loss_box_reg: 0.090  loss_mask: 0.129  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 1.8226  data_time: 0.0095  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:31:47 d2.utils.events]: \u001b[0m eta: 0:33:38  iter: 56899  total_loss: 0.217  loss_cls: 0.022  loss_box_reg: 0.084  loss_mask: 0.097  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8224  data_time: 0.0097  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:32:23 d2.utils.events]: \u001b[0m eta: 0:33:02  iter: 56919  total_loss: 0.242  loss_cls: 0.027  loss_box_reg: 0.085  loss_mask: 0.122  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8223  data_time: 0.0095  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:33:00 d2.utils.events]: \u001b[0m eta: 0:32:25  iter: 56939  total_loss: 0.251  loss_cls: 0.024  loss_box_reg: 0.098  loss_mask: 0.119  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8225  data_time: 0.0105  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:33:35 d2.utils.events]: \u001b[0m eta: 0:31:48  iter: 56959  total_loss: 0.205  loss_cls: 0.022  loss_box_reg: 0.086  loss_mask: 0.102  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8223  data_time: 0.0094  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:34:12 d2.utils.events]: \u001b[0m eta: 0:31:12  iter: 56979  total_loss: 0.236  loss_cls: 0.025  loss_box_reg: 0.089  loss_mask: 0.112  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8223  data_time: 0.0079  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:34:49 d2.utils.events]: \u001b[0m eta: 0:30:35  iter: 56999  total_loss: 0.218  loss_cls: 0.023  loss_box_reg: 0.087  loss_mask: 0.113  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8221  data_time: 0.0092  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:35:24 d2.utils.events]: \u001b[0m eta: 0:29:59  iter: 57019  total_loss: 0.237  loss_cls: 0.019  loss_box_reg: 0.097  loss_mask: 0.105  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8219  data_time: 0.0074  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:36:00 d2.utils.events]: \u001b[0m eta: 0:29:21  iter: 57039  total_loss: 0.264  loss_cls: 0.029  loss_box_reg: 0.105  loss_mask: 0.112  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8218  data_time: 0.0084  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:36:35 d2.utils.events]: \u001b[0m eta: 0:28:42  iter: 57059  total_loss: 0.229  loss_cls: 0.027  loss_box_reg: 0.083  loss_mask: 0.108  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8217  data_time: 0.0110  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:37:12 d2.utils.events]: \u001b[0m eta: 0:28:05  iter: 57079  total_loss: 0.225  loss_cls: 0.024  loss_box_reg: 0.081  loss_mask: 0.110  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8218  data_time: 0.0079  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:37:48 d2.utils.events]: \u001b[0m eta: 0:27:27  iter: 57099  total_loss: 0.290  loss_cls: 0.029  loss_box_reg: 0.110  loss_mask: 0.117  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  time: 1.8216  data_time: 0.0095  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:38:23 d2.utils.events]: \u001b[0m eta: 0:26:48  iter: 57119  total_loss: 0.233  loss_cls: 0.023  loss_box_reg: 0.088  loss_mask: 0.102  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8215  data_time: 0.0093  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:39:00 d2.utils.events]: \u001b[0m eta: 0:26:10  iter: 57139  total_loss: 0.240  loss_cls: 0.030  loss_box_reg: 0.094  loss_mask: 0.107  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8216  data_time: 0.0082  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:39:36 d2.utils.events]: \u001b[0m eta: 0:25:33  iter: 57159  total_loss: 0.238  loss_cls: 0.025  loss_box_reg: 0.099  loss_mask: 0.117  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8215  data_time: 0.0087  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:40:12 d2.utils.events]: \u001b[0m eta: 0:24:57  iter: 57179  total_loss: 0.240  loss_cls: 0.028  loss_box_reg: 0.095  loss_mask: 0.128  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  time: 1.8214  data_time: 0.0094  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:40:47 d2.utils.events]: \u001b[0m eta: 0:24:19  iter: 57199  total_loss: 0.229  loss_cls: 0.023  loss_box_reg: 0.098  loss_mask: 0.105  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8213  data_time: 0.0078  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:41:23 d2.utils.events]: \u001b[0m eta: 0:23:42  iter: 57219  total_loss: 0.238  loss_cls: 0.023  loss_box_reg: 0.086  loss_mask: 0.122  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8212  data_time: 0.0097  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:41:59 d2.utils.events]: \u001b[0m eta: 0:23:05  iter: 57239  total_loss: 0.236  loss_cls: 0.026  loss_box_reg: 0.078  loss_mask: 0.109  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 1.8211  data_time: 0.0087  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:42:35 d2.utils.events]: \u001b[0m eta: 0:22:31  iter: 57259  total_loss: 0.250  loss_cls: 0.026  loss_box_reg: 0.080  loss_mask: 0.113  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8210  data_time: 0.0088  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:43:11 d2.utils.events]: \u001b[0m eta: 0:21:56  iter: 57279  total_loss: 0.239  loss_cls: 0.023  loss_box_reg: 0.087  loss_mask: 0.126  loss_rpn_cls: 0.000  loss_rpn_loc: 0.011  time: 1.8210  data_time: 0.0087  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:43:48 d2.utils.events]: \u001b[0m eta: 0:21:21  iter: 57299  total_loss: 0.187  loss_cls: 0.018  loss_box_reg: 0.078  loss_mask: 0.110  loss_rpn_cls: 0.000  loss_rpn_loc: 0.010  time: 1.8210  data_time: 0.0099  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:44:24 d2.utils.events]: \u001b[0m eta: 0:20:43  iter: 57319  total_loss: 0.240  loss_cls: 0.026  loss_box_reg: 0.091  loss_mask: 0.114  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 1.8209  data_time: 0.0090  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:45:02 d2.utils.events]: \u001b[0m eta: 0:20:08  iter: 57339  total_loss: 0.264  loss_cls: 0.020  loss_box_reg: 0.092  loss_mask: 0.123  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8212  data_time: 0.0083  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:45:39 d2.utils.events]: \u001b[0m eta: 0:19:31  iter: 57359  total_loss: 0.231  loss_cls: 0.024  loss_box_reg: 0.091  loss_mask: 0.101  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8212  data_time: 0.0102  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:46:14 d2.utils.events]: \u001b[0m eta: 0:18:53  iter: 57379  total_loss: 0.240  loss_cls: 0.028  loss_box_reg: 0.086  loss_mask: 0.118  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 1.8211  data_time: 0.0077  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:46:48 d2.utils.events]: \u001b[0m eta: 0:18:14  iter: 57399  total_loss: 0.224  loss_cls: 0.019  loss_box_reg: 0.089  loss_mask: 0.112  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8207  data_time: 0.0095  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:47:21 d2.utils.events]: \u001b[0m eta: 0:17:35  iter: 57419  total_loss: 0.258  loss_cls: 0.026  loss_box_reg: 0.099  loss_mask: 0.116  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8203  data_time: 0.0105  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:47:57 d2.utils.events]: \u001b[0m eta: 0:16:58  iter: 57439  total_loss: 0.206  loss_cls: 0.024  loss_box_reg: 0.065  loss_mask: 0.095  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8202  data_time: 0.0102  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:48:33 d2.utils.events]: \u001b[0m eta: 0:16:22  iter: 57459  total_loss: 0.270  loss_cls: 0.021  loss_box_reg: 0.101  loss_mask: 0.127  loss_rpn_cls: 0.000  loss_rpn_loc: 0.010  time: 1.8202  data_time: 0.0097  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:49:09 d2.utils.events]: \u001b[0m eta: 0:15:46  iter: 57479  total_loss: 0.265  loss_cls: 0.023  loss_box_reg: 0.089  loss_mask: 0.111  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 1.8202  data_time: 0.0089  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:49:46 d2.utils.events]: \u001b[0m eta: 0:15:10  iter: 57499  total_loss: 0.253  loss_cls: 0.018  loss_box_reg: 0.096  loss_mask: 0.118  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  time: 1.8202  data_time: 0.0091  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:50:22 d2.utils.events]: \u001b[0m eta: 0:14:33  iter: 57519  total_loss: 0.259  loss_cls: 0.031  loss_box_reg: 0.097  loss_mask: 0.116  loss_rpn_cls: 0.000  loss_rpn_loc: 0.010  time: 1.8202  data_time: 0.0084  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:51:00 d2.utils.events]: \u001b[0m eta: 0:13:57  iter: 57539  total_loss: 0.302  loss_cls: 0.033  loss_box_reg: 0.116  loss_mask: 0.123  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8203  data_time: 0.0083  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:51:36 d2.utils.events]: \u001b[0m eta: 0:13:20  iter: 57559  total_loss: 0.201  loss_cls: 0.017  loss_box_reg: 0.091  loss_mask: 0.093  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8203  data_time: 0.0082  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:52:11 d2.utils.events]: \u001b[0m eta: 0:12:43  iter: 57579  total_loss: 0.257  loss_cls: 0.025  loss_box_reg: 0.092  loss_mask: 0.127  loss_rpn_cls: 0.000  loss_rpn_loc: 0.010  time: 1.8201  data_time: 0.0100  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:52:48 d2.utils.events]: \u001b[0m eta: 0:12:06  iter: 57599  total_loss: 0.257  loss_cls: 0.028  loss_box_reg: 0.101  loss_mask: 0.115  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  time: 1.8201  data_time: 0.0091  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:53:25 d2.utils.events]: \u001b[0m eta: 0:11:29  iter: 57619  total_loss: 0.194  loss_cls: 0.013  loss_box_reg: 0.078  loss_mask: 0.097  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 1.8202  data_time: 0.0103  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:54:02 d2.utils.events]: \u001b[0m eta: 0:10:53  iter: 57639  total_loss: 0.211  loss_cls: 0.019  loss_box_reg: 0.080  loss_mask: 0.105  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8203  data_time: 0.0087  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:54:38 d2.utils.events]: \u001b[0m eta: 0:10:18  iter: 57659  total_loss: 0.202  loss_cls: 0.023  loss_box_reg: 0.066  loss_mask: 0.097  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 1.8203  data_time: 0.0082  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:55:15 d2.utils.events]: \u001b[0m eta: 0:09:41  iter: 57679  total_loss: 0.174  loss_cls: 0.017  loss_box_reg: 0.068  loss_mask: 0.091  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 1.8203  data_time: 0.0110  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:55:51 d2.utils.events]: \u001b[0m eta: 0:09:05  iter: 57699  total_loss: 0.282  loss_cls: 0.032  loss_box_reg: 0.101  loss_mask: 0.132  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 1.8203  data_time: 0.0074  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:56:27 d2.utils.events]: \u001b[0m eta: 0:08:29  iter: 57719  total_loss: 0.200  loss_cls: 0.026  loss_box_reg: 0.076  loss_mask: 0.115  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 1.8203  data_time: 0.0105  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:57:03 d2.utils.events]: \u001b[0m eta: 0:07:52  iter: 57739  total_loss: 0.223  loss_cls: 0.018  loss_box_reg: 0.088  loss_mask: 0.115  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8202  data_time: 0.0095  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:57:38 d2.utils.events]: \u001b[0m eta: 0:07:15  iter: 57759  total_loss: 0.295  loss_cls: 0.033  loss_box_reg: 0.100  loss_mask: 0.123  loss_rpn_cls: 0.001  loss_rpn_loc: 0.015  time: 1.8200  data_time: 0.0092  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:58:15 d2.utils.events]: \u001b[0m eta: 0:06:39  iter: 57779  total_loss: 0.219  loss_cls: 0.032  loss_box_reg: 0.088  loss_mask: 0.114  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  time: 1.8201  data_time: 0.0112  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:58:49 d2.utils.events]: \u001b[0m eta: 0:06:03  iter: 57799  total_loss: 0.292  loss_cls: 0.027  loss_box_reg: 0.120  loss_mask: 0.124  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 1.8198  data_time: 0.0079  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:59:24 d2.utils.events]: \u001b[0m eta: 0:05:26  iter: 57819  total_loss: 0.212  loss_cls: 0.021  loss_box_reg: 0.083  loss_mask: 0.107  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8196  data_time: 0.0088  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 09:59:59 d2.utils.events]: \u001b[0m eta: 0:04:50  iter: 57839  total_loss: 0.240  loss_cls: 0.024  loss_box_reg: 0.088  loss_mask: 0.113  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 1.8194  data_time: 0.0080  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 10:00:35 d2.utils.events]: \u001b[0m eta: 0:04:14  iter: 57859  total_loss: 0.242  loss_cls: 0.022  loss_box_reg: 0.094  loss_mask: 0.109  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8194  data_time: 0.0092  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 10:01:10 d2.utils.events]: \u001b[0m eta: 0:03:38  iter: 57879  total_loss: 0.244  loss_cls: 0.030  loss_box_reg: 0.085  loss_mask: 0.110  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  time: 1.8192  data_time: 0.0108  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 10:01:47 d2.utils.events]: \u001b[0m eta: 0:03:02  iter: 57899  total_loss: 0.221  loss_cls: 0.020  loss_box_reg: 0.090  loss_mask: 0.109  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 1.8192  data_time: 0.0076  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 10:02:23 d2.utils.events]: \u001b[0m eta: 0:02:26  iter: 57919  total_loss: 0.226  loss_cls: 0.020  loss_box_reg: 0.079  loss_mask: 0.111  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8192  data_time: 0.0088  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 10:03:00 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 57939  total_loss: 0.234  loss_cls: 0.022  loss_box_reg: 0.074  loss_mask: 0.124  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  time: 1.8192  data_time: 0.0111  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 10:03:37 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 57959  total_loss: 0.212  loss_cls: 0.025  loss_box_reg: 0.084  loss_mask: 0.105  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8193  data_time: 0.0079  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 10:04:14 d2.utils.events]: \u001b[0m eta: 0:00:37  iter: 57979  total_loss: 0.246  loss_cls: 0.024  loss_box_reg: 0.088  loss_mask: 0.127  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 1.8194  data_time: 0.0088  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 10:04:54 d2.data.datasets.coco]: \u001b[0mLoaded 190 images in COCO format from /content/drive/MyDrive/detectron2_500/test.json\n",
            "\u001b[32m[09/02 10:04:54 d2.data.build]: \u001b[0mDistribution of instances among all 6 categories:\n",
            "\u001b[36m|  category  | #instances   |  category  | #instances   |   category    | #instances   |\n",
            "|:----------:|:-------------|:----------:|:-------------|:-------------:|:-------------|\n",
            "| aeroplane  | 100          |    car     | 99           |     chair     | 99           |\n",
            "|    cow     | 100          |   person   | 100          | traffic_light | 99           |\n",
            "|            |              |            |              |               |              |\n",
            "|   total    | 597          |            |              |               |              |\u001b[0m\n",
            "\u001b[32m[09/02 10:04:54 d2.data.common]: \u001b[0mSerializing 190 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[09/02 10:04:54 d2.data.common]: \u001b[0mSerialized dataset takes 0.34 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/02 10:04:54 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
            "\u001b[32m[09/02 10:04:54 d2.utils.events]: \u001b[0m eta: 0:00:01  iter: 57999  total_loss: 0.237  loss_cls: 0.023  loss_box_reg: 0.081  loss_mask: 0.112  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  time: 1.8193  data_time: 0.0088  lr: 0.000250  max_mem: 2783M\n",
            "\u001b[32m[09/02 10:04:54 d2.engine.hooks]: \u001b[0mOverall training speed: 7997 iterations in 4:02:30 (1.8196 s / it)\n",
            "\u001b[32m[09/02 10:04:54 d2.engine.hooks]: \u001b[0mTotal training time: 4:02:58 (0:00:27 on hooks)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rI4rmTa_IvT_",
        "outputId": "6b3d587c-f82f-4ed2-9a08-9787aadaddc7"
      },
      "source": [
        "import os\n",
        "#test evaluation\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "\n",
        "cfg.MODEL.WEIGHTS = '/content/drive/MyDrive/detectron2_500/output_detect/model_final.pth'\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.25\n",
        "predictor = DefaultPredictor(cfg)\n",
        "evaluator = COCOEvaluator(\"my_dataset_val2\", cfg, False, output_dir=\"/content/drive/MyDrive/detectron2_500/output_detect/\")\n",
        "val_loader = build_detection_test_loader(cfg, \"my_dataset_val2\")\n",
        "inference_on_dataset(trainer.model, val_loader, evaluator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[09/02 10:52:48 d2.data.datasets.coco]: \u001b[0mLoaded 190 images in COCO format from /content/drive/MyDrive/detectron2_500/test.json\n",
            "\u001b[32m[09/02 10:52:48 d2.data.common]: \u001b[0mSerializing 190 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[09/02 10:52:48 d2.data.common]: \u001b[0mSerialized dataset takes 0.34 MiB\n",
            "\u001b[32m[09/02 10:52:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 190 images\n",
            "\u001b[32m[09/02 10:52:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/190. 0.3736 s / img. ETA=0:01:08\n",
            "\u001b[32m[09/02 10:52:58 d2.evaluation.evaluator]: \u001b[0mInference done 24/190. 0.3885 s / img. ETA=0:01:05\n",
            "\u001b[32m[09/02 10:53:03 d2.evaluation.evaluator]: \u001b[0mInference done 37/190. 0.3943 s / img. ETA=0:01:01\n",
            "\u001b[32m[09/02 10:53:09 d2.evaluation.evaluator]: \u001b[0mInference done 50/190. 0.3956 s / img. ETA=0:00:56\n",
            "\u001b[32m[09/02 10:53:14 d2.evaluation.evaluator]: \u001b[0mInference done 63/190. 0.3937 s / img. ETA=0:00:50\n",
            "\u001b[32m[09/02 10:53:19 d2.evaluation.evaluator]: \u001b[0mInference done 76/190. 0.3955 s / img. ETA=0:00:45\n",
            "\u001b[32m[09/02 10:53:25 d2.evaluation.evaluator]: \u001b[0mInference done 89/190. 0.3964 s / img. ETA=0:00:40\n",
            "\u001b[32m[09/02 10:53:30 d2.evaluation.evaluator]: \u001b[0mInference done 102/190. 0.3957 s / img. ETA=0:00:35\n",
            "\u001b[32m[09/02 10:53:35 d2.evaluation.evaluator]: \u001b[0mInference done 115/190. 0.3959 s / img. ETA=0:00:30\n",
            "\u001b[32m[09/02 10:53:40 d2.evaluation.evaluator]: \u001b[0mInference done 128/190. 0.3959 s / img. ETA=0:00:24\n",
            "\u001b[32m[09/02 10:53:46 d2.evaluation.evaluator]: \u001b[0mInference done 141/190. 0.3963 s / img. ETA=0:00:19\n",
            "\u001b[32m[09/02 10:53:51 d2.evaluation.evaluator]: \u001b[0mInference done 154/190. 0.3947 s / img. ETA=0:00:14\n",
            "\u001b[32m[09/02 10:53:56 d2.evaluation.evaluator]: \u001b[0mInference done 167/190. 0.3946 s / img. ETA=0:00:09\n",
            "\u001b[32m[09/02 10:54:01 d2.evaluation.evaluator]: \u001b[0mInference done 180/190. 0.3948 s / img. ETA=0:00:04\n",
            "\u001b[32m[09/02 10:54:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:14.327237 (0.401769 s / img per device, on 1 devices)\n",
            "\u001b[32m[09/02 10:54:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:12 (0.394272 s / img per device, on 1 devices)\n",
            "\u001b[32m[09/02 10:54:05 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[09/02 10:54:05 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /content/drive/MyDrive/detectron2_500/output_detect/coco_instances_results.json\n",
            "\u001b[32m[09/02 10:54:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.33s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.09s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.301\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.462\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.308\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.153\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.413\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.450\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.193\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.421\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.434\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.255\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.528\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.672\n",
            "\u001b[32m[09/02 10:54:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 30.115 | 46.151 | 30.785 | 15.273 | 41.318 | 44.998 |\n",
            "\u001b[32m[09/02 10:54:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category      | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:--------------|:-------|\n",
            "| aeroplane  | 55.857 | car        | 15.326 | chair         | 20.374 |\n",
            "| cow        | 53.049 | person     | 10.797 | traffic_light | 25.285 |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.37s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.08s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.242\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.434\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.265\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.338\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.388\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.163\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.355\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.365\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.219\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.450\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.544\n",
            "\u001b[32m[09/02 10:54:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 24.198 | 43.379 | 26.451 | 11.997 | 33.753 | 38.784 |\n",
            "\u001b[32m[09/02 10:54:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category   | AP     | category   | AP     | category      | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:--------------|:-------|\n",
            "| aeroplane  | 40.207 | car        | 14.769 | chair         | 15.868 |\n",
            "| cow        | 43.465 | person     | 8.808  | traffic_light | 22.069 |\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('bbox',\n",
              "              {'AP': 30.114684608698113,\n",
              "               'AP-aeroplane': 55.85674074126396,\n",
              "               'AP-car': 15.326092893808896,\n",
              "               'AP-chair': 20.37356627547494,\n",
              "               'AP-cow': 53.04893713421212,\n",
              "               'AP-person': 10.797446040413964,\n",
              "               'AP-traffic_light': 25.285324567014815,\n",
              "               'AP50': 46.15141733326155,\n",
              "               'AP75': 30.785177117136442,\n",
              "               'APl': 44.998137592785106,\n",
              "               'APm': 41.31835037753761,\n",
              "               'APs': 15.272920694134328}),\n",
              "             ('segm',\n",
              "              {'AP': 24.197608211597306,\n",
              "               'AP-aeroplane': 40.20678237257738,\n",
              "               'AP-car': 14.768558709074671,\n",
              "               'AP-chair': 15.86795630334523,\n",
              "               'AP-cow': 43.46505557940127,\n",
              "               'AP-person': 8.808437413790129,\n",
              "               'AP-traffic_light': 22.06885889139513,\n",
              "               'AP50': 43.37944491067707,\n",
              "               'AP75': 26.45050515085107,\n",
              "               'APl': 38.784484717908406,\n",
              "               'APm': 33.75271862736534,\n",
              "               'APs': 11.997007442649206})])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnWlfU3CShWw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c066e69-7e0e-4181-e0d3-aaa0c2d6383d"
      },
      "source": [
        "import os\n",
        "#test evaluation\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "\n",
        "cfg.MODEL.WEIGHTS = '/content/drive/MyDrive/detectron2_500/output_detect/model_0057999.pth'\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.25\n",
        "predictor = DefaultPredictor(cfg)\n",
        "evaluator = COCOEvaluator(\"my_dataset_val2\", cfg, False, output_dir=\"/content/drive/MyDrive/detectron2_500/output_detect/\")\n",
        "val_loader = build_detection_test_loader(cfg, \"my_dataset_val2\")\n",
        "inference_on_dataset(trainer.model, val_loader, evaluator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[09/02 10:50:06 d2.data.datasets.coco]: \u001b[0mLoaded 190 images in COCO format from /content/drive/MyDrive/detectron2_500/test.json\n",
            "\u001b[32m[09/02 10:50:06 d2.data.common]: \u001b[0mSerializing 190 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[09/02 10:50:06 d2.data.common]: \u001b[0mSerialized dataset takes 0.34 MiB\n",
            "\u001b[32m[09/02 10:50:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 190 images\n",
            "\u001b[32m[09/02 10:50:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/190. 0.3727 s / img. ETA=0:01:08\n",
            "\u001b[32m[09/02 10:50:16 d2.evaluation.evaluator]: \u001b[0mInference done 24/190. 0.3886 s / img. ETA=0:01:05\n",
            "\u001b[32m[09/02 10:50:22 d2.evaluation.evaluator]: \u001b[0mInference done 37/190. 0.3954 s / img. ETA=0:01:01\n",
            "\u001b[32m[09/02 10:50:27 d2.evaluation.evaluator]: \u001b[0mInference done 50/190. 0.3968 s / img. ETA=0:00:56\n",
            "\u001b[32m[09/02 10:50:32 d2.evaluation.evaluator]: \u001b[0mInference done 63/190. 0.3950 s / img. ETA=0:00:51\n",
            "\u001b[32m[09/02 10:50:37 d2.evaluation.evaluator]: \u001b[0mInference done 76/190. 0.3966 s / img. ETA=0:00:46\n",
            "\u001b[32m[09/02 10:50:43 d2.evaluation.evaluator]: \u001b[0mInference done 89/190. 0.3974 s / img. ETA=0:00:40\n",
            "\u001b[32m[09/02 10:50:48 d2.evaluation.evaluator]: \u001b[0mInference done 102/190. 0.3963 s / img. ETA=0:00:35\n",
            "\u001b[32m[09/02 10:50:53 d2.evaluation.evaluator]: \u001b[0mInference done 115/190. 0.3965 s / img. ETA=0:00:30\n",
            "\u001b[32m[09/02 10:50:58 d2.evaluation.evaluator]: \u001b[0mInference done 128/190. 0.3965 s / img. ETA=0:00:25\n",
            "\u001b[32m[09/02 10:51:04 d2.evaluation.evaluator]: \u001b[0mInference done 141/190. 0.3970 s / img. ETA=0:00:19\n",
            "\u001b[32m[09/02 10:51:09 d2.evaluation.evaluator]: \u001b[0mInference done 154/190. 0.3952 s / img. ETA=0:00:14\n",
            "\u001b[32m[09/02 10:51:14 d2.evaluation.evaluator]: \u001b[0mInference done 167/190. 0.3950 s / img. ETA=0:00:09\n",
            "\u001b[32m[09/02 10:51:19 d2.evaluation.evaluator]: \u001b[0mInference done 180/190. 0.3954 s / img. ETA=0:00:04\n",
            "\u001b[32m[09/02 10:51:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:14.438052 (0.402368 s / img per device, on 1 devices)\n",
            "\u001b[32m[09/02 10:51:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:13 (0.394828 s / img per device, on 1 devices)\n",
            "\u001b[32m[09/02 10:51:23 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[09/02 10:51:23 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /content/drive/MyDrive/detectron2_500/output_detect/coco_instances_results.json\n",
            "\u001b[32m[09/02 10:51:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.34s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.08s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.301\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.462\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.308\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.153\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.413\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.450\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.193\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.421\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.434\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.255\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.528\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.672\n",
            "\u001b[32m[09/02 10:51:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 30.115 | 46.151 | 30.785 | 15.273 | 41.318 | 44.998 |\n",
            "\u001b[32m[09/02 10:51:24 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category      | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:--------------|:-------|\n",
            "| aeroplane  | 55.857 | car        | 15.326 | chair         | 20.374 |\n",
            "| cow        | 53.049 | person     | 10.797 | traffic_light | 25.285 |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.54s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.08s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.242\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.434\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.265\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.338\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.388\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.163\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.355\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.365\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.219\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.450\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.544\n",
            "\u001b[32m[09/02 10:51:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 24.198 | 43.379 | 26.451 | 11.997 | 33.753 | 38.784 |\n",
            "\u001b[32m[09/02 10:51:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category   | AP     | category   | AP     | category      | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:--------------|:-------|\n",
            "| aeroplane  | 40.207 | car        | 14.769 | chair         | 15.868 |\n",
            "| cow        | 43.465 | person     | 8.808  | traffic_light | 22.069 |\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('bbox',\n",
              "              {'AP': 30.114684608698113,\n",
              "               'AP-aeroplane': 55.85674074126396,\n",
              "               'AP-car': 15.326092893808896,\n",
              "               'AP-chair': 20.37356627547494,\n",
              "               'AP-cow': 53.04893713421212,\n",
              "               'AP-person': 10.797446040413964,\n",
              "               'AP-traffic_light': 25.285324567014815,\n",
              "               'AP50': 46.15141733326155,\n",
              "               'AP75': 30.785177117136442,\n",
              "               'APl': 44.998137592785106,\n",
              "               'APm': 41.31835037753761,\n",
              "               'APs': 15.272920694134328}),\n",
              "             ('segm',\n",
              "              {'AP': 24.197608211597306,\n",
              "               'AP-aeroplane': 40.20678237257738,\n",
              "               'AP-car': 14.768558709074671,\n",
              "               'AP-chair': 15.86795630334523,\n",
              "               'AP-cow': 43.46505557940127,\n",
              "               'AP-person': 8.808437413790129,\n",
              "               'AP-traffic_light': 22.06885889139513,\n",
              "               'AP50': 43.37944491067707,\n",
              "               'AP75': 26.45050515085107,\n",
              "               'APl': 38.784484717908406,\n",
              "               'APm': 33.75271862736534,\n",
              "               'APs': 11.997007442649206})])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk9VfpQ6EmRe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b4c82c2-66be-4c69-a1e3-99f2a2e5caf3"
      },
      "source": [
        "import os\n",
        "#test evaluation\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "\n",
        "cfg.MODEL.WEIGHTS = '/content/drive/MyDrive/detectron2_500/output_detect/model_final.pth'\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.25\n",
        "predictor = DefaultPredictor(cfg)\n",
        "evaluator = COCOEvaluator(\"my_dataset_train2\", cfg, False, output_dir=\"/content/drive/MyDrive/detectron2_500/output_detect/\")\n",
        "val_loader = build_detection_test_loader(cfg, \"my_dataset_train2\")\n",
        "inference_on_dataset(trainer.model, val_loader, evaluator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[09/02 10:54:21 d2.data.datasets.coco]: \u001b[0mLoaded 689 images in COCO format from /content/drive/MyDrive/detectron2_500/train.json\n",
            "\u001b[32m[09/02 10:54:22 d2.data.common]: \u001b[0mSerializing 689 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[09/02 10:54:22 d2.data.common]: \u001b[0mSerialized dataset takes 1.35 MiB\n",
            "\u001b[32m[09/02 10:54:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 689 images\n",
            "\u001b[32m[09/02 10:54:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/689. 0.4072 s / img. ETA=0:04:38\n",
            "\u001b[32m[09/02 10:54:32 d2.evaluation.evaluator]: \u001b[0mInference done 25/689. 0.3857 s / img. ETA=0:04:19\n",
            "\u001b[32m[09/02 10:54:37 d2.evaluation.evaluator]: \u001b[0mInference done 38/689. 0.3848 s / img. ETA=0:04:14\n",
            "\u001b[32m[09/02 10:54:42 d2.evaluation.evaluator]: \u001b[0mInference done 51/689. 0.3856 s / img. ETA=0:04:09\n",
            "\u001b[32m[09/02 10:54:47 d2.evaluation.evaluator]: \u001b[0mInference done 64/689. 0.3881 s / img. ETA=0:04:06\n",
            "\u001b[32m[09/02 10:54:52 d2.evaluation.evaluator]: \u001b[0mInference done 76/689. 0.3906 s / img. ETA=0:04:04\n",
            "\u001b[32m[09/02 10:54:57 d2.evaluation.evaluator]: \u001b[0mInference done 89/689. 0.3908 s / img. ETA=0:03:58\n",
            "\u001b[32m[09/02 10:55:02 d2.evaluation.evaluator]: \u001b[0mInference done 102/689. 0.3894 s / img. ETA=0:03:52\n",
            "\u001b[32m[09/02 10:55:08 d2.evaluation.evaluator]: \u001b[0mInference done 115/689. 0.3903 s / img. ETA=0:03:48\n",
            "\u001b[32m[09/02 10:55:13 d2.evaluation.evaluator]: \u001b[0mInference done 128/689. 0.3905 s / img. ETA=0:03:43\n",
            "\u001b[32m[09/02 10:55:18 d2.evaluation.evaluator]: \u001b[0mInference done 141/689. 0.3919 s / img. ETA=0:03:38\n",
            "\u001b[32m[09/02 10:55:23 d2.evaluation.evaluator]: \u001b[0mInference done 154/689. 0.3919 s / img. ETA=0:03:33\n",
            "\u001b[32m[09/02 10:55:29 d2.evaluation.evaluator]: \u001b[0mInference done 167/689. 0.3921 s / img. ETA=0:03:28\n",
            "\u001b[32m[09/02 10:55:34 d2.evaluation.evaluator]: \u001b[0mInference done 180/689. 0.3915 s / img. ETA=0:03:22\n",
            "\u001b[32m[09/02 10:55:39 d2.evaluation.evaluator]: \u001b[0mInference done 193/689. 0.3911 s / img. ETA=0:03:17\n",
            "\u001b[32m[09/02 10:55:44 d2.evaluation.evaluator]: \u001b[0mInference done 206/689. 0.3914 s / img. ETA=0:03:12\n",
            "\u001b[32m[09/02 10:55:49 d2.evaluation.evaluator]: \u001b[0mInference done 219/689. 0.3909 s / img. ETA=0:03:07\n",
            "\u001b[32m[09/02 10:55:54 d2.evaluation.evaluator]: \u001b[0mInference done 232/689. 0.3902 s / img. ETA=0:03:01\n",
            "\u001b[32m[09/02 10:55:59 d2.evaluation.evaluator]: \u001b[0mInference done 245/689. 0.3900 s / img. ETA=0:02:56\n",
            "\u001b[32m[09/02 10:56:04 d2.evaluation.evaluator]: \u001b[0mInference done 258/689. 0.3898 s / img. ETA=0:02:50\n",
            "\u001b[32m[09/02 10:56:09 d2.evaluation.evaluator]: \u001b[0mInference done 271/689. 0.3900 s / img. ETA=0:02:45\n",
            "\u001b[32m[09/02 10:56:14 d2.evaluation.evaluator]: \u001b[0mInference done 284/689. 0.3898 s / img. ETA=0:02:40\n",
            "\u001b[32m[09/02 10:56:20 d2.evaluation.evaluator]: \u001b[0mInference done 297/689. 0.3901 s / img. ETA=0:02:35\n",
            "\u001b[32m[09/02 10:56:25 d2.evaluation.evaluator]: \u001b[0mInference done 310/689. 0.3902 s / img. ETA=0:02:30\n",
            "\u001b[32m[09/02 10:56:30 d2.evaluation.evaluator]: \u001b[0mInference done 324/689. 0.3897 s / img. ETA=0:02:24\n",
            "\u001b[32m[09/02 10:56:35 d2.evaluation.evaluator]: \u001b[0mInference done 337/689. 0.3896 s / img. ETA=0:02:19\n",
            "\u001b[32m[09/02 10:56:40 d2.evaluation.evaluator]: \u001b[0mInference done 350/689. 0.3892 s / img. ETA=0:02:14\n",
            "\u001b[32m[09/02 10:56:46 d2.evaluation.evaluator]: \u001b[0mInference done 363/689. 0.3897 s / img. ETA=0:02:09\n",
            "\u001b[32m[09/02 10:56:51 d2.evaluation.evaluator]: \u001b[0mInference done 376/689. 0.3900 s / img. ETA=0:02:04\n",
            "\u001b[32m[09/02 10:56:56 d2.evaluation.evaluator]: \u001b[0mInference done 389/689. 0.3898 s / img. ETA=0:01:58\n",
            "\u001b[32m[09/02 10:57:01 d2.evaluation.evaluator]: \u001b[0mInference done 402/689. 0.3901 s / img. ETA=0:01:53\n",
            "\u001b[32m[09/02 10:57:07 d2.evaluation.evaluator]: \u001b[0mInference done 415/689. 0.3902 s / img. ETA=0:01:48\n",
            "\u001b[32m[09/02 10:57:12 d2.evaluation.evaluator]: \u001b[0mInference done 429/689. 0.3898 s / img. ETA=0:01:43\n",
            "\u001b[32m[09/02 10:57:17 d2.evaluation.evaluator]: \u001b[0mInference done 442/689. 0.3900 s / img. ETA=0:01:38\n",
            "\u001b[32m[09/02 10:57:23 d2.evaluation.evaluator]: \u001b[0mInference done 456/689. 0.3897 s / img. ETA=0:01:32\n",
            "\u001b[32m[09/02 10:57:28 d2.evaluation.evaluator]: \u001b[0mInference done 469/689. 0.3896 s / img. ETA=0:01:27\n",
            "\u001b[32m[09/02 10:57:33 d2.evaluation.evaluator]: \u001b[0mInference done 482/689. 0.3896 s / img. ETA=0:01:22\n",
            "\u001b[32m[09/02 10:57:38 d2.evaluation.evaluator]: \u001b[0mInference done 495/689. 0.3898 s / img. ETA=0:01:16\n",
            "\u001b[32m[09/02 10:57:43 d2.evaluation.evaluator]: \u001b[0mInference done 508/689. 0.3899 s / img. ETA=0:01:11\n",
            "\u001b[32m[09/02 10:57:48 d2.evaluation.evaluator]: \u001b[0mInference done 521/689. 0.3900 s / img. ETA=0:01:06\n",
            "\u001b[32m[09/02 10:57:54 d2.evaluation.evaluator]: \u001b[0mInference done 534/689. 0.3901 s / img. ETA=0:01:01\n",
            "\u001b[32m[09/02 10:57:59 d2.evaluation.evaluator]: \u001b[0mInference done 547/689. 0.3900 s / img. ETA=0:00:56\n",
            "\u001b[32m[09/02 10:58:04 d2.evaluation.evaluator]: \u001b[0mInference done 560/689. 0.3901 s / img. ETA=0:00:51\n",
            "\u001b[32m[09/02 10:58:09 d2.evaluation.evaluator]: \u001b[0mInference done 573/689. 0.3899 s / img. ETA=0:00:45\n",
            "\u001b[32m[09/02 10:58:14 d2.evaluation.evaluator]: \u001b[0mInference done 586/689. 0.3897 s / img. ETA=0:00:40\n",
            "\u001b[32m[09/02 10:58:19 d2.evaluation.evaluator]: \u001b[0mInference done 600/689. 0.3894 s / img. ETA=0:00:35\n",
            "\u001b[32m[09/02 10:58:25 d2.evaluation.evaluator]: \u001b[0mInference done 613/689. 0.3895 s / img. ETA=0:00:30\n",
            "\u001b[32m[09/02 10:58:30 d2.evaluation.evaluator]: \u001b[0mInference done 626/689. 0.3894 s / img. ETA=0:00:24\n",
            "\u001b[32m[09/02 10:58:35 d2.evaluation.evaluator]: \u001b[0mInference done 639/689. 0.3895 s / img. ETA=0:00:19\n",
            "\u001b[32m[09/02 10:58:40 d2.evaluation.evaluator]: \u001b[0mInference done 652/689. 0.3896 s / img. ETA=0:00:14\n",
            "\u001b[32m[09/02 10:58:45 d2.evaluation.evaluator]: \u001b[0mInference done 665/689. 0.3897 s / img. ETA=0:00:09\n",
            "\u001b[32m[09/02 10:58:51 d2.evaluation.evaluator]: \u001b[0mInference done 678/689. 0.3899 s / img. ETA=0:00:04\n",
            "\u001b[32m[09/02 10:58:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:31.065626 (0.396295 s / img per device, on 1 devices)\n",
            "\u001b[32m[09/02 10:58:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:04:26 (0.389714 s / img per device, on 1 devices)\n",
            "\u001b[32m[09/02 10:58:55 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[09/02 10:58:55 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /content/drive/MyDrive/detectron2_500/output_detect/coco_instances_results.json\n",
            "\u001b[32m[09/02 10:58:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.60s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.18s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.882\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.986\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.966\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.852\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.921\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.945\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.339\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.880\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.913\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.878\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.949\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.973\n",
            "\u001b[32m[09/02 10:58:57 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 88.221 | 98.603 | 96.562 | 85.167 | 92.146 | 94.539 |\n",
            "\u001b[32m[09/02 10:58:57 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category      | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:--------------|:-------|\n",
            "| aeroplane  | 97.464 | car        | 85.598 | chair         | 88.659 |\n",
            "| cow        | 87.030 | person     | 89.073 | traffic_light | 81.502 |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=1.53s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.18s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.684\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.969\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.819\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.622\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.723\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.838\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.286\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.729\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.754\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.688\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.787\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.877\n",
            "\u001b[32m[09/02 10:58:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 68.398 | 96.917 | 81.912 | 62.207 | 72.333 | 83.818 |\n",
            "\u001b[32m[09/02 10:58:59 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category   | AP     | category   | AP     | category      | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:--------------|:-------|\n",
            "| aeroplane  | 70.458 | car        | 70.475 | chair         | 66.117 |\n",
            "| cow        | 64.706 | person     | 66.906 | traffic_light | 71.725 |\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('bbox',\n",
              "              {'AP': 88.22101280577175,\n",
              "               'AP-aeroplane': 97.46390429021127,\n",
              "               'AP-car': 85.59760109222138,\n",
              "               'AP-chair': 88.65940568771605,\n",
              "               'AP-cow': 87.0303001221745,\n",
              "               'AP-person': 89.07287218339125,\n",
              "               'AP-traffic_light': 81.50199345891605,\n",
              "               'AP50': 98.60324120715872,\n",
              "               'AP75': 96.56185016678269,\n",
              "               'APl': 94.53909774617792,\n",
              "               'APm': 92.14592449586543,\n",
              "               'APs': 85.16731934322864}),\n",
              "             ('segm',\n",
              "              {'AP': 68.39782637046075,\n",
              "               'AP-aeroplane': 70.45805080631722,\n",
              "               'AP-car': 70.47480796163774,\n",
              "               'AP-chair': 66.11745748849238,\n",
              "               'AP-cow': 64.70594805609741,\n",
              "               'AP-person': 66.90559867520254,\n",
              "               'AP-traffic_light': 71.72509523501719,\n",
              "               'AP50': 96.91655983858206,\n",
              "               'AP75': 81.91221339362991,\n",
              "               'APl': 83.81752634722558,\n",
              "               'APm': 72.33281919133859,\n",
              "               'APs': 62.207377780369065})])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfDl6LppTZUO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb831c56-c7a7-4981-d725-0b8a9c6034b6"
      },
      "source": [
        "import os\n",
        "#test evaluation\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "\n",
        "cfg.MODEL.WEIGHTS = '/content/drive/MyDrive/detectron2_500/output_detect/model_0057999.pth'\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.25\n",
        "predictor = DefaultPredictor(cfg)\n",
        "evaluator = COCOEvaluator(\"my_dataset_train2\", cfg, False, output_dir=\"/content/drive/MyDrive/detectron2_500/output_detect/\")\n",
        "val_loader = build_detection_test_loader(cfg, \"my_dataset_train2\")\n",
        "inference_on_dataset(trainer.model, val_loader, evaluator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[09/02 11:05:21 d2.data.datasets.coco]: \u001b[0mLoaded 689 images in COCO format from /content/drive/MyDrive/detectron2_500/train.json\n",
            "\u001b[32m[09/02 11:05:21 d2.data.common]: \u001b[0mSerializing 689 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[09/02 11:05:21 d2.data.common]: \u001b[0mSerialized dataset takes 1.35 MiB\n",
            "\u001b[32m[09/02 11:05:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 689 images\n",
            "\u001b[32m[09/02 11:05:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/689. 0.4118 s / img. ETA=0:04:41\n",
            "\u001b[32m[09/02 11:05:31 d2.evaluation.evaluator]: \u001b[0mInference done 24/689. 0.3910 s / img. ETA=0:04:23\n",
            "\u001b[32m[09/02 11:05:36 d2.evaluation.evaluator]: \u001b[0mInference done 37/689. 0.3916 s / img. ETA=0:04:18\n",
            "\u001b[32m[09/02 11:05:42 d2.evaluation.evaluator]: \u001b[0mInference done 50/689. 0.3910 s / img. ETA=0:04:13\n",
            "\u001b[32m[09/02 11:05:47 d2.evaluation.evaluator]: \u001b[0mInference done 63/689. 0.3933 s / img. ETA=0:04:10\n",
            "\u001b[32m[09/02 11:05:52 d2.evaluation.evaluator]: \u001b[0mInference done 75/689. 0.3955 s / img. ETA=0:04:07\n",
            "\u001b[32m[09/02 11:05:57 d2.evaluation.evaluator]: \u001b[0mInference done 88/689. 0.3945 s / img. ETA=0:04:01\n",
            "\u001b[32m[09/02 11:06:02 d2.evaluation.evaluator]: \u001b[0mInference done 101/689. 0.3929 s / img. ETA=0:03:55\n",
            "\u001b[32m[09/02 11:06:07 d2.evaluation.evaluator]: \u001b[0mInference done 114/689. 0.3936 s / img. ETA=0:03:50\n",
            "\u001b[32m[09/02 11:06:13 d2.evaluation.evaluator]: \u001b[0mInference done 127/689. 0.3938 s / img. ETA=0:03:45\n",
            "\u001b[32m[09/02 11:06:18 d2.evaluation.evaluator]: \u001b[0mInference done 140/689. 0.3944 s / img. ETA=0:03:40\n",
            "\u001b[32m[09/02 11:06:23 d2.evaluation.evaluator]: \u001b[0mInference done 153/689. 0.3943 s / img. ETA=0:03:35\n",
            "\u001b[32m[09/02 11:06:28 d2.evaluation.evaluator]: \u001b[0mInference done 166/689. 0.3945 s / img. ETA=0:03:30\n",
            "\u001b[32m[09/02 11:06:34 d2.evaluation.evaluator]: \u001b[0mInference done 179/689. 0.3942 s / img. ETA=0:03:24\n",
            "\u001b[32m[09/02 11:06:39 d2.evaluation.evaluator]: \u001b[0mInference done 192/689. 0.3932 s / img. ETA=0:03:18\n",
            "\u001b[32m[09/02 11:06:44 d2.evaluation.evaluator]: \u001b[0mInference done 205/689. 0.3933 s / img. ETA=0:03:13\n",
            "\u001b[32m[09/02 11:06:49 d2.evaluation.evaluator]: \u001b[0mInference done 218/689. 0.3929 s / img. ETA=0:03:08\n",
            "\u001b[32m[09/02 11:06:54 d2.evaluation.evaluator]: \u001b[0mInference done 232/689. 0.3918 s / img. ETA=0:03:02\n",
            "\u001b[32m[09/02 11:06:59 d2.evaluation.evaluator]: \u001b[0mInference done 245/689. 0.3914 s / img. ETA=0:02:56\n",
            "\u001b[32m[09/02 11:07:04 d2.evaluation.evaluator]: \u001b[0mInference done 258/689. 0.3912 s / img. ETA=0:02:51\n",
            "\u001b[32m[09/02 11:07:10 d2.evaluation.evaluator]: \u001b[0mInference done 271/689. 0.3913 s / img. ETA=0:02:46\n",
            "\u001b[32m[09/02 11:07:15 d2.evaluation.evaluator]: \u001b[0mInference done 284/689. 0.3910 s / img. ETA=0:02:41\n",
            "\u001b[32m[09/02 11:07:20 d2.evaluation.evaluator]: \u001b[0mInference done 297/689. 0.3914 s / img. ETA=0:02:36\n",
            "\u001b[32m[09/02 11:07:25 d2.evaluation.evaluator]: \u001b[0mInference done 310/689. 0.3914 s / img. ETA=0:02:30\n",
            "\u001b[32m[09/02 11:07:31 d2.evaluation.evaluator]: \u001b[0mInference done 324/689. 0.3908 s / img. ETA=0:02:25\n",
            "\u001b[32m[09/02 11:07:36 d2.evaluation.evaluator]: \u001b[0mInference done 337/689. 0.3907 s / img. ETA=0:02:19\n",
            "\u001b[32m[09/02 11:07:41 d2.evaluation.evaluator]: \u001b[0mInference done 350/689. 0.3903 s / img. ETA=0:02:14\n",
            "\u001b[32m[09/02 11:07:46 d2.evaluation.evaluator]: \u001b[0mInference done 363/689. 0.3906 s / img. ETA=0:02:09\n",
            "\u001b[32m[09/02 11:07:51 d2.evaluation.evaluator]: \u001b[0mInference done 376/689. 0.3909 s / img. ETA=0:02:04\n",
            "\u001b[32m[09/02 11:07:56 d2.evaluation.evaluator]: \u001b[0mInference done 389/689. 0.3907 s / img. ETA=0:01:59\n",
            "\u001b[32m[09/02 11:08:02 d2.evaluation.evaluator]: \u001b[0mInference done 402/689. 0.3910 s / img. ETA=0:01:54\n",
            "\u001b[32m[09/02 11:08:07 d2.evaluation.evaluator]: \u001b[0mInference done 415/689. 0.3910 s / img. ETA=0:01:49\n",
            "\u001b[32m[09/02 11:08:12 d2.evaluation.evaluator]: \u001b[0mInference done 428/689. 0.3907 s / img. ETA=0:01:43\n",
            "\u001b[32m[09/02 11:08:17 d2.evaluation.evaluator]: \u001b[0mInference done 441/689. 0.3908 s / img. ETA=0:01:38\n",
            "\u001b[32m[09/02 11:08:22 d2.evaluation.evaluator]: \u001b[0mInference done 455/689. 0.3904 s / img. ETA=0:01:32\n",
            "\u001b[32m[09/02 11:08:28 d2.evaluation.evaluator]: \u001b[0mInference done 468/689. 0.3905 s / img. ETA=0:01:27\n",
            "\u001b[32m[09/02 11:08:33 d2.evaluation.evaluator]: \u001b[0mInference done 481/689. 0.3904 s / img. ETA=0:01:22\n",
            "\u001b[32m[09/02 11:08:38 d2.evaluation.evaluator]: \u001b[0mInference done 494/689. 0.3906 s / img. ETA=0:01:17\n",
            "\u001b[32m[09/02 11:08:43 d2.evaluation.evaluator]: \u001b[0mInference done 507/689. 0.3905 s / img. ETA=0:01:12\n",
            "\u001b[32m[09/02 11:08:48 d2.evaluation.evaluator]: \u001b[0mInference done 520/689. 0.3907 s / img. ETA=0:01:07\n",
            "\u001b[32m[09/02 11:08:53 d2.evaluation.evaluator]: \u001b[0mInference done 533/689. 0.3905 s / img. ETA=0:01:01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZvv8m8-Lz5C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}