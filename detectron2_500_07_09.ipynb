{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "detectron2_500_27.08.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPcMStdYSvyWB1/twsRXDW/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vidyabandgar97/A2A/blob/main/detectron2_500_07_09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yw3X08oHoWnA",
        "outputId": "b6a12713-c40f-439a-d2a6-1d6c533ad145"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NVlkSGGogwA",
        "outputId": "009d0ce7-11c2-4f95-b16a-c4060441a3d6"
      },
      "source": [
        "%cd /content/drive/MyDrive/detectron2_500/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/detectron2_500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zIPp3vtogy1",
        "outputId": "678123f1-e13f-4650-c4ec-0429e8eb8854"
      },
      "source": [
        "# install dependencies: (use cu101 because colab has CUDA 10.1)\n",
        "!pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html \n",
        "!pip install cython pyyaml==5.1\n",
        "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version\n",
        "# opencv is pre-installed on colab"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/cu101/torch_stable.html\n",
            "Collecting torch==1.5\n",
            "  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.0%2Bcu101-cp37-cp37m-linux_x86_64.whl (703.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 703.8 MB 23 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.6\n",
            "  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.0%2Bcu101-cp37-cp37m-linux_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 42.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.5) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.5) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.6) (7.1.2)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.10.0+cu102\n",
            "    Uninstalling torchvision-0.10.0+cu102:\n",
            "      Successfully uninstalled torchvision-0.10.0+cu102\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.5.0+cu101 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.5.0+cu101 torchvision-0.6.0+cu101\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (0.29.24)\n",
            "Collecting pyyaml==5.1\n",
            "  Downloading PyYAML-5.1.tar.gz (274 kB)\n",
            "\u001b[K     |████████████████████████████████| 274 kB 12.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.1-cp37-cp37m-linux_x86_64.whl size=44092 sha256=eecb4160e8e1119c6ecb7890c51f6d5d6c317efc6157195947b2896c2553cbf7\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/f5/10/d00a2bd30928b972790053b5de0c703ca87324f3fead0f2fd9\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: pyyaml\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed pyyaml-5.1\n",
            "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-sh6oaxix\n",
            "  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-sh6oaxix\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (57.4.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (0.29.24)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools==2.0) (1.15.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp37-cp37m-linux_x86_64.whl size=263922 sha256=f35f4e2f4b6a08f20a5ec0c59e1b65c8ac54fa6115c9f29301448bde2d354cae\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-19mhkeo8/wheels/e2/6b/1d/344ac773c7495ea0b85eb228bc66daec7400a143a92d36b7b1\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: pycocotools\n",
            "  Attempting uninstall: pycocotools\n",
            "    Found existing installation: pycocotools 2.0.2\n",
            "    Uninstalling pycocotools-2.0.2:\n",
            "      Successfully uninstalled pycocotools-2.0.2\n",
            "Successfully installed pycocotools-2.0\n",
            "1.5.0+cu101 True\n",
            "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Copyright (C) 2017 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNRsGvvkog2s",
        "outputId": "9e869112-293d-4b5a-bde3-f4e9c74c8586"
      },
      "source": [
        "!pip install torch==1.9.0 torchvision==0.4.1"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.9.0\n",
            "  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 2.7 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.4.1\n",
            "  Downloading torchvision-0.4.1-cp37-cp37m-manylinux1_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 19.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.4.1) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.4.1) (7.1.2)\n",
            "INFO: pip is looking at multiple versions of <Python from Requires-Python> to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Cannot install torch==1.9.0 and torchvision==0.4.1 because these package versions have conflicting dependencies.\u001b[0m\n",
            "\n",
            "The conflict is caused by:\n",
            "    The user requested torch==1.9.0\n",
            "    torchvision 0.4.1 depends on torch==1.3.0\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
            "\n",
            "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/user_guide/#fixing-conflicting-dependencies\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WDn770log5j",
        "outputId": "164a330c-1796-4b8b-8cc4-28ab09443a88"
      },
      "source": [
        "!pip install detectron2==0.1.3 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html\n",
            "Collecting detectron2==0.1.3\n",
            "  Downloading https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/detectron2-0.1.3%2Bcu101-cp37-cp37m-linux_x86_64.whl (6.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.2 MB 3.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (1.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (1.1.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (0.8.9)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (4.62.0)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (0.16.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (7.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (3.2.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (2.6.0)\n",
            "Collecting mock\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Collecting fvcore>=0.1.1\n",
            "  Downloading fvcore-0.1.5.post20210825.tar.gz (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore>=0.1.1->detectron2==0.1.3) (1.19.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore>=0.1.1->detectron2==0.1.3) (5.1)\n",
            "Collecting iopath>=0.1.7\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.1.3) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.1.3) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.1.3) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.1.3) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->detectron2==0.1.3) (1.15.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (0.4.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (2.23.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (1.39.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (3.17.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (0.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (0.12.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (0.37.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (1.34.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.1.3) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->detectron2==0.1.3) (4.6.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (2021.5.30)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.1.3) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->detectron2==0.1.3) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->detectron2==0.1.3) (3.7.4.3)\n",
            "Building wheels for collected packages: fvcore\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20210825-py3-none-any.whl size=60661 sha256=d40b7f6c3f39aad6749b91e27855a38a569fb024430d55fa2ceeecb7b1b6de1f\n",
            "  Stored in directory: /root/.cache/pip/wheels/53/c4/f8/c4cb07f135845218b019b4a55d8a0470a0f21ee13f8dcd16be\n",
            "Successfully built fvcore\n",
            "Installing collected packages: portalocker, yacs, iopath, mock, fvcore, detectron2\n",
            "Successfully installed detectron2-0.1.3+cu101 fvcore-0.1.5.post20210825 iopath-0.1.9 mock-4.0.3 portalocker-2.3.2 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oxi7m9lAog_x"
      },
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2ZpZRvY8xmE"
      },
      "source": [
        "#if your dataset is in COCO format, this cell can be replaced by the following three lines:\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "register_coco_instances(\"my_dataset_train2\", {}, \"/content/drive/MyDrive/detectron2_500/train.json\", \"/content/drive/MyDrive/detectron2_500/Dataset\")\n",
        "register_coco_instances(\"my_dataset_val2\", {}, \"/content/drive/MyDrive/detectron2_500/test.json\", \"/content/drive/MyDrive/detectron2_500/test_data\")\n",
        "register_coco_instances(\"my_dataset_test2\", {}, \"/content/drive/MyDrive/detectron2_500/test.json\", \"/content/drive/MyDrive/detectron2_500/test_data\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HG8JZ6Hb84hs"
      },
      "source": [
        "#We are importing our own Trainer Module here to use the COCO validation evaluation during training. Otherwise no validation eval occurs.\n",
        "\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.evaluation import COCOEvaluator\n",
        "from detectron2.data import transforms as T\n",
        "\n",
        "from detectron2.data import (\n",
        "    MetadataCatalog,\n",
        "    build_detection_test_loader,\n",
        "    build_detection_train_loader,\n",
        ")\n",
        "\n",
        "from detectron2.data import DatasetMapper   # the default mapper"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrSl7Hn_87eZ"
      },
      "source": [
        "class CocoTrainer(DefaultTrainer):\n",
        "\n",
        "  @classmethod\n",
        "  def build_train_loader(cls, cfg):\n",
        "    return build_detection_train_loader(\n",
        "        cfg, \n",
        "        mapper=DatasetMapper(\n",
        "            cfg, \n",
        "            is_train=True, \n",
        "            augmentations=[\n",
        "                           T.Resize((1024, 1024)), \n",
        "                           T.HFlipTransform(1024)\n",
        "                           ]\n",
        "        )\n",
        "    )\n",
        "\n",
        "  @classmethod\n",
        "  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "    if output_folder is None:\n",
        "        os.makedirs(\"coco_eval\", exist_ok=True)\n",
        "        output_folder = \"coco_eval\"\n",
        "\n",
        "    return COCOEvaluator(dataset_name, cfg, False, output_folder)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUYTHFK9ohHJ",
        "outputId": "b3e85e37-16a3-4892-b4f9-fddf6f8910de"
      },
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "import os\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.OUTPUT_DIR = \"/content/drive/MyDrive/detectron2_500/output_detect\"\n",
        "cfg.SOLVER.CHECKPOINT_PERIOD = 1000\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"Misc/mask_rcnn_R_50_FPN_3x_dconv_c3-c5.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"my_dataset_train2\",)\n",
        "cfg.DATASETS.TEST = (\"my_dataset_val2\",)\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"Misc/mask_rcnn_R_50_FPN_3x_dconv_c3-c5.yaml\")  # Let training initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
        "cfg.SOLVER.MAX_ITER = 86000    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
        "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 6  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
        "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg) \n",
        "trainer.resume_or_load(resume=True)\n",
        "trainer.train()\n",
        "#trainer.test()\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[09/07 09:56:42 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): DeformBottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(128, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): DeformBottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(128, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): DeformBottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(128, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): DeformBottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(128, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): DeformBottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=256, out_channels=256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): DeformBottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=256, out_channels=256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): DeformBottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=256, out_channels=256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): DeformBottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=256, out_channels=256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): DeformBottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=256, out_channels=256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): DeformBottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=256, out_channels=256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): DeformBottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): DeformBottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): DeformBottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[09/07 09:56:44 d2.data.datasets.coco]: \u001b[0mLoading /content/drive/MyDrive/detectron2_500/train.json takes 1.68 seconds.\n",
            "\u001b[32m[09/07 09:56:44 d2.data.datasets.coco]: \u001b[0mLoaded 689 images in COCO format from /content/drive/MyDrive/detectron2_500/train.json\n",
            "\u001b[32m[09/07 09:56:44 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 689 images left.\n",
            "\u001b[32m[09/07 09:56:44 d2.data.build]: \u001b[0mDistribution of instances among all 6 categories:\n",
            "\u001b[36m|  category  | #instances   |  category  | #instances   |   category    | #instances   |\n",
            "|:----------:|:-------------|:----------:|:-------------|:-------------:|:-------------|\n",
            "| aeroplane  | 143          |    car     | 500          |     chair     | 500          |\n",
            "|    cow     | 372          |   person   | 500          | traffic_light | 499          |\n",
            "|            |              |            |              |               |              |\n",
            "|   total    | 2514         |            |              |               |              |\u001b[0m\n",
            "\u001b[32m[09/07 09:56:44 d2.data.common]: \u001b[0mSerializing 689 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[09/07 09:56:44 d2.data.common]: \u001b[0mSerialized dataset takes 1.35 MiB\n",
            "\u001b[32m[09/07 09:56:44 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[09/07 09:56:44 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[09/07 09:56:51 d2.engine.train_loop]: \u001b[0mStarting training from iteration 86000\n",
            "\u001b[32m[09/07 09:56:51 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:00 (0:00:00 on hooks)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPQ6fhWLohNp",
        "outputId": "f816e291-318d-4cdd-cc85-106f541becc7"
      },
      "source": [
        "import os\n",
        "#test evaluation\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "\n",
        "cfg.MODEL.WEIGHTS = '/content/drive/MyDrive/detectron2_500/output_detect/model_final.pth'\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.25\n",
        "predictor = DefaultPredictor(cfg)\n",
        "evaluator = COCOEvaluator(\"my_dataset_val2\", cfg, False, output_dir=\"/content/drive/MyDrive/detectron2_500/output_detect/\")\n",
        "val_loader = build_detection_test_loader(cfg, \"my_dataset_val2\")\n",
        "inference_on_dataset(trainer.model, val_loader, evaluator)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[09/07 09:57:04 d2.data.datasets.coco]: \u001b[0mLoaded 190 images in COCO format from /content/drive/MyDrive/detectron2_500/test.json\n",
            "\u001b[32m[09/07 09:57:04 d2.data.build]: \u001b[0mDistribution of instances among all 6 categories:\n",
            "\u001b[36m|  category  | #instances   |  category  | #instances   |   category    | #instances   |\n",
            "|:----------:|:-------------|:----------:|:-------------|:-------------:|:-------------|\n",
            "| aeroplane  | 100          |    car     | 99           |     chair     | 99           |\n",
            "|    cow     | 100          |   person   | 100          | traffic_light | 99           |\n",
            "|            |              |            |              |               |              |\n",
            "|   total    | 597          |            |              |               |              |\u001b[0m\n",
            "\u001b[32m[09/07 09:57:04 d2.data.common]: \u001b[0mSerializing 190 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[09/07 09:57:04 d2.data.common]: \u001b[0mSerialized dataset takes 0.34 MiB\n",
            "\u001b[32m[09/07 09:57:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 190 images\n",
            "\u001b[32m[09/07 09:57:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/190. 0.3332 s / img. ETA=0:01:01\n",
            "\u001b[32m[09/07 09:57:14 d2.evaluation.evaluator]: \u001b[0mInference done 26/190. 0.3442 s / img. ETA=0:00:57\n",
            "\u001b[32m[09/07 09:57:19 d2.evaluation.evaluator]: \u001b[0mInference done 40/190. 0.3499 s / img. ETA=0:00:53\n",
            "\u001b[32m[09/07 09:57:25 d2.evaluation.evaluator]: \u001b[0mInference done 54/190. 0.3485 s / img. ETA=0:00:48\n",
            "\u001b[32m[09/07 09:57:30 d2.evaluation.evaluator]: \u001b[0mInference done 68/190. 0.3495 s / img. ETA=0:00:43\n",
            "\u001b[32m[09/07 09:57:35 d2.evaluation.evaluator]: \u001b[0mInference done 82/190. 0.3509 s / img. ETA=0:00:38\n",
            "\u001b[32m[09/07 09:57:40 d2.evaluation.evaluator]: \u001b[0mInference done 96/190. 0.3527 s / img. ETA=0:00:33\n",
            "\u001b[32m[09/07 09:57:45 d2.evaluation.evaluator]: \u001b[0mInference done 110/190. 0.3524 s / img. ETA=0:00:28\n",
            "\u001b[32m[09/07 09:57:50 d2.evaluation.evaluator]: \u001b[0mInference done 124/190. 0.3527 s / img. ETA=0:00:23\n",
            "\u001b[32m[09/07 09:57:55 d2.evaluation.evaluator]: \u001b[0mInference done 138/190. 0.3538 s / img. ETA=0:00:18\n",
            "\u001b[32m[09/07 09:58:01 d2.evaluation.evaluator]: \u001b[0mInference done 153/190. 0.3532 s / img. ETA=0:00:13\n",
            "\u001b[32m[09/07 09:58:06 d2.evaluation.evaluator]: \u001b[0mInference done 167/190. 0.3535 s / img. ETA=0:00:08\n",
            "\u001b[32m[09/07 09:58:11 d2.evaluation.evaluator]: \u001b[0mInference done 181/190. 0.3541 s / img. ETA=0:00:03\n",
            "\u001b[32m[09/07 09:58:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:06.965802 (0.361977 s / img per device, on 1 devices)\n",
            "\u001b[32m[09/07 09:58:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:05 (0.353673 s / img per device, on 1 devices)\n",
            "\u001b[32m[09/07 09:58:14 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[09/07 09:58:14 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /content/drive/MyDrive/detectron2_500/output_detect/coco_instances_results.json\n",
            "\u001b[32m[09/07 09:58:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.45s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.08s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.290\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.450\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.297\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.145\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.405\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.439\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.192\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.416\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.429\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.254\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.518\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.658\n",
            "\u001b[32m[09/07 09:58:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 28.984 | 45.037 | 29.704 | 14.522 | 40.464 | 43.913 |\n",
            "\u001b[32m[09/07 09:58:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category      | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:--------------|:-------|\n",
            "| aeroplane  | 54.573 | car        | 14.666 | chair         | 19.969 |\n",
            "| cow        | 49.022 | person     | 10.651 | traffic_light | 25.023 |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.38s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.09s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.233\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.424\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.253\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.115\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.325\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.379\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.160\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.349\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.359\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.220\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.435\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.528\n",
            "\u001b[32m[09/07 09:58:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 23.257 | 42.385 | 25.316 | 11.456 | 32.504 | 37.905 |\n",
            "\u001b[32m[09/07 09:58:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category   | AP     | category   | AP     | category      | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:--------------|:-------|\n",
            "| aeroplane  | 39.125 | car        | 13.696 | chair         | 14.429 |\n",
            "| cow        | 40.668 | person     | 8.840  | traffic_light | 22.782 |\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('bbox',\n",
              "              {'AP': 28.98399615813917,\n",
              "               'AP-aeroplane': 54.57337962218733,\n",
              "               'AP-car': 14.66612805636027,\n",
              "               'AP-chair': 19.969412071910146,\n",
              "               'AP-cow': 49.021736761204615,\n",
              "               'AP-person': 10.650646989033767,\n",
              "               'AP-traffic_light': 25.022673448138853,\n",
              "               'AP50': 45.03740027896978,\n",
              "               'AP75': 29.703910273555806,\n",
              "               'APl': 43.91260835680967,\n",
              "               'APm': 40.464182486473106,\n",
              "               'APs': 14.5215639775658}),\n",
              "             ('segm',\n",
              "              {'AP': 23.25659772128245,\n",
              "               'AP-aeroplane': 39.12518787892412,\n",
              "               'AP-car': 13.695654512165826,\n",
              "               'AP-chair': 14.429427753456547,\n",
              "               'AP-cow': 40.66808307048525,\n",
              "               'AP-person': 8.839691185693024,\n",
              "               'AP-traffic_light': 22.781541926969926,\n",
              "               'AP50': 42.384749137878536,\n",
              "               'AP75': 25.316161950387716,\n",
              "               'APl': 37.905305049520734,\n",
              "               'APm': 32.504470585780396,\n",
              "               'APs': 11.455878745055307})])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4Z_i-GZSyMy",
        "outputId": "fbe9e818-20d5-4f3c-bb2a-074852ee6297"
      },
      "source": [
        "import os\n",
        "#test evaluation\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "\n",
        "cfg.MODEL.WEIGHTS = '/content/drive/MyDrive/detectron2_500/output_detect/model_0085999.pth'\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.25\n",
        "predictor = DefaultPredictor(cfg)\n",
        "evaluator = COCOEvaluator(\"my_dataset_val2\", cfg, False, output_dir=\"/content/drive/MyDrive/detectron2_500/output_detect/\")\n",
        "val_loader = build_detection_test_loader(cfg, \"my_dataset_val2\")\n",
        "inference_on_dataset(trainer.model, val_loader, evaluator)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[09/07 09:59:55 d2.data.datasets.coco]: \u001b[0mLoaded 190 images in COCO format from /content/drive/MyDrive/detectron2_500/test.json\n",
            "\u001b[32m[09/07 09:59:55 d2.data.common]: \u001b[0mSerializing 190 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[09/07 09:59:55 d2.data.common]: \u001b[0mSerialized dataset takes 0.34 MiB\n",
            "\u001b[32m[09/07 09:59:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 190 images\n",
            "\u001b[32m[09/07 09:59:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/190. 0.3358 s / img. ETA=0:01:01\n",
            "\u001b[32m[09/07 10:00:05 d2.evaluation.evaluator]: \u001b[0mInference done 26/190. 0.3456 s / img. ETA=0:00:57\n",
            "\u001b[32m[09/07 10:00:10 d2.evaluation.evaluator]: \u001b[0mInference done 40/190. 0.3519 s / img. ETA=0:00:53\n",
            "\u001b[32m[09/07 10:00:15 d2.evaluation.evaluator]: \u001b[0mInference done 55/190. 0.3510 s / img. ETA=0:00:48\n",
            "\u001b[32m[09/07 10:00:20 d2.evaluation.evaluator]: \u001b[0mInference done 69/190. 0.3519 s / img. ETA=0:00:43\n",
            "\u001b[32m[09/07 10:00:25 d2.evaluation.evaluator]: \u001b[0mInference done 83/190. 0.3526 s / img. ETA=0:00:38\n",
            "\u001b[32m[09/07 10:00:31 d2.evaluation.evaluator]: \u001b[0mInference done 97/190. 0.3543 s / img. ETA=0:00:33\n",
            "\u001b[32m[09/07 10:00:36 d2.evaluation.evaluator]: \u001b[0mInference done 111/190. 0.3539 s / img. ETA=0:00:28\n",
            "\u001b[32m[09/07 10:00:41 d2.evaluation.evaluator]: \u001b[0mInference done 125/190. 0.3540 s / img. ETA=0:00:23\n",
            "\u001b[32m[09/07 10:00:46 d2.evaluation.evaluator]: \u001b[0mInference done 139/190. 0.3553 s / img. ETA=0:00:18\n",
            "\u001b[32m[09/07 10:00:51 d2.evaluation.evaluator]: \u001b[0mInference done 154/190. 0.3543 s / img. ETA=0:00:13\n",
            "\u001b[32m[09/07 10:00:56 d2.evaluation.evaluator]: \u001b[0mInference done 168/190. 0.3545 s / img. ETA=0:00:07\n",
            "\u001b[32m[09/07 10:01:01 d2.evaluation.evaluator]: \u001b[0mInference done 182/190. 0.3547 s / img. ETA=0:00:02\n",
            "\u001b[32m[09/07 10:01:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:06.936572 (0.361819 s / img per device, on 1 devices)\n",
            "\u001b[32m[09/07 10:01:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:05 (0.354702 s / img per device, on 1 devices)\n",
            "\u001b[32m[09/07 10:01:04 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[09/07 10:01:04 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /content/drive/MyDrive/detectron2_500/output_detect/coco_instances_results.json\n",
            "\u001b[32m[09/07 10:01:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.36s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.08s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.290\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.450\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.297\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.145\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.405\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.439\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.192\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.416\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.429\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.254\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.518\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.658\n",
            "\u001b[32m[09/07 10:01:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 28.984 | 45.037 | 29.704 | 14.522 | 40.464 | 43.913 |\n",
            "\u001b[32m[09/07 10:01:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category      | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:--------------|:-------|\n",
            "| aeroplane  | 54.573 | car        | 14.666 | chair         | 19.969 |\n",
            "| cow        | 49.022 | person     | 10.651 | traffic_light | 25.023 |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.38s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.08s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.233\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.424\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.253\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.115\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.325\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.379\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.160\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.349\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.359\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.220\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.435\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.528\n",
            "\u001b[32m[09/07 10:01:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 23.257 | 42.385 | 25.316 | 11.456 | 32.504 | 37.905 |\n",
            "\u001b[32m[09/07 10:01:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category   | AP     | category   | AP     | category      | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:--------------|:-------|\n",
            "| aeroplane  | 39.125 | car        | 13.696 | chair         | 14.429 |\n",
            "| cow        | 40.668 | person     | 8.840  | traffic_light | 22.782 |\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('bbox',\n",
              "              {'AP': 28.98399615813917,\n",
              "               'AP-aeroplane': 54.57337962218733,\n",
              "               'AP-car': 14.66612805636027,\n",
              "               'AP-chair': 19.969412071910146,\n",
              "               'AP-cow': 49.021736761204615,\n",
              "               'AP-person': 10.650646989033767,\n",
              "               'AP-traffic_light': 25.022673448138853,\n",
              "               'AP50': 45.03740027896978,\n",
              "               'AP75': 29.703910273555806,\n",
              "               'APl': 43.91260835680967,\n",
              "               'APm': 40.464182486473106,\n",
              "               'APs': 14.5215639775658}),\n",
              "             ('segm',\n",
              "              {'AP': 23.25659772128245,\n",
              "               'AP-aeroplane': 39.12518787892412,\n",
              "               'AP-car': 13.695654512165826,\n",
              "               'AP-chair': 14.429427753456547,\n",
              "               'AP-cow': 40.66808307048525,\n",
              "               'AP-person': 8.839691185693024,\n",
              "               'AP-traffic_light': 22.781541926969926,\n",
              "               'AP50': 42.384749137878536,\n",
              "               'AP75': 25.316161950387716,\n",
              "               'APl': 37.905305049520734,\n",
              "               'APm': 32.504470585780396,\n",
              "               'APs': 11.455878745055307})])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ2TVK3Gs9NM",
        "outputId": "cb82e055-b9bb-4b10-b436-a51c9be20380"
      },
      "source": [
        "import os\n",
        "#test evaluation\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "\n",
        "cfg.MODEL.WEIGHTS = '/content/drive/MyDrive/detectron2_500/output_detect/model_final.pth'\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.25\n",
        "predictor = DefaultPredictor(cfg)\n",
        "evaluator = COCOEvaluator(\"my_dataset_train2\", cfg, False, output_dir=\"/content/drive/MyDrive/detectron2_500/output_detect/\")\n",
        "val_loader = build_detection_test_loader(cfg, \"my_dataset_train2\")\n",
        "inference_on_dataset(trainer.model, val_loader, evaluator)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[09/07 10:01:50 d2.data.datasets.coco]: \u001b[0mLoaded 689 images in COCO format from /content/drive/MyDrive/detectron2_500/train.json\n",
            "\u001b[32m[09/07 10:01:51 d2.data.common]: \u001b[0mSerializing 689 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[09/07 10:01:51 d2.data.common]: \u001b[0mSerialized dataset takes 1.35 MiB\n",
            "\u001b[32m[09/07 10:01:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 689 images\n",
            "\u001b[32m[09/07 10:01:56 d2.evaluation.evaluator]: \u001b[0mInference done 11/689. 0.3721 s / img. ETA=0:04:15\n",
            "\u001b[32m[09/07 10:02:01 d2.evaluation.evaluator]: \u001b[0mInference done 26/689. 0.3502 s / img. ETA=0:03:55\n",
            "\u001b[32m[09/07 10:02:06 d2.evaluation.evaluator]: \u001b[0mInference done 41/689. 0.3476 s / img. ETA=0:03:49\n",
            "\u001b[32m[09/07 10:02:11 d2.evaluation.evaluator]: \u001b[0mInference done 55/689. 0.3501 s / img. ETA=0:03:46\n",
            "\u001b[32m[09/07 10:02:17 d2.evaluation.evaluator]: \u001b[0mInference done 69/689. 0.3517 s / img. ETA=0:03:43\n",
            "\u001b[32m[09/07 10:02:22 d2.evaluation.evaluator]: \u001b[0mInference done 83/689. 0.3539 s / img. ETA=0:03:39\n",
            "\u001b[32m[09/07 10:02:27 d2.evaluation.evaluator]: \u001b[0mInference done 97/689. 0.3543 s / img. ETA=0:03:34\n",
            "\u001b[32m[09/07 10:02:32 d2.evaluation.evaluator]: \u001b[0mInference done 111/689. 0.3550 s / img. ETA=0:03:29\n",
            "\u001b[32m[09/07 10:02:37 d2.evaluation.evaluator]: \u001b[0mInference done 125/689. 0.3552 s / img. ETA=0:03:24\n",
            "\u001b[32m[09/07 10:02:42 d2.evaluation.evaluator]: \u001b[0mInference done 139/689. 0.3558 s / img. ETA=0:03:20\n",
            "\u001b[32m[09/07 10:02:47 d2.evaluation.evaluator]: \u001b[0mInference done 153/689. 0.3563 s / img. ETA=0:03:15\n",
            "\u001b[32m[09/07 10:02:53 d2.evaluation.evaluator]: \u001b[0mInference done 167/689. 0.3569 s / img. ETA=0:03:10\n",
            "\u001b[32m[09/07 10:02:58 d2.evaluation.evaluator]: \u001b[0mInference done 182/689. 0.3560 s / img. ETA=0:03:04\n",
            "\u001b[32m[09/07 10:03:03 d2.evaluation.evaluator]: \u001b[0mInference done 196/689. 0.3558 s / img. ETA=0:02:59\n",
            "\u001b[32m[09/07 10:03:08 d2.evaluation.evaluator]: \u001b[0mInference done 210/689. 0.3567 s / img. ETA=0:02:54\n",
            "\u001b[32m[09/07 10:03:13 d2.evaluation.evaluator]: \u001b[0mInference done 225/689. 0.3556 s / img. ETA=0:02:48\n",
            "\u001b[32m[09/07 10:03:19 d2.evaluation.evaluator]: \u001b[0mInference done 240/689. 0.3553 s / img. ETA=0:02:43\n",
            "\u001b[32m[09/07 10:03:24 d2.evaluation.evaluator]: \u001b[0mInference done 254/689. 0.3551 s / img. ETA=0:02:37\n",
            "\u001b[32m[09/07 10:03:29 d2.evaluation.evaluator]: \u001b[0mInference done 268/689. 0.3556 s / img. ETA=0:02:32\n",
            "\u001b[32m[09/07 10:03:34 d2.evaluation.evaluator]: \u001b[0mInference done 282/689. 0.3553 s / img. ETA=0:02:27\n",
            "\u001b[32m[09/07 10:03:39 d2.evaluation.evaluator]: \u001b[0mInference done 296/689. 0.3557 s / img. ETA=0:02:22\n",
            "\u001b[32m[09/07 10:03:44 d2.evaluation.evaluator]: \u001b[0mInference done 310/689. 0.3559 s / img. ETA=0:02:17\n",
            "\u001b[32m[09/07 10:03:50 d2.evaluation.evaluator]: \u001b[0mInference done 325/689. 0.3554 s / img. ETA=0:02:12\n",
            "\u001b[32m[09/07 10:03:55 d2.evaluation.evaluator]: \u001b[0mInference done 339/689. 0.3555 s / img. ETA=0:02:07\n",
            "\u001b[32m[09/07 10:04:00 d2.evaluation.evaluator]: \u001b[0mInference done 353/689. 0.3554 s / img. ETA=0:02:01\n",
            "\u001b[32m[09/07 10:04:05 d2.evaluation.evaluator]: \u001b[0mInference done 367/689. 0.3560 s / img. ETA=0:01:57\n",
            "\u001b[32m[09/07 10:04:10 d2.evaluation.evaluator]: \u001b[0mInference done 381/689. 0.3558 s / img. ETA=0:01:51\n",
            "\u001b[32m[09/07 10:04:15 d2.evaluation.evaluator]: \u001b[0mInference done 395/689. 0.3561 s / img. ETA=0:01:47\n",
            "\u001b[32m[09/07 10:04:21 d2.evaluation.evaluator]: \u001b[0mInference done 409/689. 0.3562 s / img. ETA=0:01:41\n",
            "\u001b[32m[09/07 10:04:26 d2.evaluation.evaluator]: \u001b[0mInference done 423/689. 0.3561 s / img. ETA=0:01:36\n",
            "\u001b[32m[09/07 10:04:31 d2.evaluation.evaluator]: \u001b[0mInference done 438/689. 0.3557 s / img. ETA=0:01:31\n",
            "\u001b[32m[09/07 10:04:36 d2.evaluation.evaluator]: \u001b[0mInference done 453/689. 0.3555 s / img. ETA=0:01:25\n",
            "\u001b[32m[09/07 10:04:41 d2.evaluation.evaluator]: \u001b[0mInference done 467/689. 0.3555 s / img. ETA=0:01:20\n",
            "\u001b[32m[09/07 10:04:46 d2.evaluation.evaluator]: \u001b[0mInference done 481/689. 0.3555 s / img. ETA=0:01:15\n",
            "\u001b[32m[09/07 10:04:52 d2.evaluation.evaluator]: \u001b[0mInference done 495/689. 0.3558 s / img. ETA=0:01:10\n",
            "\u001b[32m[09/07 10:04:57 d2.evaluation.evaluator]: \u001b[0mInference done 509/689. 0.3560 s / img. ETA=0:01:05\n",
            "\u001b[32m[09/07 10:05:02 d2.evaluation.evaluator]: \u001b[0mInference done 523/689. 0.3561 s / img. ETA=0:01:00\n",
            "\u001b[32m[09/07 10:05:07 d2.evaluation.evaluator]: \u001b[0mInference done 537/689. 0.3564 s / img. ETA=0:00:55\n",
            "\u001b[32m[09/07 10:05:12 d2.evaluation.evaluator]: \u001b[0mInference done 551/689. 0.3565 s / img. ETA=0:00:50\n",
            "\u001b[32m[09/07 10:05:18 d2.evaluation.evaluator]: \u001b[0mInference done 565/689. 0.3569 s / img. ETA=0:00:45\n",
            "\u001b[32m[09/07 10:05:23 d2.evaluation.evaluator]: \u001b[0mInference done 580/689. 0.3565 s / img. ETA=0:00:39\n",
            "\u001b[32m[09/07 10:05:28 d2.evaluation.evaluator]: \u001b[0mInference done 594/689. 0.3567 s / img. ETA=0:00:34\n",
            "\u001b[32m[09/07 10:05:33 d2.evaluation.evaluator]: \u001b[0mInference done 608/689. 0.3567 s / img. ETA=0:00:29\n",
            "\u001b[32m[09/07 10:05:38 d2.evaluation.evaluator]: \u001b[0mInference done 622/689. 0.3568 s / img. ETA=0:00:24\n",
            "\u001b[32m[09/07 10:05:43 d2.evaluation.evaluator]: \u001b[0mInference done 636/689. 0.3569 s / img. ETA=0:00:19\n",
            "\u001b[32m[09/07 10:05:49 d2.evaluation.evaluator]: \u001b[0mInference done 650/689. 0.3571 s / img. ETA=0:00:14\n",
            "\u001b[32m[09/07 10:05:54 d2.evaluation.evaluator]: \u001b[0mInference done 664/689. 0.3573 s / img. ETA=0:00:09\n",
            "\u001b[32m[09/07 10:05:59 d2.evaluation.evaluator]: \u001b[0mInference done 678/689. 0.3576 s / img. ETA=0:00:04\n",
            "\u001b[32m[09/07 10:06:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:09.766333 (0.365155 s / img per device, on 1 devices)\n",
            "\u001b[32m[09/07 10:06:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:04:04 (0.357571 s / img per device, on 1 devices)\n",
            "\u001b[32m[09/07 10:06:03 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[09/07 10:06:03 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /content/drive/MyDrive/detectron2_500/output_detect/coco_instances_results.json\n",
            "\u001b[32m[09/07 10:06:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.56s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.17s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.901\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.987\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.975\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.877\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.935\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.961\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.341\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.897\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.931\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.902\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.962\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.983\n",
            "\u001b[32m[09/07 10:06:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 90.144 | 98.731 | 97.528 | 87.734 | 93.536 | 96.084 |\n",
            "\u001b[32m[09/07 10:06:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category      | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:--------------|:-------|\n",
            "| aeroplane  | 97.505 | car        | 87.769 | chair         | 89.474 |\n",
            "| cow        | 90.475 | person     | 90.239 | traffic_light | 85.403 |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=1.63s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.19s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.710\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.977\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.851\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.656\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.743\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.854\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.293\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.754\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.781\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.722\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.807\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.892\n",
            "\u001b[32m[09/07 10:06:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 71.048 | 97.700 | 85.071 | 65.572 | 74.309 | 85.446 |\n",
            "\u001b[32m[09/07 10:06:07 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category   | AP     | category   | AP     | category      | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:--------------|:-------|\n",
            "| aeroplane  | 72.378 | car        | 73.344 | chair         | 68.960 |\n",
            "| cow        | 66.688 | person     | 69.088 | traffic_light | 75.830 |\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('bbox',\n",
              "              {'AP': 90.14414637284705,\n",
              "               'AP-aeroplane': 97.5046735442775,\n",
              "               'AP-car': 87.76866864133054,\n",
              "               'AP-chair': 89.47432734229967,\n",
              "               'AP-cow': 90.4748976867685,\n",
              "               'AP-person': 90.23886735543314,\n",
              "               'AP-traffic_light': 85.40344366697295,\n",
              "               'AP50': 98.73068806907918,\n",
              "               'AP75': 97.52827898558189,\n",
              "               'APl': 96.084273558184,\n",
              "               'APm': 93.53585458883222,\n",
              "               'APs': 87.73384424280555}),\n",
              "             ('segm',\n",
              "              {'AP': 71.0479835296563,\n",
              "               'AP-aeroplane': 72.37761169743177,\n",
              "               'AP-car': 73.34421383141503,\n",
              "               'AP-chair': 68.96028807350005,\n",
              "               'AP-cow': 66.68790716391861,\n",
              "               'AP-person': 69.0876560609309,\n",
              "               'AP-traffic_light': 75.83022435074153,\n",
              "               'AP50': 97.70041956815953,\n",
              "               'AP75': 85.07104841918662,\n",
              "               'APl': 85.44634382492144,\n",
              "               'APm': 74.30907903234747,\n",
              "               'APs': 65.5720124624275})])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mdfzn5wmS1tJ",
        "outputId": "605d87ac-e076-4311-b640-54c2e17330d4"
      },
      "source": [
        "import os\n",
        "#test evaluation\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "\n",
        "cfg.MODEL.WEIGHTS = '/content/drive/MyDrive/detectron2_500/output_detect/model_0085999.pth'\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.25\n",
        "predictor = DefaultPredictor(cfg)\n",
        "evaluator = COCOEvaluator(\"my_dataset_train2\", cfg, False, output_dir=\"/content/drive/MyDrive/detectron2_500/output_detect/\")\n",
        "val_loader = build_detection_test_loader(cfg, \"my_dataset_train2\")\n",
        "inference_on_dataset(trainer.model, val_loader, evaluator)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[09/07 10:11:34 d2.data.datasets.coco]: \u001b[0mLoaded 689 images in COCO format from /content/drive/MyDrive/detectron2_500/train.json\n",
            "\u001b[32m[09/07 10:11:34 d2.data.common]: \u001b[0mSerializing 689 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[09/07 10:11:34 d2.data.common]: \u001b[0mSerialized dataset takes 1.35 MiB\n",
            "\u001b[32m[09/07 10:11:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 689 images\n",
            "\u001b[32m[09/07 10:11:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/689. 0.3663 s / img. ETA=0:04:11\n",
            "\u001b[32m[09/07 10:11:43 d2.evaluation.evaluator]: \u001b[0mInference done 26/689. 0.3474 s / img. ETA=0:03:53\n",
            "\u001b[32m[09/07 10:11:49 d2.evaluation.evaluator]: \u001b[0mInference done 41/689. 0.3452 s / img. ETA=0:03:47\n",
            "\u001b[32m[09/07 10:11:54 d2.evaluation.evaluator]: \u001b[0mInference done 55/689. 0.3478 s / img. ETA=0:03:43\n",
            "\u001b[32m[09/07 10:11:59 d2.evaluation.evaluator]: \u001b[0mInference done 69/689. 0.3492 s / img. ETA=0:03:40\n",
            "\u001b[32m[09/07 10:12:04 d2.evaluation.evaluator]: \u001b[0mInference done 83/689. 0.3514 s / img. ETA=0:03:37\n",
            "\u001b[32m[09/07 10:12:09 d2.evaluation.evaluator]: \u001b[0mInference done 97/689. 0.3519 s / img. ETA=0:03:32\n",
            "\u001b[32m[09/07 10:12:14 d2.evaluation.evaluator]: \u001b[0mInference done 111/689. 0.3530 s / img. ETA=0:03:27\n",
            "\u001b[32m[09/07 10:12:19 d2.evaluation.evaluator]: \u001b[0mInference done 125/689. 0.3535 s / img. ETA=0:03:23\n",
            "\u001b[32m[09/07 10:12:24 d2.evaluation.evaluator]: \u001b[0mInference done 139/689. 0.3543 s / img. ETA=0:03:18\n",
            "\u001b[32m[09/07 10:12:30 d2.evaluation.evaluator]: \u001b[0mInference done 153/689. 0.3549 s / img. ETA=0:03:13\n",
            "\u001b[32m[09/07 10:12:35 d2.evaluation.evaluator]: \u001b[0mInference done 167/689. 0.3555 s / img. ETA=0:03:09\n",
            "\u001b[32m[09/07 10:12:40 d2.evaluation.evaluator]: \u001b[0mInference done 182/689. 0.3548 s / img. ETA=0:03:03\n",
            "\u001b[32m[09/07 10:12:45 d2.evaluation.evaluator]: \u001b[0mInference done 196/689. 0.3549 s / img. ETA=0:02:58\n",
            "\u001b[32m[09/07 10:12:50 d2.evaluation.evaluator]: \u001b[0mInference done 210/689. 0.3560 s / img. ETA=0:02:53\n",
            "\u001b[32m[09/07 10:12:56 d2.evaluation.evaluator]: \u001b[0mInference done 225/689. 0.3549 s / img. ETA=0:02:47\n",
            "\u001b[32m[09/07 10:13:01 d2.evaluation.evaluator]: \u001b[0mInference done 240/689. 0.3547 s / img. ETA=0:02:42\n",
            "\u001b[32m[09/07 10:13:06 d2.evaluation.evaluator]: \u001b[0mInference done 254/689. 0.3546 s / img. ETA=0:02:37\n",
            "\u001b[32m[09/07 10:13:11 d2.evaluation.evaluator]: \u001b[0mInference done 268/689. 0.3551 s / img. ETA=0:02:32\n",
            "\u001b[32m[09/07 10:13:16 d2.evaluation.evaluator]: \u001b[0mInference done 282/689. 0.3549 s / img. ETA=0:02:27\n",
            "\u001b[32m[09/07 10:13:21 d2.evaluation.evaluator]: \u001b[0mInference done 296/689. 0.3555 s / img. ETA=0:02:22\n",
            "\u001b[32m[09/07 10:13:27 d2.evaluation.evaluator]: \u001b[0mInference done 310/689. 0.3557 s / img. ETA=0:02:17\n",
            "\u001b[32m[09/07 10:13:32 d2.evaluation.evaluator]: \u001b[0mInference done 325/689. 0.3553 s / img. ETA=0:02:11\n",
            "\u001b[32m[09/07 10:13:37 d2.evaluation.evaluator]: \u001b[0mInference done 339/689. 0.3556 s / img. ETA=0:02:06\n",
            "\u001b[32m[09/07 10:13:42 d2.evaluation.evaluator]: \u001b[0mInference done 353/689. 0.3556 s / img. ETA=0:02:01\n",
            "\u001b[32m[09/07 10:13:47 d2.evaluation.evaluator]: \u001b[0mInference done 367/689. 0.3561 s / img. ETA=0:01:56\n",
            "\u001b[32m[09/07 10:13:52 d2.evaluation.evaluator]: \u001b[0mInference done 381/689. 0.3561 s / img. ETA=0:01:51\n",
            "\u001b[32m[09/07 10:13:58 d2.evaluation.evaluator]: \u001b[0mInference done 395/689. 0.3565 s / img. ETA=0:01:46\n",
            "\u001b[32m[09/07 10:14:03 d2.evaluation.evaluator]: \u001b[0mInference done 409/689. 0.3566 s / img. ETA=0:01:41\n",
            "\u001b[32m[09/07 10:14:08 d2.evaluation.evaluator]: \u001b[0mInference done 423/689. 0.3567 s / img. ETA=0:01:36\n",
            "\u001b[32m[09/07 10:14:13 d2.evaluation.evaluator]: \u001b[0mInference done 438/689. 0.3565 s / img. ETA=0:01:31\n",
            "\u001b[32m[09/07 10:14:18 d2.evaluation.evaluator]: \u001b[0mInference done 452/689. 0.3564 s / img. ETA=0:01:26\n",
            "\u001b[32m[09/07 10:14:24 d2.evaluation.evaluator]: \u001b[0mInference done 466/689. 0.3565 s / img. ETA=0:01:20\n",
            "\u001b[32m[09/07 10:14:29 d2.evaluation.evaluator]: \u001b[0mInference done 480/689. 0.3564 s / img. ETA=0:01:15\n",
            "\u001b[32m[09/07 10:14:34 d2.evaluation.evaluator]: \u001b[0mInference done 494/689. 0.3567 s / img. ETA=0:01:10\n",
            "\u001b[32m[09/07 10:14:39 d2.evaluation.evaluator]: \u001b[0mInference done 508/689. 0.3568 s / img. ETA=0:01:05\n",
            "\u001b[32m[09/07 10:14:44 d2.evaluation.evaluator]: \u001b[0mInference done 522/689. 0.3568 s / img. ETA=0:01:00\n",
            "\u001b[32m[09/07 10:14:49 d2.evaluation.evaluator]: \u001b[0mInference done 536/689. 0.3569 s / img. ETA=0:00:55\n",
            "\u001b[32m[09/07 10:14:54 d2.evaluation.evaluator]: \u001b[0mInference done 550/689. 0.3569 s / img. ETA=0:00:50\n",
            "\u001b[32m[09/07 10:14:59 d2.evaluation.evaluator]: \u001b[0mInference done 564/689. 0.3572 s / img. ETA=0:00:45\n",
            "\u001b[32m[09/07 10:15:05 d2.evaluation.evaluator]: \u001b[0mInference done 579/689. 0.3567 s / img. ETA=0:00:39\n",
            "\u001b[32m[09/07 10:15:10 d2.evaluation.evaluator]: \u001b[0mInference done 593/689. 0.3568 s / img. ETA=0:00:34\n",
            "\u001b[32m[09/07 10:15:15 d2.evaluation.evaluator]: \u001b[0mInference done 608/689. 0.3566 s / img. ETA=0:00:29\n",
            "\u001b[32m[09/07 10:15:20 d2.evaluation.evaluator]: \u001b[0mInference done 622/689. 0.3566 s / img. ETA=0:00:24\n",
            "\u001b[32m[09/07 10:15:25 d2.evaluation.evaluator]: \u001b[0mInference done 636/689. 0.3566 s / img. ETA=0:00:19\n",
            "\u001b[32m[09/07 10:15:30 d2.evaluation.evaluator]: \u001b[0mInference done 650/689. 0.3567 s / img. ETA=0:00:14\n",
            "\u001b[32m[09/07 10:15:36 d2.evaluation.evaluator]: \u001b[0mInference done 664/689. 0.3569 s / img. ETA=0:00:09\n",
            "\u001b[32m[09/07 10:15:41 d2.evaluation.evaluator]: \u001b[0mInference done 678/689. 0.3571 s / img. ETA=0:00:03\n",
            "\u001b[32m[09/07 10:15:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:08.648143 (0.363521 s / img per device, on 1 devices)\n",
            "\u001b[32m[09/07 10:15:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:04:04 (0.356970 s / img per device, on 1 devices)\n",
            "\u001b[32m[09/07 10:15:45 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[09/07 10:15:45 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /content/drive/MyDrive/detectron2_500/output_detect/coco_instances_results.json\n",
            "\u001b[32m[09/07 10:15:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.45s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.17s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.901\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.987\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.975\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.877\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.935\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.961\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.341\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.897\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.931\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.902\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.962\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.983\n",
            "\u001b[32m[09/07 10:15:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 90.144 | 98.731 | 97.528 | 87.734 | 93.536 | 96.084 |\n",
            "\u001b[32m[09/07 10:15:47 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category      | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:--------------|:-------|\n",
            "| aeroplane  | 97.505 | car        | 87.769 | chair         | 89.474 |\n",
            "| cow        | 90.475 | person     | 90.239 | traffic_light | 85.403 |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=1.76s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.17s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.710\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.977\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.851\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.656\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.743\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.854\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.293\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.754\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.781\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.722\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.807\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.892\n",
            "\u001b[32m[09/07 10:15:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 71.048 | 97.700 | 85.071 | 65.572 | 74.309 | 85.446 |\n",
            "\u001b[32m[09/07 10:15:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category   | AP     | category   | AP     | category      | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:--------------|:-------|\n",
            "| aeroplane  | 72.378 | car        | 73.344 | chair         | 68.960 |\n",
            "| cow        | 66.688 | person     | 69.088 | traffic_light | 75.830 |\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('bbox',\n",
              "              {'AP': 90.14414637284705,\n",
              "               'AP-aeroplane': 97.5046735442775,\n",
              "               'AP-car': 87.76866864133054,\n",
              "               'AP-chair': 89.47432734229967,\n",
              "               'AP-cow': 90.4748976867685,\n",
              "               'AP-person': 90.23886735543314,\n",
              "               'AP-traffic_light': 85.40344366697295,\n",
              "               'AP50': 98.73068806907918,\n",
              "               'AP75': 97.52827898558189,\n",
              "               'APl': 96.084273558184,\n",
              "               'APm': 93.53585458883222,\n",
              "               'APs': 87.73384424280555}),\n",
              "             ('segm',\n",
              "              {'AP': 71.0479835296563,\n",
              "               'AP-aeroplane': 72.37761169743177,\n",
              "               'AP-car': 73.34421383141503,\n",
              "               'AP-chair': 68.96028807350005,\n",
              "               'AP-cow': 66.68790716391861,\n",
              "               'AP-person': 69.0876560609309,\n",
              "               'AP-traffic_light': 75.83022435074153,\n",
              "               'AP50': 97.70041956815953,\n",
              "               'AP75': 85.07104841918662,\n",
              "               'APl': 85.44634382492144,\n",
              "               'APm': 74.30907903234747,\n",
              "               'APs': 65.5720124624275})])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uj7B0legToC1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}