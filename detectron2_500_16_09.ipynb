{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "detectron2_500_27.08.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "161RJsMPnS_LaJASy9Cw87jpA8joHvcWa",
      "authorship_tag": "ABX9TyN/9h6IUSmH+4hsoPFnsZ6d",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vidyabandgar97/A2A/blob/main/detectron2_500_16_09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yw3X08oHoWnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93ef1287-2cf5-4cd5-9f2e-e2307728e183"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NVlkSGGogwA",
        "outputId": "66eb606b-d97c-4c9d-a14f-6c7fba036ea5"
      },
      "source": [
        "%cd /content/drive/MyDrive/detectron2_500/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/detectron2_500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zIPp3vtogy1",
        "outputId": "d6bf7714-9056-4d3c-f9e1-0ea1ed5a7b36"
      },
      "source": [
        "# install dependencies: (use cu101 because colab has CUDA 10.1)\n",
        "!pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html \n",
        "!pip install cython pyyaml==5.1\n",
        "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version\n",
        "# opencv is pre-installed on colab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/cu101/torch_stable.html\n",
            "Requirement already satisfied: torch==1.5 in /usr/local/lib/python3.7/dist-packages (1.5.0+cu101)\n",
            "Requirement already satisfied: torchvision==0.6 in /usr/local/lib/python3.7/dist-packages (0.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.5) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.5) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.6) (7.1.2)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (0.29.24)\n",
            "Requirement already satisfied: pyyaml==5.1 in /usr/local/lib/python3.7/dist-packages (5.1)\n",
            "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-ig0k00xf\n",
            "  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-ig0k00xf\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (57.4.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (0.29.24)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.19.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools==2.0) (1.15.0)\n",
            "1.5.0+cu101 True\n",
            "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Copyright (C) 2017 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNRsGvvkog2s",
        "outputId": "b44a0631-cfd6-44c3-9489-e7826c1c4546"
      },
      "source": [
        "!pip install torch==1.9.0 torchvision==0.4.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.9.0\n",
            "  Using cached torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
            "Collecting torchvision==0.4.1\n",
            "  Using cached torchvision-0.4.1-cp37-cp37m-manylinux1_x86_64.whl (10.1 MB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.4.1) (1.19.5)\n",
            "INFO: pip is looking at multiple versions of <Python from Requires-Python> to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Cannot install torch==1.9.0 and torchvision==0.4.1 because these package versions have conflicting dependencies.\u001b[0m\n",
            "\n",
            "The conflict is caused by:\n",
            "    The user requested torch==1.9.0\n",
            "    torchvision 0.4.1 depends on torch==1.3.0\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
            "\n",
            "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/user_guide/#fixing-conflicting-dependencies\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WDn770log5j",
        "outputId": "9c41b358-0992-4e17-e4fc-a166671ccfc6"
      },
      "source": [
        "!pip install detectron2==0.1.3 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html\n",
            "Requirement already satisfied: detectron2==0.1.3 in /usr/local/lib/python3.7/dist-packages (0.1.3+cu101)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (0.8.9)\n",
            "Requirement already satisfied: fvcore>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (0.1.5.post20210915)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (7.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (3.2.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (2.6.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (0.16.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (1.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (1.1.0)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (0.1.8)\n",
            "Requirement already satisfied: mock in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (4.0.3)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (4.62.0)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.3) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore>=0.1.1->detectron2==0.1.3) (1.19.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore>=0.1.1->detectron2==0.1.3) (5.1)\n",
            "Requirement already satisfied: iopath>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from fvcore>=0.1.1->detectron2==0.1.3) (0.1.9)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from iopath>=0.1.7->fvcore>=0.1.1->detectron2==0.1.3) (2.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.1.3) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.1.3) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.1.3) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.1.3) (1.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->detectron2==0.1.3) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (3.17.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (0.37.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (0.4.5)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (0.12.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (1.39.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (0.6.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (1.34.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.3) (57.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.1.3) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->detectron2==0.1.3) (4.6.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.3) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.3) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.1.3) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->detectron2==0.1.3) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->detectron2==0.1.3) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oxi7m9lAog_x"
      },
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2ZpZRvY8xmE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "59e21680-63f5-4998-ac64-b31bce95acd2"
      },
      "source": [
        "#if your dataset is in COCO format, this cell can be replaced by the following three lines:\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "register_coco_instances(\"my_dataset_train2\", {}, \"/content/drive/MyDrive/detectron2_500/train.json\", \"/content/drive/MyDrive/detectron2_500/Dataset\")\n",
        "register_coco_instances(\"my_dataset_val2\", {}, \"/content/drive/MyDrive/detectron2_500/test.json\", \"/content/drive/MyDrive/detectron2_500/test_data\")\n",
        "register_coco_instances(\"my_dataset_test2\", {}, \"/content/drive/MyDrive/detectron2_500/test.json\", \"/content/drive/MyDrive/detectron2_500/test_data\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-56eabaad391e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#if your dataset is in COCO format, this cell can be replaced by the following three lines:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregister_coco_instances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mregister_coco_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"my_dataset_train2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/detectron2_500/train.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/detectron2_500/Dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mregister_coco_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"my_dataset_val2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/detectron2_500/test.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/detectron2_500/test_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mregister_coco_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"my_dataset_test2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/detectron2_500/test.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/detectron2_500/test_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/data/datasets/register_coco.py\u001b[0m in \u001b[0;36mregister_coco_instances\u001b[0;34m(name, metadata, json_file, image_root)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_root\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# 1. register a function which returns dicts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mDatasetCatalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mload_coco_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# 2. Optionally, add metadata about this dataset,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/data/catalog.py\u001b[0m in \u001b[0;36mregister\u001b[0;34m(name, func)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"You must register a function with `DatasetCatalog.register`!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         assert name not in DatasetCatalog._REGISTERED, \"Dataset '{}' is already registered!\".format(\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         )\n\u001b[1;32m     41\u001b[0m         \u001b[0mDatasetCatalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_REGISTERED\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Dataset 'my_dataset_train2' is already registered!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HG8JZ6Hb84hs"
      },
      "source": [
        "#We are importing our own Trainer Module here to use the COCO validation evaluation during training. Otherwise no validation eval occurs.\n",
        "\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.evaluation import COCOEvaluator\n",
        "from detectron2.data import transforms as T\n",
        "\n",
        "from detectron2.data import (\n",
        "    MetadataCatalog,\n",
        "    build_detection_test_loader,\n",
        "    build_detection_train_loader,\n",
        ")\n",
        "\n",
        "from detectron2.data import DatasetMapper   # the default mapper"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrSl7Hn_87eZ"
      },
      "source": [
        "class CocoTrainer(DefaultTrainer):\n",
        "\n",
        "  @classmethod\n",
        "  def build_train_loader(cls, cfg):\n",
        "    return build_detection_train_loader(\n",
        "        cfg, \n",
        "        mapper=DatasetMapper(\n",
        "            cfg, \n",
        "            is_train=True, \n",
        "            augmentations=[\n",
        "                           T.RandomFlip(prob=0.5),\n",
        "                           T.augmentation_impl.RandomBrightness(0.5, 1.5),\n",
        "                           #T.augmentation_impl.RandomRotation(30),\n",
        "                           T.RandomLighting(scale=1.4),\n",
        "                           T.RandomCrop(\"absolute\", (640, 480))\n",
        "                           ]\n",
        "        )\n",
        "    )\n",
        "\n",
        "  @classmethod\n",
        "  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "    if output_folder is None:\n",
        "        os.makedirs(\"coco_eval\", exist_ok=True)\n",
        "        output_folder = \"coco_eval\"\n",
        "\n",
        "    return COCOEvaluator(dataset_name, cfg, False, output_folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUYTHFK9ohHJ",
        "outputId": "541136dc-4859-41d5-9521-f3478144b9d9"
      },
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "import os\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.OUTPUT_DIR = \"/content/drive/MyDrive/detectron2_500/output_detect\"\n",
        "cfg.SOLVER.CHECKPOINT_PERIOD = 1000\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"Misc/mask_rcnn_R_50_FPN_3x_dconv_c3-c5.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"my_dataset_train2\",)\n",
        "cfg.DATASETS.TEST = (\"my_dataset_val2\",)\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"Misc/mask_rcnn_R_50_FPN_3x_dconv_c3-c5.yaml\")  # Let training initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
        "cfg.SOLVER.MAX_ITER = 130000    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
        "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 6  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
        "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg) \n",
        "trainer.resume_or_load(resume=True)\n",
        "trainer.train()\n",
        "#trainer.test()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[09/16 09:37:34 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): DeformBottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(128, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): DeformBottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(128, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): DeformBottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(128, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): DeformBottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(128, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): DeformBottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=256, out_channels=256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): DeformBottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=256, out_channels=256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): DeformBottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=256, out_channels=256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): DeformBottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=256, out_channels=256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): DeformBottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=256, out_channels=256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): DeformBottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=256, out_channels=256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): DeformBottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): DeformBottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): DeformBottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (conv2): DeformConv(\n",
            "            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=1, deformable_groups=1, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[09/16 09:37:34 d2.data.datasets.coco]: \u001b[0mLoaded 689 images in COCO format from /content/drive/MyDrive/detectron2_500/train.json\n",
            "\u001b[32m[09/16 09:37:34 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 689 images left.\n",
            "\u001b[32m[09/16 09:37:34 d2.data.common]: \u001b[0mSerializing 689 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[09/16 09:37:34 d2.data.common]: \u001b[0mSerialized dataset takes 1.35 MiB\n",
            "\u001b[32m[09/16 09:37:34 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[09/16 09:37:34 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[09/16 09:37:35 d2.engine.train_loop]: \u001b[0mStarting training from iteration 130000\n",
            "\u001b[32m[09/16 09:37:35 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:00 (0:00:00 on hooks)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPQ6fhWLohNp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98e4ab38-a9fa-4e7e-baec-3f6208e56795"
      },
      "source": [
        "import os\n",
        "#test evaluation\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "\n",
        "cfg.MODEL.WEIGHTS = '/content/drive/MyDrive/detectron2_500/output_detect/model_final.pth'\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.25\n",
        "predictor = DefaultPredictor(cfg)\n",
        "evaluator = COCOEvaluator(\"my_dataset_val2\", cfg, False, output_dir=\"/content/drive/MyDrive/detectron2_500/output_detect/\")\n",
        "val_loader = build_detection_test_loader(cfg, \"my_dataset_val2\")\n",
        "inference_on_dataset(trainer.model, val_loader, evaluator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[09/16 09:37:41 d2.data.datasets.coco]: \u001b[0mLoaded 190 images in COCO format from /content/drive/MyDrive/detectron2_500/test.json\n",
            "\u001b[32m[09/16 09:37:41 d2.data.common]: \u001b[0mSerializing 190 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[09/16 09:37:41 d2.data.common]: \u001b[0mSerialized dataset takes 0.34 MiB\n",
            "\u001b[32m[09/16 09:37:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 190 images\n",
            "\u001b[32m[09/16 09:37:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/190. 0.3652 s / img. ETA=0:01:06\n",
            "\u001b[32m[09/16 09:37:50 d2.evaluation.evaluator]: \u001b[0mInference done 24/190. 0.3796 s / img. ETA=0:01:04\n",
            "\u001b[32m[09/16 09:37:56 d2.evaluation.evaluator]: \u001b[0mInference done 37/190. 0.3860 s / img. ETA=0:00:59\n",
            "\u001b[32m[09/16 09:38:01 d2.evaluation.evaluator]: \u001b[0mInference done 50/190. 0.3868 s / img. ETA=0:00:55\n",
            "\u001b[32m[09/16 09:38:06 d2.evaluation.evaluator]: \u001b[0mInference done 63/190. 0.3853 s / img. ETA=0:00:49\n",
            "\u001b[32m[09/16 09:38:11 d2.evaluation.evaluator]: \u001b[0mInference done 76/190. 0.3871 s / img. ETA=0:00:44\n",
            "\u001b[32m[09/16 09:38:16 d2.evaluation.evaluator]: \u001b[0mInference done 89/190. 0.3880 s / img. ETA=0:00:39\n",
            "\u001b[32m[09/16 09:38:21 d2.evaluation.evaluator]: \u001b[0mInference done 102/190. 0.3871 s / img. ETA=0:00:34\n",
            "\u001b[32m[09/16 09:38:26 d2.evaluation.evaluator]: \u001b[0mInference done 115/190. 0.3871 s / img. ETA=0:00:29\n",
            "\u001b[32m[09/16 09:38:32 d2.evaluation.evaluator]: \u001b[0mInference done 128/190. 0.3870 s / img. ETA=0:00:24\n",
            "\u001b[32m[09/16 09:38:37 d2.evaluation.evaluator]: \u001b[0mInference done 141/190. 0.3876 s / img. ETA=0:00:19\n",
            "\u001b[32m[09/16 09:38:42 d2.evaluation.evaluator]: \u001b[0mInference done 155/190. 0.3857 s / img. ETA=0:00:13\n",
            "\u001b[32m[09/16 09:38:47 d2.evaluation.evaluator]: \u001b[0mInference done 168/190. 0.3855 s / img. ETA=0:00:08\n",
            "\u001b[32m[09/16 09:38:52 d2.evaluation.evaluator]: \u001b[0mInference done 181/190. 0.3855 s / img. ETA=0:00:03\n",
            "\u001b[32m[09/16 09:38:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:12.483073 (0.391800 s / img per device, on 1 devices)\n",
            "\u001b[32m[09/16 09:38:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:11 (0.384892 s / img per device, on 1 devices)\n",
            "\u001b[32m[09/16 09:38:56 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[09/16 09:38:56 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /content/drive/MyDrive/detectron2_500/output_detect/coco_instances_results.json\n",
            "\u001b[32m[09/16 09:38:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.32s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.07s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.280\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.430\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.291\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.140\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.385\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.465\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.189\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.408\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.418\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.249\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.494\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.652\n",
            "\u001b[32m[09/16 09:38:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 27.981 | 43.016 | 29.089 | 14.022 | 38.481 | 46.463 |\n",
            "\u001b[32m[09/16 09:38:56 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category      | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:--------------|:-------|\n",
            "| aeroplane  | 52.407 | car        | 15.598 | chair         | 20.299 |\n",
            "| cow        | 45.846 | person     | 10.363 | traffic_light | 23.374 |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.32s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.07s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.226\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.400\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.239\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.114\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.314\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.403\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.160\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.343\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.352\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.218\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.418\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.520\n",
            "\u001b[32m[09/16 09:38:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 22.571 | 40.010 | 23.853 | 11.406 | 31.390 | 40.345 |\n",
            "\u001b[32m[09/16 09:38:57 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category   | AP     | category   | AP     | category      | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:--------------|:-------|\n",
            "| aeroplane  | 37.695 | car        | 13.959 | chair         | 13.915 |\n",
            "| cow        | 39.502 | person     | 8.033  | traffic_light | 22.321 |\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('bbox',\n",
              "              {'AP': 27.981311353706328,\n",
              "               'AP-aeroplane': 52.407318064862515,\n",
              "               'AP-car': 15.597922854139112,\n",
              "               'AP-chair': 20.29922947581379,\n",
              "               'AP-cow': 45.84647956728704,\n",
              "               'AP-person': 10.362980208816094,\n",
              "               'AP-traffic_light': 23.373937951319398,\n",
              "               'AP50': 43.016248267860895,\n",
              "               'AP75': 29.08869658632148,\n",
              "               'APl': 46.46331370654038,\n",
              "               'APm': 38.48135745431186,\n",
              "               'APs': 14.021736398351559}),\n",
              "             ('segm',\n",
              "              {'AP': 22.570844306529565,\n",
              "               'AP-aeroplane': 37.69468899380797,\n",
              "               'AP-car': 13.959149910418912,\n",
              "               'AP-chair': 13.914549574229124,\n",
              "               'AP-cow': 39.502491668149645,\n",
              "               'AP-person': 8.033183650497085,\n",
              "               'AP-traffic_light': 22.321002042074632,\n",
              "               'AP50': 40.010157880886474,\n",
              "               'AP75': 23.853043664183446,\n",
              "               'APl': 40.34496386857583,\n",
              "               'APm': 31.390372284017147,\n",
              "               'APs': 11.405626116494378})])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4Z_i-GZSyMy",
        "outputId": "fbe9e818-20d5-4f3c-bb2a-074852ee6297"
      },
      "source": [
        "import os\n",
        "#test evaluation\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "\n",
        "cfg.MODEL.WEIGHTS = '/content/drive/MyDrive/detectron2_500/output_detect/model_0092000.pth'\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.25\n",
        "predictor = DefaultPredictor(cfg)\n",
        "evaluator = COCOEvaluator(\"my_dataset_val2\", cfg, False, output_dir=\"/content/drive/MyDrive/detectron2_500/output_detect/\")\n",
        "val_loader = build_detection_test_loader(cfg, \"my_dataset_val2\")\n",
        "inference_on_dataset(trainer.model, val_loader, evaluator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[09/07 09:59:55 d2.data.datasets.coco]: \u001b[0mLoaded 190 images in COCO format from /content/drive/MyDrive/detectron2_500/test.json\n",
            "\u001b[32m[09/07 09:59:55 d2.data.common]: \u001b[0mSerializing 190 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[09/07 09:59:55 d2.data.common]: \u001b[0mSerialized dataset takes 0.34 MiB\n",
            "\u001b[32m[09/07 09:59:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 190 images\n",
            "\u001b[32m[09/07 09:59:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/190. 0.3358 s / img. ETA=0:01:01\n",
            "\u001b[32m[09/07 10:00:05 d2.evaluation.evaluator]: \u001b[0mInference done 26/190. 0.3456 s / img. ETA=0:00:57\n",
            "\u001b[32m[09/07 10:00:10 d2.evaluation.evaluator]: \u001b[0mInference done 40/190. 0.3519 s / img. ETA=0:00:53\n",
            "\u001b[32m[09/07 10:00:15 d2.evaluation.evaluator]: \u001b[0mInference done 55/190. 0.3510 s / img. ETA=0:00:48\n",
            "\u001b[32m[09/07 10:00:20 d2.evaluation.evaluator]: \u001b[0mInference done 69/190. 0.3519 s / img. ETA=0:00:43\n",
            "\u001b[32m[09/07 10:00:25 d2.evaluation.evaluator]: \u001b[0mInference done 83/190. 0.3526 s / img. ETA=0:00:38\n",
            "\u001b[32m[09/07 10:00:31 d2.evaluation.evaluator]: \u001b[0mInference done 97/190. 0.3543 s / img. ETA=0:00:33\n",
            "\u001b[32m[09/07 10:00:36 d2.evaluation.evaluator]: \u001b[0mInference done 111/190. 0.3539 s / img. ETA=0:00:28\n",
            "\u001b[32m[09/07 10:00:41 d2.evaluation.evaluator]: \u001b[0mInference done 125/190. 0.3540 s / img. ETA=0:00:23\n",
            "\u001b[32m[09/07 10:00:46 d2.evaluation.evaluator]: \u001b[0mInference done 139/190. 0.3553 s / img. ETA=0:00:18\n",
            "\u001b[32m[09/07 10:00:51 d2.evaluation.evaluator]: \u001b[0mInference done 154/190. 0.3543 s / img. ETA=0:00:13\n",
            "\u001b[32m[09/07 10:00:56 d2.evaluation.evaluator]: \u001b[0mInference done 168/190. 0.3545 s / img. ETA=0:00:07\n",
            "\u001b[32m[09/07 10:01:01 d2.evaluation.evaluator]: \u001b[0mInference done 182/190. 0.3547 s / img. ETA=0:00:02\n",
            "\u001b[32m[09/07 10:01:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:06.936572 (0.361819 s / img per device, on 1 devices)\n",
            "\u001b[32m[09/07 10:01:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:05 (0.354702 s / img per device, on 1 devices)\n",
            "\u001b[32m[09/07 10:01:04 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[09/07 10:01:04 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /content/drive/MyDrive/detectron2_500/output_detect/coco_instances_results.json\n",
            "\u001b[32m[09/07 10:01:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.36s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.08s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.290\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.450\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.297\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.145\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.405\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.439\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.192\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.416\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.429\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.254\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.518\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.658\n",
            "\u001b[32m[09/07 10:01:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 28.984 | 45.037 | 29.704 | 14.522 | 40.464 | 43.913 |\n",
            "\u001b[32m[09/07 10:01:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category      | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:--------------|:-------|\n",
            "| aeroplane  | 54.573 | car        | 14.666 | chair         | 19.969 |\n",
            "| cow        | 49.022 | person     | 10.651 | traffic_light | 25.023 |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.38s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.08s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.233\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.424\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.253\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.115\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.325\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.379\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.160\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.349\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.359\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.220\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.435\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.528\n",
            "\u001b[32m[09/07 10:01:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 23.257 | 42.385 | 25.316 | 11.456 | 32.504 | 37.905 |\n",
            "\u001b[32m[09/07 10:01:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category   | AP     | category   | AP     | category      | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:--------------|:-------|\n",
            "| aeroplane  | 39.125 | car        | 13.696 | chair         | 14.429 |\n",
            "| cow        | 40.668 | person     | 8.840  | traffic_light | 22.782 |\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('bbox',\n",
              "              {'AP': 28.98399615813917,\n",
              "               'AP-aeroplane': 54.57337962218733,\n",
              "               'AP-car': 14.66612805636027,\n",
              "               'AP-chair': 19.969412071910146,\n",
              "               'AP-cow': 49.021736761204615,\n",
              "               'AP-person': 10.650646989033767,\n",
              "               'AP-traffic_light': 25.022673448138853,\n",
              "               'AP50': 45.03740027896978,\n",
              "               'AP75': 29.703910273555806,\n",
              "               'APl': 43.91260835680967,\n",
              "               'APm': 40.464182486473106,\n",
              "               'APs': 14.5215639775658}),\n",
              "             ('segm',\n",
              "              {'AP': 23.25659772128245,\n",
              "               'AP-aeroplane': 39.12518787892412,\n",
              "               'AP-car': 13.695654512165826,\n",
              "               'AP-chair': 14.429427753456547,\n",
              "               'AP-cow': 40.66808307048525,\n",
              "               'AP-person': 8.839691185693024,\n",
              "               'AP-traffic_light': 22.781541926969926,\n",
              "               'AP50': 42.384749137878536,\n",
              "               'AP75': 25.316161950387716,\n",
              "               'APl': 37.905305049520734,\n",
              "               'APm': 32.504470585780396,\n",
              "               'APs': 11.455878745055307})])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQ2TVK3Gs9NM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfbac263-6214-4e21-f1c3-18dfce800a52"
      },
      "source": [
        "import os\n",
        "#test evaluation\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "\n",
        "cfg.MODEL.WEIGHTS = '/content/drive/MyDrive/detectron2_500/output_detect/model_final.pth'\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.25\n",
        "predictor = DefaultPredictor(cfg)\n",
        "evaluator = COCOEvaluator(\"my_dataset_train2\", cfg, False, output_dir=\"/content/drive/MyDrive/detectron2_500/output_detect/\")\n",
        "val_loader = build_detection_test_loader(cfg, \"my_dataset_train2\")\n",
        "inference_on_dataset(trainer.model, val_loader, evaluator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[09/16 09:38:58 d2.data.datasets.coco]: \u001b[0mLoaded 689 images in COCO format from /content/drive/MyDrive/detectron2_500/train.json\n",
            "\u001b[32m[09/16 09:38:58 d2.data.common]: \u001b[0mSerializing 689 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[09/16 09:38:58 d2.data.common]: \u001b[0mSerialized dataset takes 1.35 MiB\n",
            "\u001b[32m[09/16 09:38:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 689 images\n",
            "\u001b[32m[09/16 09:39:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/689. 0.3965 s / img. ETA=0:04:31\n",
            "\u001b[32m[09/16 09:39:08 d2.evaluation.evaluator]: \u001b[0mInference done 25/689. 0.3749 s / img. ETA=0:04:11\n",
            "\u001b[32m[09/16 09:39:13 d2.evaluation.evaluator]: \u001b[0mInference done 39/689. 0.3731 s / img. ETA=0:04:05\n",
            "\u001b[32m[09/16 09:39:19 d2.evaluation.evaluator]: \u001b[0mInference done 53/689. 0.3747 s / img. ETA=0:04:01\n",
            "\u001b[32m[09/16 09:39:24 d2.evaluation.evaluator]: \u001b[0mInference done 66/689. 0.3768 s / img. ETA=0:03:58\n",
            "\u001b[32m[09/16 09:39:29 d2.evaluation.evaluator]: \u001b[0mInference done 79/689. 0.3773 s / img. ETA=0:03:53\n",
            "\u001b[32m[09/16 09:39:34 d2.evaluation.evaluator]: \u001b[0mInference done 92/689. 0.3788 s / img. ETA=0:03:49\n",
            "\u001b[32m[09/16 09:39:39 d2.evaluation.evaluator]: \u001b[0mInference done 106/689. 0.3786 s / img. ETA=0:03:44\n",
            "\u001b[32m[09/16 09:39:44 d2.evaluation.evaluator]: \u001b[0mInference done 119/689. 0.3789 s / img. ETA=0:03:39\n",
            "\u001b[32m[09/16 09:39:49 d2.evaluation.evaluator]: \u001b[0mInference done 132/689. 0.3792 s / img. ETA=0:03:34\n",
            "\u001b[32m[09/16 09:39:55 d2.evaluation.evaluator]: \u001b[0mInference done 145/689. 0.3800 s / img. ETA=0:03:30\n",
            "\u001b[32m[09/16 09:40:00 d2.evaluation.evaluator]: \u001b[0mInference done 158/689. 0.3804 s / img. ETA=0:03:25\n",
            "\u001b[32m[09/16 09:40:05 d2.evaluation.evaluator]: \u001b[0mInference done 171/689. 0.3808 s / img. ETA=0:03:20\n",
            "\u001b[32m[09/16 09:40:10 d2.evaluation.evaluator]: \u001b[0mInference done 185/689. 0.3795 s / img. ETA=0:03:14\n",
            "\u001b[32m[09/16 09:40:15 d2.evaluation.evaluator]: \u001b[0mInference done 199/689. 0.3794 s / img. ETA=0:03:08\n",
            "\u001b[32m[09/16 09:40:20 d2.evaluation.evaluator]: \u001b[0mInference done 212/689. 0.3798 s / img. ETA=0:03:04\n",
            "\u001b[32m[09/16 09:40:26 d2.evaluation.evaluator]: \u001b[0mInference done 226/689. 0.3788 s / img. ETA=0:02:58\n",
            "\u001b[32m[09/16 09:40:31 d2.evaluation.evaluator]: \u001b[0mInference done 240/689. 0.3784 s / img. ETA=0:02:52\n",
            "\u001b[32m[09/16 09:40:36 d2.evaluation.evaluator]: \u001b[0mInference done 254/689. 0.3780 s / img. ETA=0:02:47\n",
            "\u001b[32m[09/16 09:40:41 d2.evaluation.evaluator]: \u001b[0mInference done 267/689. 0.3782 s / img. ETA=0:02:42\n",
            "\u001b[32m[09/16 09:40:46 d2.evaluation.evaluator]: \u001b[0mInference done 281/689. 0.3779 s / img. ETA=0:02:36\n",
            "\u001b[32m[09/16 09:40:52 d2.evaluation.evaluator]: \u001b[0mInference done 294/689. 0.3783 s / img. ETA=0:02:31\n",
            "\u001b[32m[09/16 09:40:57 d2.evaluation.evaluator]: \u001b[0mInference done 307/689. 0.3783 s / img. ETA=0:02:26\n",
            "\u001b[32m[09/16 09:41:02 d2.evaluation.evaluator]: \u001b[0mInference done 321/689. 0.3779 s / img. ETA=0:02:21\n",
            "\u001b[32m[09/16 09:41:07 d2.evaluation.evaluator]: \u001b[0mInference done 335/689. 0.3780 s / img. ETA=0:02:15\n",
            "\u001b[32m[09/16 09:41:12 d2.evaluation.evaluator]: \u001b[0mInference done 349/689. 0.3776 s / img. ETA=0:02:10\n",
            "\u001b[32m[09/16 09:41:18 d2.evaluation.evaluator]: \u001b[0mInference done 362/689. 0.3780 s / img. ETA=0:02:05\n",
            "\u001b[32m[09/16 09:41:23 d2.evaluation.evaluator]: \u001b[0mInference done 375/689. 0.3784 s / img. ETA=0:02:00\n",
            "\u001b[32m[09/16 09:41:28 d2.evaluation.evaluator]: \u001b[0mInference done 389/689. 0.3782 s / img. ETA=0:01:55\n",
            "\u001b[32m[09/16 09:41:33 d2.evaluation.evaluator]: \u001b[0mInference done 402/689. 0.3784 s / img. ETA=0:01:50\n",
            "\u001b[32m[09/16 09:41:38 d2.evaluation.evaluator]: \u001b[0mInference done 415/689. 0.3785 s / img. ETA=0:01:45\n",
            "\u001b[32m[09/16 09:41:43 d2.evaluation.evaluator]: \u001b[0mInference done 429/689. 0.3782 s / img. ETA=0:01:39\n",
            "\u001b[32m[09/16 09:41:49 d2.evaluation.evaluator]: \u001b[0mInference done 442/689. 0.3783 s / img. ETA=0:01:34\n",
            "\u001b[32m[09/16 09:41:54 d2.evaluation.evaluator]: \u001b[0mInference done 456/689. 0.3780 s / img. ETA=0:01:29\n",
            "\u001b[32m[09/16 09:41:59 d2.evaluation.evaluator]: \u001b[0mInference done 470/689. 0.3780 s / img. ETA=0:01:24\n",
            "\u001b[32m[09/16 09:42:04 d2.evaluation.evaluator]: \u001b[0mInference done 484/689. 0.3779 s / img. ETA=0:01:18\n",
            "\u001b[32m[09/16 09:42:10 d2.evaluation.evaluator]: \u001b[0mInference done 497/689. 0.3782 s / img. ETA=0:01:13\n",
            "\u001b[32m[09/16 09:42:15 d2.evaluation.evaluator]: \u001b[0mInference done 511/689. 0.3782 s / img. ETA=0:01:08\n",
            "\u001b[32m[09/16 09:42:20 d2.evaluation.evaluator]: \u001b[0mInference done 524/689. 0.3783 s / img. ETA=0:01:03\n",
            "\u001b[32m[09/16 09:42:25 d2.evaluation.evaluator]: \u001b[0mInference done 538/689. 0.3783 s / img. ETA=0:00:58\n",
            "\u001b[32m[09/16 09:42:31 d2.evaluation.evaluator]: \u001b[0mInference done 552/689. 0.3781 s / img. ETA=0:00:52\n",
            "\u001b[32m[09/16 09:42:36 d2.evaluation.evaluator]: \u001b[0mInference done 565/689. 0.3785 s / img. ETA=0:00:47\n",
            "\u001b[32m[09/16 09:42:41 d2.evaluation.evaluator]: \u001b[0mInference done 579/689. 0.3779 s / img. ETA=0:00:42\n",
            "\u001b[32m[09/16 09:42:46 d2.evaluation.evaluator]: \u001b[0mInference done 592/689. 0.3780 s / img. ETA=0:00:37\n",
            "\u001b[32m[09/16 09:42:51 d2.evaluation.evaluator]: \u001b[0mInference done 606/689. 0.3778 s / img. ETA=0:00:31\n",
            "\u001b[32m[09/16 09:42:56 d2.evaluation.evaluator]: \u001b[0mInference done 620/689. 0.3776 s / img. ETA=0:00:26\n",
            "\u001b[32m[09/16 09:43:01 d2.evaluation.evaluator]: \u001b[0mInference done 633/689. 0.3776 s / img. ETA=0:00:21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mdfzn5wmS1tJ",
        "outputId": "605d87ac-e076-4311-b640-54c2e17330d4"
      },
      "source": [
        "import os\n",
        "#test evaluation\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "\n",
        "cfg.MODEL.WEIGHTS = '/content/drive/MyDrive/detectron2_500/output_detect/model_0092000.pth'\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.25\n",
        "predictor = DefaultPredictor(cfg)\n",
        "evaluator = COCOEvaluator(\"my_dataset_train2\", cfg, False, output_dir=\"/content/drive/MyDrive/detectron2_500/output_detect/\")\n",
        "val_loader = build_detection_test_loader(cfg, \"my_dataset_train2\")\n",
        "inference_on_dataset(trainer.model, val_loader, evaluator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[09/07 10:11:34 d2.data.datasets.coco]: \u001b[0mLoaded 689 images in COCO format from /content/drive/MyDrive/detectron2_500/train.json\n",
            "\u001b[32m[09/07 10:11:34 d2.data.common]: \u001b[0mSerializing 689 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[09/07 10:11:34 d2.data.common]: \u001b[0mSerialized dataset takes 1.35 MiB\n",
            "\u001b[32m[09/07 10:11:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 689 images\n",
            "\u001b[32m[09/07 10:11:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/689. 0.3663 s / img. ETA=0:04:11\n",
            "\u001b[32m[09/07 10:11:43 d2.evaluation.evaluator]: \u001b[0mInference done 26/689. 0.3474 s / img. ETA=0:03:53\n",
            "\u001b[32m[09/07 10:11:49 d2.evaluation.evaluator]: \u001b[0mInference done 41/689. 0.3452 s / img. ETA=0:03:47\n",
            "\u001b[32m[09/07 10:11:54 d2.evaluation.evaluator]: \u001b[0mInference done 55/689. 0.3478 s / img. ETA=0:03:43\n",
            "\u001b[32m[09/07 10:11:59 d2.evaluation.evaluator]: \u001b[0mInference done 69/689. 0.3492 s / img. ETA=0:03:40\n",
            "\u001b[32m[09/07 10:12:04 d2.evaluation.evaluator]: \u001b[0mInference done 83/689. 0.3514 s / img. ETA=0:03:37\n",
            "\u001b[32m[09/07 10:12:09 d2.evaluation.evaluator]: \u001b[0mInference done 97/689. 0.3519 s / img. ETA=0:03:32\n",
            "\u001b[32m[09/07 10:12:14 d2.evaluation.evaluator]: \u001b[0mInference done 111/689. 0.3530 s / img. ETA=0:03:27\n",
            "\u001b[32m[09/07 10:12:19 d2.evaluation.evaluator]: \u001b[0mInference done 125/689. 0.3535 s / img. ETA=0:03:23\n",
            "\u001b[32m[09/07 10:12:24 d2.evaluation.evaluator]: \u001b[0mInference done 139/689. 0.3543 s / img. ETA=0:03:18\n",
            "\u001b[32m[09/07 10:12:30 d2.evaluation.evaluator]: \u001b[0mInference done 153/689. 0.3549 s / img. ETA=0:03:13\n",
            "\u001b[32m[09/07 10:12:35 d2.evaluation.evaluator]: \u001b[0mInference done 167/689. 0.3555 s / img. ETA=0:03:09\n",
            "\u001b[32m[09/07 10:12:40 d2.evaluation.evaluator]: \u001b[0mInference done 182/689. 0.3548 s / img. ETA=0:03:03\n",
            "\u001b[32m[09/07 10:12:45 d2.evaluation.evaluator]: \u001b[0mInference done 196/689. 0.3549 s / img. ETA=0:02:58\n",
            "\u001b[32m[09/07 10:12:50 d2.evaluation.evaluator]: \u001b[0mInference done 210/689. 0.3560 s / img. ETA=0:02:53\n",
            "\u001b[32m[09/07 10:12:56 d2.evaluation.evaluator]: \u001b[0mInference done 225/689. 0.3549 s / img. ETA=0:02:47\n",
            "\u001b[32m[09/07 10:13:01 d2.evaluation.evaluator]: \u001b[0mInference done 240/689. 0.3547 s / img. ETA=0:02:42\n",
            "\u001b[32m[09/07 10:13:06 d2.evaluation.evaluator]: \u001b[0mInference done 254/689. 0.3546 s / img. ETA=0:02:37\n",
            "\u001b[32m[09/07 10:13:11 d2.evaluation.evaluator]: \u001b[0mInference done 268/689. 0.3551 s / img. ETA=0:02:32\n",
            "\u001b[32m[09/07 10:13:16 d2.evaluation.evaluator]: \u001b[0mInference done 282/689. 0.3549 s / img. ETA=0:02:27\n",
            "\u001b[32m[09/07 10:13:21 d2.evaluation.evaluator]: \u001b[0mInference done 296/689. 0.3555 s / img. ETA=0:02:22\n",
            "\u001b[32m[09/07 10:13:27 d2.evaluation.evaluator]: \u001b[0mInference done 310/689. 0.3557 s / img. ETA=0:02:17\n",
            "\u001b[32m[09/07 10:13:32 d2.evaluation.evaluator]: \u001b[0mInference done 325/689. 0.3553 s / img. ETA=0:02:11\n",
            "\u001b[32m[09/07 10:13:37 d2.evaluation.evaluator]: \u001b[0mInference done 339/689. 0.3556 s / img. ETA=0:02:06\n",
            "\u001b[32m[09/07 10:13:42 d2.evaluation.evaluator]: \u001b[0mInference done 353/689. 0.3556 s / img. ETA=0:02:01\n",
            "\u001b[32m[09/07 10:13:47 d2.evaluation.evaluator]: \u001b[0mInference done 367/689. 0.3561 s / img. ETA=0:01:56\n",
            "\u001b[32m[09/07 10:13:52 d2.evaluation.evaluator]: \u001b[0mInference done 381/689. 0.3561 s / img. ETA=0:01:51\n",
            "\u001b[32m[09/07 10:13:58 d2.evaluation.evaluator]: \u001b[0mInference done 395/689. 0.3565 s / img. ETA=0:01:46\n",
            "\u001b[32m[09/07 10:14:03 d2.evaluation.evaluator]: \u001b[0mInference done 409/689. 0.3566 s / img. ETA=0:01:41\n",
            "\u001b[32m[09/07 10:14:08 d2.evaluation.evaluator]: \u001b[0mInference done 423/689. 0.3567 s / img. ETA=0:01:36\n",
            "\u001b[32m[09/07 10:14:13 d2.evaluation.evaluator]: \u001b[0mInference done 438/689. 0.3565 s / img. ETA=0:01:31\n",
            "\u001b[32m[09/07 10:14:18 d2.evaluation.evaluator]: \u001b[0mInference done 452/689. 0.3564 s / img. ETA=0:01:26\n",
            "\u001b[32m[09/07 10:14:24 d2.evaluation.evaluator]: \u001b[0mInference done 466/689. 0.3565 s / img. ETA=0:01:20\n",
            "\u001b[32m[09/07 10:14:29 d2.evaluation.evaluator]: \u001b[0mInference done 480/689. 0.3564 s / img. ETA=0:01:15\n",
            "\u001b[32m[09/07 10:14:34 d2.evaluation.evaluator]: \u001b[0mInference done 494/689. 0.3567 s / img. ETA=0:01:10\n",
            "\u001b[32m[09/07 10:14:39 d2.evaluation.evaluator]: \u001b[0mInference done 508/689. 0.3568 s / img. ETA=0:01:05\n",
            "\u001b[32m[09/07 10:14:44 d2.evaluation.evaluator]: \u001b[0mInference done 522/689. 0.3568 s / img. ETA=0:01:00\n",
            "\u001b[32m[09/07 10:14:49 d2.evaluation.evaluator]: \u001b[0mInference done 536/689. 0.3569 s / img. ETA=0:00:55\n",
            "\u001b[32m[09/07 10:14:54 d2.evaluation.evaluator]: \u001b[0mInference done 550/689. 0.3569 s / img. ETA=0:00:50\n",
            "\u001b[32m[09/07 10:14:59 d2.evaluation.evaluator]: \u001b[0mInference done 564/689. 0.3572 s / img. ETA=0:00:45\n",
            "\u001b[32m[09/07 10:15:05 d2.evaluation.evaluator]: \u001b[0mInference done 579/689. 0.3567 s / img. ETA=0:00:39\n",
            "\u001b[32m[09/07 10:15:10 d2.evaluation.evaluator]: \u001b[0mInference done 593/689. 0.3568 s / img. ETA=0:00:34\n",
            "\u001b[32m[09/07 10:15:15 d2.evaluation.evaluator]: \u001b[0mInference done 608/689. 0.3566 s / img. ETA=0:00:29\n",
            "\u001b[32m[09/07 10:15:20 d2.evaluation.evaluator]: \u001b[0mInference done 622/689. 0.3566 s / img. ETA=0:00:24\n",
            "\u001b[32m[09/07 10:15:25 d2.evaluation.evaluator]: \u001b[0mInference done 636/689. 0.3566 s / img. ETA=0:00:19\n",
            "\u001b[32m[09/07 10:15:30 d2.evaluation.evaluator]: \u001b[0mInference done 650/689. 0.3567 s / img. ETA=0:00:14\n",
            "\u001b[32m[09/07 10:15:36 d2.evaluation.evaluator]: \u001b[0mInference done 664/689. 0.3569 s / img. ETA=0:00:09\n",
            "\u001b[32m[09/07 10:15:41 d2.evaluation.evaluator]: \u001b[0mInference done 678/689. 0.3571 s / img. ETA=0:00:03\n",
            "\u001b[32m[09/07 10:15:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:08.648143 (0.363521 s / img per device, on 1 devices)\n",
            "\u001b[32m[09/07 10:15:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:04:04 (0.356970 s / img per device, on 1 devices)\n",
            "\u001b[32m[09/07 10:15:45 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[09/07 10:15:45 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /content/drive/MyDrive/detectron2_500/output_detect/coco_instances_results.json\n",
            "\u001b[32m[09/07 10:15:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.45s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.17s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.901\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.987\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.975\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.877\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.935\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.961\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.341\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.897\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.931\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.902\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.962\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.983\n",
            "\u001b[32m[09/07 10:15:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 90.144 | 98.731 | 97.528 | 87.734 | 93.536 | 96.084 |\n",
            "\u001b[32m[09/07 10:15:47 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category      | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:--------------|:-------|\n",
            "| aeroplane  | 97.505 | car        | 87.769 | chair         | 89.474 |\n",
            "| cow        | 90.475 | person     | 90.239 | traffic_light | 85.403 |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=1.76s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.17s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.710\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.977\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.851\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.656\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.743\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.854\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.293\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.754\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.781\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.722\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.807\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.892\n",
            "\u001b[32m[09/07 10:15:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 71.048 | 97.700 | 85.071 | 65.572 | 74.309 | 85.446 |\n",
            "\u001b[32m[09/07 10:15:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category   | AP     | category   | AP     | category      | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:--------------|:-------|\n",
            "| aeroplane  | 72.378 | car        | 73.344 | chair         | 68.960 |\n",
            "| cow        | 66.688 | person     | 69.088 | traffic_light | 75.830 |\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('bbox',\n",
              "              {'AP': 90.14414637284705,\n",
              "               'AP-aeroplane': 97.5046735442775,\n",
              "               'AP-car': 87.76866864133054,\n",
              "               'AP-chair': 89.47432734229967,\n",
              "               'AP-cow': 90.4748976867685,\n",
              "               'AP-person': 90.23886735543314,\n",
              "               'AP-traffic_light': 85.40344366697295,\n",
              "               'AP50': 98.73068806907918,\n",
              "               'AP75': 97.52827898558189,\n",
              "               'APl': 96.084273558184,\n",
              "               'APm': 93.53585458883222,\n",
              "               'APs': 87.73384424280555}),\n",
              "             ('segm',\n",
              "              {'AP': 71.0479835296563,\n",
              "               'AP-aeroplane': 72.37761169743177,\n",
              "               'AP-car': 73.34421383141503,\n",
              "               'AP-chair': 68.96028807350005,\n",
              "               'AP-cow': 66.68790716391861,\n",
              "               'AP-person': 69.0876560609309,\n",
              "               'AP-traffic_light': 75.83022435074153,\n",
              "               'AP50': 97.70041956815953,\n",
              "               'AP75': 85.07104841918662,\n",
              "               'APl': 85.44634382492144,\n",
              "               'APm': 74.30907903234747,\n",
              "               'APs': 65.5720124624275})])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uj7B0legToC1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}